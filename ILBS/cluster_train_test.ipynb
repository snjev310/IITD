{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, MaxPool2D\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_maps(path):\n",
    "    images = []\n",
    "    for index, name in enumerate(os.listdir(path)):\n",
    "        folder = os.path.join(path, name)\n",
    "        for file_class in os.listdir(folder):\n",
    "            im_folder = os.path.join(folder, file_class)\n",
    "\n",
    "            for im in os.listdir(im_folder):\n",
    "                img = cv2.imread(os.path.join(im_folder, im))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "                img = cv2.resize(img, (196, 196))\n",
    "                if img is not None:\n",
    "               #     img = (img-np.mean(img))/np.std(img)\n",
    "                    images.append((np.array(img), index)) \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_set = import_maps(r'D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\train')\n",
    "image_test_set = import_maps(r'D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12900"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1950"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_all = [i[0] for i in image_train_set]\n",
    "train_images_array = np.array(train_images_all)\n",
    "#train_images_array=np.expand_dims(train_images_array,axis=3)\n",
    "train_image_label = [i[1] for i in image_train_set]\n",
    "train_image_label = np.array(train_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_all = [i[0] for i in image_test_set]\n",
    "test_images_array = np.array(test_images_all)\n",
    "test_images_array=np.expand_dims(test_images_array,axis=3)\n",
    "test_image_label = [i[1] for i in image_test_set]\n",
    "test_image_label = np.array(test_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12900, 196, 196)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler(copy=False)\n",
    "train_images = scalar.fit_transform(train_images_array.reshape(12900, 196*196))\n",
    "train_images_array = train_images.reshape(12900, 196, 196, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12900,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1950, 196, 196, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1950,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_images_array,train_image_label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "train_label_enc = enc.fit_transform(train_y.reshape(-1, 1)).toarray()\n",
    "val_label_enc = enc.fit_transform(val_y.reshape(-1, 1)).toarray()\n",
    "test_label_enc = enc.fit_transform(test_image_label.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2580, 196, 196, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10320,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 196, 196, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 196, 196, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 98, 98, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 98, 98, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 49, 49, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 49, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 49, 49, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 24, 24, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 24, 24, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "vgg16 (MaxPooling2D)         (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               9437696   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 24,284,102\n",
      "Trainable params: 24,284,102\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(196,196,1),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_regularizer= keras.regularizers.l2(0.00001)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",kernel_regularizer= keras.regularizers.l2(0.00001)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",kernel_regularizer= keras.regularizers.l2(0.00001)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_regularizer= keras.regularizers.l2(0.00001)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\",kernel_regularizer= keras.regularizers.l2(0.00001)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_regularizer= keras.regularizers.l2(0.0001)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu', name='fc1'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation='relu', name='fc2'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax', name='output'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "               optimizer=keras.optimizers.SGD(0.01),\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                            patience=10, min_lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Previous model Run for 200 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10320 samples, validate on 2580 samples\n",
      "Epoch 1/200\n",
      "10320/10320 [==============================] - 68s 7ms/sample - loss: 1.4588 - accuracy: 0.3701 - val_loss: 1.4382 - val_accuracy: 0.3888: 1.4 - ETA: 1:14 - loss: 1.4155 - accura - ETA: 1:10 - loss: 1.4220  - ETA: 1:05 - loss: 1.4288 - accuracy: 0. - ETA: 1:04 - loss: 1.4 - ETA: \n",
      "Epoch 2/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 1.4515 - accuracy: 0.3747 - val_loss: 1.4315 - val_accuracy: 0.38884s - loss: 1.4349 - accuracy: 0.39 - ETA: 53s - loss: 1.4382 -  - ETA: 50s - loss: 1.4566 - acc - ETA: 48s - loss: 1.4485 - accuracy: - ETA: 47s - loss: 1.4388 - accuracy:  - ETA: 46s - loss: 1.4349 - a - ETA: 34s - loss: 1.4515 - accuracy - ETA: 33s - loss: 1.4504 - accuracy: 0.3 - ETA: 32s - loss: 1.4506 - accuracy: - ETA: 31s - loss: 1.4518 - accuracy: 0.3 - ETA: 30s - loss: 1.4514 -  - ETA: 27s - loss: 1.4504 - - ETA: 24s - loss: 1.4494 - accurac - ETA: 23s - loss: 1.4548 - accuracy: 0.37 - ETA: 22s - loss: 1.4549 - accuracy: - ETA: 21s - loss: 1.4550 - accuracy: 0. - ETA: 20s -\n",
      "Epoch 3/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 1.4442 - accuracy: 0.3764 - val_loss: 1.4226 - val_accuracy: 0.3888TA: 59s - loss: 1.4068 - accuracy: - ETA: 57s - loss: 1.457 - ETA: 53s - loss: 1.4558 - accuracy: 0.3 - ETA: 53s - loss: 1.4679 - - ETA: 50s - loss: 1. - ETA: 45s - loss: 1.4697 - accura - ETA: 44s - loss: - ETA: 39s - loss: 1.4621 - accur - ETA: 37s - loss: 1.4649 - ETA: 33s - loss: 1.4594 - accuracy: 0. - ETA: 32s - loss: 1.458 - ETA: 29s - loss: 1.4563 - a - ETA: 26s - loss: 1.4551 - acc - ETA: 23s - loss: 1.4523 - ETA: 20s - loss: 1.4549 - ac - ETA: 17s - loss: 1.4 - ETA: 13s - loss: 1.4515 - a - ETA: 10s - loss: \n",
      "Epoch 4/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 1.4312 - accuracy: 0.3832 - val_loss: 1.4325 - val_accuracy: 0.3938 ETA: 45s - loss: 1.4291 - accuracy:  - ETA: 44s - loss: 1.4248 - accurac - ETA: 43s - ETA: 36s - loss: 1.4313 - ac - ETA: 34 - ETA: 19s - l - ETA\n",
      "Epoch 5/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 1.3937 - accuracy: 0.3944 - val_loss: 1.3056 - val_accuracy: 0.4547 ETA - ETA: 34s - loss: 1.4050 - ac - ETA: 32s - loss: 1.3999 - accuracy: 0 - ETA: 22s - loss: 1.4027 - accura - ETA: 20s - loss:  - ETA: 0s - loss: 1.3947 - accuracy: 0.39 - ETA: 0s - loss: 1.3940 - accuracy: \n",
      "Epoch 6/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 1.3096 - accuracy: 0.4343 - val_loss: 1.1488 - val_accuracy: 0.4938 52s - loss: 1.3649 -  - ETA: 4 - ETA: 34s - loss: 1.3559 - acc\n",
      "Epoch 7/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 1.1239 - accuracy: 0.5275 - val_loss: 0.8840 - val_accuracy: 0.6426 - loss: 1. - ETA:  - ETA: 38s - loss - ETA - ETA: 25s - loss: 1.1610 - accuracy: 0. - ETA: 25s - loss: 1.1585 - ac - ETA: 22s - loss: 1.1620 - accuracy: 0.50 - ETA: 22s - loss: 1.163 - ETA: 18s - loss: 1.1560 - accuracy: - ETA: 17s - loss: 1.1540 - acc\n",
      "Epoch 8/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.8581 - accuracy: 0.6402 - val_loss: 0.6329 - val_accuracy: 0.7636\n",
      "Epoch 9/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.5744 - accuracy: 0.7726 - val_loss: 0.3366 - val_accuracy: 0.8864- loss: 0.6341 - accuracy: 0.757 - ETA: 57s - loss: 0.6398 - accur - ETA: 55s - loss: 0.6323 - accu - ETA: 53s - loss: 0.6629 - acc - ETA: 50s - loss - ETA: 45s - l - ETA: 40s - loss: 0.6522 - accuracy: 0 - ETA: 39s - lo - ETA: 33s - loss: 0.6528 - accuracy: 0. - ETA: 33s - loss: 0.6508 - accurac - E - ETA: 23s - loss: 0.6378 - ETA: 12s - loss: 0.6113 - accuracy:  - ETA: 10s - loss:  - ETA: 8s - loss: 0.5971 - ac - ETA: 6s - l\n",
      "Epoch 10/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.3595 - accuracy: 0.8606 - val_loss: 0.1230 - val_accuracy: 0.9531TA: 1s - loss: 0.3614 - accu\n",
      "Epoch 11/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.1984 - accuracy: 0.9264 - val_loss: 0.0643 - val_accuracy: 0.9721 42s - loss: 0.234 - ETA: 38s - loss: 0.220 - ETA: 34s - loss: 0.2210 - accur - ETA: 32s - loss: 0.2172 - accurac - ETA: 30s - loss: 0.2 - ETA: 26s - l - ETA: 21s - loss: 0.2156 - accurac - ETA: 19s - loss: 0.2162 - accura - ETA: 17s - loss: 0.2139 - accuracy: 0.92 -  - ETA: 9s - loss: 0.2050 - accura - - ETA: 4s - loss: 0.2041 - accuracy:  - ETA: 4s - loss: 0.202 - ETA: 2s - loss: 0.2005 -  - ETA: 1s - loss: 0.1995 - accu\n",
      "Epoch 12/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.1489 - accuracy: 0.9431 - val_loss: 0.0518 - val_accuracy: 0.9744 loss: 0.1842 - accuracy:  - ETA: 52s - loss: 0.1809 -  - - ETA: 4s - loss: 0.1498 - accuracy -\n",
      "Epoch 13/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.1167 - accuracy: 0.9539 - val_loss: 0.0504 - val_accuracy: 0.9740 31s - loss: 0.1 - ETA: 18s - loss: 0.1268 - accu - ETA: 16s - loss: 0.1253 - accuracy: 0.9 - ETA: 16s - loss: 0.1250 - accu - ETA: 13s - loss: 0.1216 - accura - ET - ETA: 3s\n",
      "Epoch 14/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0861 - accuracy: 0.9641 - val_loss: 0.0567 - val_accuracy: 0.9736ss: 0.0783 - a - ETA: 50s - loss: 0.0853 - accuracy: 0 - ETA: 49s - los - ETA: 35s -  - ETA: 29s - loss: 0.0870 - a - ETA: 26s - loss: - ETA: 13s - loss: 0.0906 - a - ETA: 6s - - ETA: 3s - loss: 0.0877 - accuracy:  - ETA: 2s - l\n",
      "Epoch 15/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0709 - accuracy: 0.9669 - val_loss: 0.0470 - val_accuracy: 0.9740\n",
      "Epoch 16/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0714 - accuracy: 0.9670 - val_loss: 0.0381 - val_accuracy: 0.9779\n",
      "Epoch 17/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0607 - accuracy: 0.9701 - val_loss: 0.0453 - val_accuracy: 0.9744\n",
      "Epoch 18/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0560 - accuracy: 0.9721 - val_loss: 0.0424 - val_accuracy: 0.9740\n",
      "Epoch 19/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0525 - accuracy: 0.9729 - val_loss: 0.0381 - val_accuracy: 0.9729s \n",
      "Epoch 20/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0477 - accuracy: 0.9741 - val_loss: 0.0342 - val_accuracy: 0.974033s - loss: 0.0436 - accuracy: - ETA: 32s - - ETA: 26s - loss: 0.0450 - accuracy:  - ETA: 25s - - ETA: 19s - loss: 0\n",
      "Epoch 21/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0464 - accuracy: 0.9756 - val_loss: 0.0360 - val_accuracy: 0.9748 ETA: 31s - loss: 0.0408 - accuracy:  - ETA: 30s - loss: 0.0417 - accuracy: 0.9 - ETA: 30s - loss: 0.0421 - accurac - ETA: 28s - l \n",
      "Epoch 22/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0464 - accuracy: 0.9745 - val_loss: 0.0531 - val_accuracy: 0.9705\n",
      "Epoch 23/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0505 - accuracy: 0.9728 - val_loss: 0.0328 - val_accuracy: 0.9779. - ETA: 0s - loss: 0.0506 - accuracy: 0.97\n",
      "Epoch 24/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0453 - accuracy: 0.9755 - val_loss: 0.0372 - val_accuracy: 0.9756\n",
      "Epoch 25/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0424 - accuracy: 0.9745 - val_loss: 0.0363 - val_accuracy: 0.97441s - loss: 0.  - ETA: 28s - loss: 0.0421 - accuracy: 0.972 - ETA: 28s - loss: 0.0418 - accurac - - ETA: 19s - loss: 0.0426 - accuracy:  - ETA: 17s - loss: 0. - ETA\n",
      "Epoch 26/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0403 - accuracy: 0.9768 - val_loss: 0.0330 - val_accuracy: 0.9740\n",
      "Epoch 27/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0418 - accuracy: 0.9757 - val_loss: 0.0321 - val_accuracy: 0.9729\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0398 - accuracy: 0.9763 - val_loss: 0.0338 - val_accuracy: 0.9709 - accuracy: - ETA: 24s - loss: 0.0352 - accuracy: 0.\n",
      "Epoch 29/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0404 - accuracy: 0.9769 - val_loss: 0.0330 - val_accuracy: 0.9779 0.97 - ETA: 48s - loss: 0.0 - - ETA: 36s - loss: 0.0401 - ETA: 32s - loss: 0.0410 - - ETA: 29s - loss - ETA: 24s - lo - ETA: 19s - loss: 0.0422 - accuracy: 0.975 - ETA: 18s - loss: 0.0422 - ac - ETA: 4s - loss: 0.0405 - ac - ETA:  - ETA: 0s - loss: 0.0405 - accuracy: 0.97\n",
      "Epoch 30/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0431 - accuracy: 0.9757 - val_loss: 0.0344 - val_accuracy: 0.9733\n",
      "Epoch 31/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0414 - accuracy: 0.9740 - val_loss: 0.0347 - val_accuracy: 0.9725 - accurac - ETA: 43s - loss: 0.0350 - accuracy: 0.9 - ETA: 42s - loss: 0.0352  -\n",
      "Epoch 32/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0398 - accuracy: 0.9748 - val_loss: 0.0340 - val_accuracy: 0.9748\n",
      "Epoch 33/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0409 - accuracy: 0.9740 - val_loss: 0.0332 - val_accuracy: 0.9744 ETA: 39s - loss: 0.0352 - accura - ETA: 37s - loss: 0.0358 - accur - ETA: 35s  - ETA: 29s - loss: 0.0393 - ac - ETA: - ETA: 19s - loss: 0.0413 - acc - ETA: 17s - loss: 0.0407 - acc\n",
      "Epoch 34/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0383 - accuracy: 0.9759 - val_loss: 0.0331 - val_accuracy: 0.97210363 - accuracy: 0.9 - ETA: 17s - loss: 0.0 - ETA: 13s - loss: 0.0370 - accuracy:  - ETA: 12s \n",
      "Epoch 35/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0379 - accuracy: 0.9751 - val_loss: 0.0335 - val_accuracy: 0.9729\n",
      "Epoch 36/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0371 - accuracy: 0.9771 - val_loss: 0.0339 - val_accuracy: 0.9756\n",
      "Epoch 37/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0374 - accuracy: 0.9777 - val_loss: 0.0320 - val_accuracy: 0.9752\n",
      "Epoch 38/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0416 - accuracy: 0.9767 - val_loss: 0.0341 - val_accuracy: 0.9744: 16 - ETA: 10s - loss - ETA\n",
      "Epoch 39/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0431 - accuracy: 0.9729 - val_loss: 0.0331 - val_accuracy: 0.9729o\n",
      "Epoch 40/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0373 - accuracy: 0.9763 - val_loss: 0.0330 - val_accuracy: 0.9729\n",
      "Epoch 41/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0380 - accuracy: 0.9755 - val_loss: 0.0331 - val_accuracy: 0.9729\n",
      "Epoch 42/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0364 - accuracy: 0.9764 - val_loss: 0.0329 - val_accuracy: 0.9717\n",
      "Epoch 43/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0362 - accuracy: 0.9761 - val_loss: 0.0332 - val_accuracy: 0.97298s - loss:  - ETA: 53s - loss: 0.0301 - - ETA: 50s - loss: 0.0319 - accuracy: 0.9 - ETA: 49s - loss: 0.033 - ETA: 45s - l - ETA: 40s - lo - ETA: 5s - loss: 0.036 -\n",
      "Epoch 44/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0362 - accuracy: 0.9768 - val_loss: 0.0332 - val_accuracy: 0.973317s - loss: 0.0370 -\n",
      "Epoch 45/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0368 - accuracy: 0.9758 - val_loss: 0.0334 - val_accuracy: 0.9721 ETA: 31s - loss: 0.0372 - accur - ETA: 29s - ETA: 23s - loss: 0.036 - ETA: 19s - loss: 0.0369 - accuracy: 0.9 - ETA: 19s - loss:  - ETA: 14s - loss: 0.0367 - accu -  - ETA: 3s\n",
      "Epoch 46/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0355 - accuracy: 0.9765 - val_loss: 0.0334 - val_accuracy: 0.972524s - loss: 0.0338 -  - ETA: 21s - loss: 0.0345 - accurac - ETA: 20s - loss: 0.0340 - accur - ETA: 17s - loss: 0.0343 - acc - ETA: 15s - loss: 0.0349 - - ETA: 12s - loss: 0. - ETA: 9s - loss: 0 - ETA: 2s - loss: 0.0 - ETA: 0s - loss: 0.0354 - accuracy\n",
      "Epoch 47/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0357 - accuracy: 0.9763 - val_loss: 0.0330 - val_accuracy: 0.97090382 - accuracy: 0.974 - ETA: 41s - loss: 0.0384 - accura - ETA: 39s - loss: 0.0374 - accuracy: 0 - ETA: 39s - loss: 0 - ET - ETA: 27s - lo - ETA: 21s - loss: 0.0355 - accur - ETA: 19s - loss: 0.0355 - accuracy - ETA: 18s - loss: 0.0358 - accuracy:  - ETA: 1s - loss: 0.0360 - accu\n",
      "Epoch 48/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0362 - accuracy: 0.9751 - val_loss: 0.0330 - val_accuracy: 0.9721 40s - lo - ETA: 17s - loss: 0.0364 - accuracy - ETA: 16s - loss: 0.0371 -  - ETA: 7s - loss: - ETA: 1s - loss: 0.0359 - accu\n",
      "Epoch 49/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0343 - accuracy: 0.9784 - val_loss: 0.0330 - val_accuracy: 0.9717 - loss: 0.03 - ETA: 54s - loss: 0 - ETA: 49s - loss: 0.0289 - accur - ETA: 47s -  - ETA: 41s - loss: 0.0307 - accu - ETA: 39s - los - ETA:  - ETA: 19s - ETA: 12s - loss: 0.0348 - accuracy: 0. - ETA: 12s - loss: 0.0346 - accuracy: 0.978 - E - - ETA: \n",
      "Epoch 50/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9782 - val_loss: 0.0330 - val_accuracy: 0.9717 19s - loss: 0.0314 - acc - ETA: 17s - loss: 0. - ETA: 12s - loss: 0.0322 - accuracy: 0. - ETA: 12s - loss: 0.0328 - accuracy: 0.97 - ETA: 11s - loss: 0.0331 -  - ETA: 5s - loss: 0.0339 - ac\n",
      "Epoch 51/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9768 - val_loss: 0.0331 - val_accuracy: 0.9736\n",
      "Epoch 52/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9766 - val_loss: 0.0331 - val_accuracy: 0.9717A: 49s - loss:  - ETA: 45s - loss: 0.0396 - accuracy: 0.9 - ETA:  - ETA: 29s - loss:  - ETA: 24s - loss: 0 - ETA: 11s - los\n",
      "Epoch 53/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9762 - val_loss: 0.0331 - val_accuracy: 0.9717 - loss: 0.0360 - accuracy: 0.97 - ETA: 49s - loss: - ET - ETA: 36s - loss: 0.0366 - a - ETA: 34s - loss: 0.0361 -  - ETA: 7s - loss: 0.0 - ETA: 1s - loss: 0.036\n",
      "Epoch 54/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0363 - accuracy: 0.9763 - val_loss: 0.0332 - val_accuracy: 0.9717\n",
      "Epoch 55/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9764 - val_loss: 0.0332 - val_accuracy: 0.9717 0.0352 -  - ETA: 16s - loss - ETA: 11s - los\n",
      "Epoch 56/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0342 - accuracy: 0.9783 - val_loss: 0.0331 - val_accuracy: 0.9717: - ETA: 12s - loss: 0.0348 - ac - ETA: 5s - l - ETA: 3s\n",
      "Epoch 57/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9717\n",
      "Epoch 58/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9717\n",
      "Epoch 59/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0340 - accuracy: 0.9788 - val_loss: 0.0330 - val_accuracy: 0.9717\n",
      "Epoch 60/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0361 - accuracy: 0.9760 - val_loss: 0.0330 - val_accuracy: 0.9717\n",
      "Epoch 61/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9760 - val_loss: 0.0330 - val_accuracy: 0.971760 - - ETA: 35s - loss:  - ETA: 30s - loss: 0.0357 - accuracy - ETA: 29s - loss:  - ETA: 24s - loss: 0.0363 - accuracy: \n",
      "Epoch 62/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0352 - accuracy: 0.9770 - val_loss: 0.0330 - val_accuracy: 0.9717\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0357 - accuracy: 0.9760 - val_loss: 0.0330 - val_accuracy: 0.9717: 55s - loss: 0.0268 -  - ETA: 6s - - ETA: 3s - ETA: 0s - loss: 0.0358 - accuracy: 0.97\n",
      "Epoch 64/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9783 - val_loss: 0.0330 - val_accuracy: 0.9721\n",
      "Epoch 65/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 66/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0340 - accuracy: 0.9799 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 67/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0343 - accuracy: 0.9790 - val_loss: 0.0330 - val_accuracy: 0.9721oss: 0.0316 - accura - ETA: 43s - los - - ETA\n",
      "Epoch 68/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9771 - val_loss: 0.0330 - val_accuracy: 0.9721\n",
      "Epoch 69/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0355 - accuracy: 0.9777 - val_loss: 0.0330 - val_accuracy: 0.9721\n",
      "Epoch 70/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9791 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 71/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9777 - val_loss: 0.0330 - val_accuracy: 0.9721\n",
      "Epoch 72/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0355 - accuracy: 0.9762 - val_loss: 0.0330 - val_accuracy: 0.9721loss: 0.040 - ETA: 40s  - ETA: 33s - loss: 0.0375 - accu\n",
      "Epoch 73/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9769 - val_loss: 0.0330 - val_accuracy: 0.9721975 -  - ETA: 1s - loss: 0.034\n",
      "Epoch 74/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9773 - val_loss: 0.0330 - val_accuracy: 0.9721 0s - loss: 0.0346 - accuracy: 0.\n",
      "Epoch 75/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9775 - val_loss: 0.0330 - val_accuracy: 0.9721\n",
      "Epoch 76/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9785 - val_loss: 0.0330 - val_accuracy: 0.972121s - ETA: 15s - loss: 0.0345 - accurac - E\n",
      "Epoch 77/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9778 - val_loss: 0.0330 - val_accuracy: 0.9725354 - accurac\n",
      "Epoch 78/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9779 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 79/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9788 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 80/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0354 - accuracy: 0.9768 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 81/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0342 - accuracy: 0.9789 - val_loss: 0.0330 - val_accuracy: 0.9725ccuracy: 0 - ETA: 25s - loss: 0.0356 - accurac - E - ETA: 0s - loss: 0.0343 - accuracy\n",
      "Epoch 82/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0367 - accuracy: 0.9749 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 83/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9767 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 84/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9764 - val_loss: 0.0330 - val_accuracy: 0.97250.0337 - accuracy: - ETA: 47s - loss: 0.0343 -  - ETA: 44s  - ETA: \n",
      "Epoch 85/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9789 - val_loss: 0.0330 - val_accuracy: 0.9725 loss: 0.0267 - accur - ETA: 50s - loss: 0 - ETA: 7s\n",
      "Epoch 86/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9780 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 87/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0340 - accuracy: 0.9789 - val_loss: 0.0330 - val_accuracy: 0.9725: 25s - loss: 0.0312 - a - ET\n",
      "Epoch 88/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9769 - val_loss: 0.0330 - val_accuracy: 0.9725ETA: 42s - loss: 0.03 - ETA: \n",
      "Epoch 89/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9771 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 90/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9778 - val_loss: 0.0330 - val_accuracy: 0.9725A: 33s - - ETA: 6s - loss: 0.0350 - accuracy - ETA: 5s - loss: 0.0348 - ac - ETA: 4s - loss: 0.0351 -  - ETA: 2s - loss: 0.0350 - accuracy: 0.97 - ETA: 2s - los\n",
      "Epoch 91/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9769 - val_loss: 0.0330 - val_accuracy: 0.9725accuracy: 0 - ETA: 19s - loss: 0.0343 - accurac - ETA: 17s - loss: 0.0344 -\n",
      "Epoch 92/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9774 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 93/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0354 - accuracy: 0.9765 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 94/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0341 - accuracy: 0.9774 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 95/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0355 - accuracy: 0.9771 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 96/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0364 - accuracy: 0.9753 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 97/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9768 - val_loss: 0.0330 - val_accuracy: 0.972553s - ETA: 47s -  - ETA: 33s - loss - ETA: 28s - loss: 0.0339 - ac - ETA: 25s - loss: 0.0326 - ET\n",
      "Epoch 98/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0358 - accuracy: 0.9754 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 99/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9771 - val_loss: 0.0330 - val_accuracy: 0.9725 0. - ETA: 25s - loss: 0.0330 - ac\n",
      "Epoch 100/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9769 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 101/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0354 - accuracy: 0.9764 - val_loss: 0.0330 - val_accuracy: 0.97250355 -  - ETA: 20s - loss: 0.0351 - a - ETA: 18s - loss: 0 - ETA\n",
      "Epoch 102/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0336 - accuracy: 0.9779 - val_loss: 0.0330 - val_accuracy: 0.9725s - loss: 0.0329 \n",
      "Epoch 103/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9776 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 104/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9774 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 105/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0352 - accuracy: 0.9767 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 106/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0342 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9725- lo - ETA: 41s - loss: 0.0355 - accuracy: 0.97 - ETA - ETA: 33s - loss: 0.0370 - ac - ETA: 30 - ETA - ETA: 17s - loss: 0. - ETA: 12s - loss: 0.0357 - accurac - ETA: 11s - loss: - ETA: 8s - loss: 0.0348 - ac - ETA: 6s - los - - ETA: 0s - loss: 0.0342 - accuracy: 0.\n",
      "Epoch 107/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0342 - accuracy: 0.9788 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9755 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 109/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0359 - accuracy: 0.9774 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 110/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9773 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 111/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9779 - val_loss: 0.0330 - val_accuracy: 0.9725s - - ETA: - ETA: 10s - loss - ETA: 7s - loss: 0.0342 - accu - ETA: 2s - l\n",
      "Epoch 112/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 113/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9773 - val_loss: 0.0330 - val_accuracy: 0.9725s: 0.0344 - accuracy: - ETA: 45s - loss: 0.03 - ETA: 42s - loss: 0.0337 - accuracy: 0.97  - ETA: 25s - loss: 0.0322 - accura\n",
      "Epoch 114/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9761 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 115/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0360 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 116/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9758 - val_loss: 0.0330 - val_accuracy: 0.97257s - loss: 0.0371 - a - ETA: 45s - loss: 0.0355 -  - ETA: 42s - loss: 0.0361 - acc - ETA: 39s - los - ETA: 34s - loss:  - ETA: 29s - loss: 0.03 - ETA: 17s - loss: 0.0364 - \n",
      "Epoch 117/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0352 - accuracy: 0.9764 - val_loss: 0.0330 - val_accuracy: 0.9725 loss: 0.0353 - accura - ETA: 38s - loss: 0.0355 -  - ETA: 35s - loss: 0.0354 - accuracy: 0.97 - ETA: 34s - loss: 0.0 - ETA: - ETA: 23s - loss: 0.0356 - accuracy: 0.9 - ETA: 23s - loss: 0.0356 - accuracy: 0.97 -\n",
      "Epoch 118/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9777 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 119/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0352 - accuracy: 0.9763 - val_loss: 0.0330 - val_accuracy: 0.9725 - loss: 0.0346 - accu - ETA: 12s - loss: 0.034 - ETA: 9s - loss: 0.0349 - ac - ETA: 7s - - E - ETA: 1s - loss: 0.0347 - ac\n",
      "Epoch 120/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9777 - val_loss: 0.0330 - val_accuracy: 0.9725A: 47s - loss: 0.0347 - accura - ETA: 45s - loss: 0.032 - ETA: 4 - ETA: 18s - lo - ETA: 12\n",
      "Epoch 121/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9725s: 0.0343 - accura - ETA: 26s - loss: 0.0344 - accurac - ETA: 25s - loss: 0.0345 - ETA: 21s - loss: 0.0346 - acc - ETA: 19s - loss: 0.0\n",
      "Epoch 122/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9786 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 123/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0343 - accuracy: 0.9782 - val_loss: 0.0330 - val_accuracy: 0.9725- accuracy: 0. - ETA: 45s - loss: 0.038 - - ETA: 1s - loss: 0.0342 - accu\n",
      "Epoch 124/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0362 - accuracy: 0.9752 - val_loss: 0.0330 - val_accuracy: 0.9725TA: 1s - loss: 0.0365 - ac - ETA: 0s - loss: 0.0362 - accuracy: 0.97\n",
      "Epoch 125/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9788 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 126/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9779 - val_loss: 0.0330 - val_accuracy: 0.9725o\n",
      "Epoch 127/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9775 - val_loss: 0.0330 - val_accuracy: 0.9725- ETA: 44s - loss: \n",
      "Epoch 128/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9767 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 129/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0359 - accuracy: 0.9762 - val_loss: 0.0330 - val_accuracy: 0.9725 0.0378 - accuracy: 0.9 - ETA: 39s - loss: 0.0373 - accur - ETA: 37s - l - ETA: 15s - loss: 0.0354 - acc - ETA: 12s - loss: 0.0354 - accuracy:  - ETA: 2s - loss:\n",
      "Epoch 130/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9770 - val_loss: 0.0330 - val_accuracy: 0.9725348 - accuracy: 0.97 - ETA: 7s - loss: 0.0349 - accuracy:  - ETA: 2s -\n",
      "Epoch 131/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9771 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 132/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9781 - val_loss: 0.0330 - val_accuracy: 0.9725s - loss: 0.0359 - accuracy: 0. - ETA: 37s - loss:  - ETA: 0s - loss: 0.0352 - accuracy\n",
      "Epoch 133/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9781 - val_loss: 0.0330 - val_accuracy: 0.9725ss: 0.0318 - a - ETA: 35s - loss: 0.0332 - accuracy: 0 - ETA: 34s - l - ETA: 29s - loss: 0.0325 - accuracy: 0.981 - ETA: 28s - loss: 0.0324 - accuracy: - ETA: 2s - loss: 0\n",
      "Epoch 134/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0355 - accuracy: 0.9765 - val_loss: 0.0330 - val_accuracy: 0.9725loss: 0.0345 - accu - ETA: 8s - loss: 0.0346 - accuracy: 0.97 - ETA: 7s - loss: 0.0344 - ac - ETA: 6s - loss: 0 - ETA:  - ETA: 1s - loss: 0.0358 - accu\n",
      "Epoch 135/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.97250300 - a - ETA: 25s - loss: 0.0350 - accu - ETA: 4s - loss: 0.0348 - accu - ETA: 2s -\n",
      "Epoch 136/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9773 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 137/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9774 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 138/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9763 - val_loss: 0.0330 - val_accuracy: 0.9725.0352 - accuracy: 0.9 - ETA: 32s  - ETA: 5s - loss: - ETA: 3s\n",
      "Epoch 139/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0343 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.972549s - ETA: 42s - loss - ETA: 2s - loss: 0.0344 - accu - ETA: 1s - loss: 0.034\n",
      "Epoch 140/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9769 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 141/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 142/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9763 - val_loss: 0.0330 - val_accuracy: 0.9725: 42s - loss: 0.0333 - ac - E - ETA: 15s - loss: 0.0346 - accuracy: 0.97 - ETA: 14s - loss: 0.0347 - a - ETA: 12s -\n",
      "Epoch 143/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9785 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 144/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0342 - accuracy: 0.9786 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 145/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0362 - accuracy: 0.9758 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0343 - accuracy: 0.9776 - val_loss: 0.0330 - val_accuracy: 0.9725r - ETA: 43s - loss: 0.0325 - accuracy: 0 - ETA: 42s - loss: 0.0326 - accura - ETA: 40s - loss: 0.0332 - a - ETA: 37s - loss: 0.0334 - accuracy: 0.976 - ETA: 37s - loss: 0.0331  - ETA: 34s - loss: 0.0336 - ETA\n",
      "Epoch 147/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0342 - accuracy: 0.9780 - val_loss: 0.0330 - val_accuracy: 0.9725oss: 0.0351 - accuracy: - ETA: 22s - loss: 0.0353 - accura - ETA: 20s - \n",
      "Epoch 148/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0341 - accuracy: 0.9791 - val_loss: 0.0330 - val_accuracy: 0.9725T - ETA: 43s - loss: 0.03 - ETA: 39s -  - ETA: 0s - loss: 0.0342 - accura\n",
      "Epoch 149/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0357 - accuracy: 0.9759 - val_loss: 0.0330 - val_accuracy: 0.9725cura\n",
      "Epoch 150/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9778 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 151/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9768 - val_loss: 0.0330 - val_accuracy: 0.9725oss: 0.0370 -  -\n",
      "Epoch 152/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9780 - val_loss: 0.0330 - val_accuracy: 0.9725y\n",
      "Epoch 153/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0352 - accuracy: 0.9770 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 154/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9757 - val_loss: 0.0330 - val_accuracy: 0.9725accuracy: 0 - ETA: 42s - loss: 0.0355 - ac\n",
      "Epoch 155/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9767 - val_loss: 0.0330 - val_accuracy: 0.9725 0.0370 - ac - ETA: 19s - loss: 0.0367 - accuracy: 0.97 - ETA: 19s - loss: 0.0366 - ac - ETA: 0s - loss: 0.0351 - accuracy: 0.97 - ETA: 0s - loss: 0.0352 - accuracy\n",
      "Epoch 156/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.9725 - ETA: 24s - loss: 0.03 - ETA: 20s \n",
      "Epoch 157/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0358 - accuracy: 0.9765 - val_loss: 0.0330 - val_accuracy: 0.9725- ETA: 4s - loss: 0.0356 - accuracy: 0. -\n",
      "Epoch 158/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0360 - accuracy: 0.9763 - val_loss: 0.0330 - val_accuracy: 0.9725: 56s - loss: - ETA - ETA: 6s - loss: 0.0365 - accura - ETA: 1s - loss: 0.0359 - accu\n",
      "Epoch 159/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.9725ETA: 1s - loss: 0.0352 \n",
      "Epoch 160/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9774 - val_loss: 0.0330 - val_accuracy: 0.9725 accuracy: \n",
      "Epoch 161/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9783 - val_loss: 0.0330 - val_accuracy: 0.9725: 35s - loss: 0.0363 - accuracy: 0.9 - ETA: 35s - loss: - ETA: 30s - loss - ETA: 17s - loss: 0.0364 - accuracy: 0.977 - ETA: 16 - ETA: 1s - loss: 0.0355 - accura - ETA: 0s - loss: 0.0353 - accura\n",
      "Epoch 162/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9778 - val_loss: 0.0330 - val_accuracy: 0.9725s: 0.0318 - accuracy: 0.980 - ETA: 42s - - ETA: 36s - lo - ETA: 31  - ETA: 16s - loss: 0.0331 - a - ETA: 13s - loss: 0.0332 - accuracy: 0.97 - - ETA: 3s - loss: 0.0338 - accuracy: 0. - ETA: 3s - loss: 0.0338 - accuracy: 0. - ETA: 2s -\n",
      "Epoch 163/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.9725s - loss: 0.0349 - accuracy: \n",
      "Epoch 164/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9767 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 165/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0337 - accuracy: 0.9797 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 166/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0366 - accuracy: 0.9745 - val_loss: 0.0330 - val_accuracy: 0.9725- ETA: 18s - loss: 0.0372 - accurac - ETA: 4s - loss: 0.035 - ETA: 3s - - ETA: 0s - loss: 0.0367 - accuracy: 0.97\n",
      "Epoch 167/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9754 - val_loss: 0.0330 - val_accuracy: 0.9725uracy: 0.978 - ETA: 49s - loss: 0.0322 - accur - ETA: 47s - loss: 0.0311 - accu - ETA: 44s - loss: 0.0332 - accuracy: 0.977 - ETA: - ETA: 20s - loss: 0.0337 - accu - ETA: 18s - loss: 0.0335 - accu - ETA: 16s - loss: 0.0334 - ETA: 12s - loss: 0.0 - ETA: 9s - loss: 0.0343 -  - ETA: 7s - loss: 0.0344 - accuracy:  - E - ETA: 3s - loss: 0.0341 - accuracy:  - ETA: 3s - loss: 0.0341 - accuracy: 0. - ETA: 2s - l\n",
      "Epoch 168/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9761 - val_loss: 0.0330 - val_accuracy: 0.9725TA: 36s - loss: - ETA: 8s - loss: 0.0356 - ac - ETA: 2s - loss: 0.0348 - accuracy: 0. - ETA: 2s - los\n",
      "Epoch 169/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9768 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 170/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9766 - val_loss: 0.0330 - val_accuracy: 0.97250.0282 - - ETA: 48s - loss: 0.0 - ETA: 44s - loss: 0 - ETA: - ETA: 4s - loss: 0.0 - ETA: 2s - loss: 0.0346 - accuracy: 0.97 - ETA: 2s - loss:\n",
      "Epoch 171/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9767 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 172/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9751 - val_loss: 0.0330 - val_accuracy: 0.9725: 0. - ETA: 50s - lo - ETA: 45s - loss: 0.0325 - accuracy: 0 - ETA: 44s - lo - ETA: 38 - ETA - ETA: 0s - loss: 0.0345 - accura\n",
      "Epoch 173/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9768 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 174/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9778 - val_loss: 0.0330 - val_accuracy: 0.9725 - loss: 0.0289 - accur - ETA: 2s - loss: 0.0347 - accu - ETA: 1s - loss: 0.0350 \n",
      "Epoch 175/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9762 - val_loss: 0.0330 - val_accuracy: 0.9725s: - ETA: 34s - loss: - E - ETA: 3s - loss: 0.0358 - accura - ETA: 2s - los\n",
      "Epoch 176/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9774 - val_loss: 0.0330 - val_accuracy: 0.9725s - loss: 0 - ETA: 53s - loss:  - ETA: 40s - loss: 0.0312 -  - ETA: 6s - loss: 0.0352 - accuracy: 0. - ETA: 6s - loss: 0.0352 - accuracy - ETA: 1s - loss: 0.0344 \n",
      "Epoch 177/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0347 - accuracy: 0.9779 - val_loss: 0.0330 - val_accuracy: 0.9725A: 49s - loss: 0.0320 - ETA: 37s \n",
      "Epoch 178/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0345 - accuracy: 0.9773 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 179/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0339 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9725s - loss: 0.0 - ETA: 22s - loss: 0.0333 - ac - ETA: 19s - loss: 0.0327 - ETA: 16s - loss: 0 - ETA: 11s - loss: 0.0331 - ETA: 9s - loss: 0.0336 - accuracy - ETA: 4s - loss: 0.0334  - ETA: 2s - los\n",
      "Epoch 180/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9786 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0353 - accuracy: 0.9775 - val_loss: 0.0330 - val_accuracy: 0.9725- l - ETA: 34s - loss: 0.0328 - accu - ETA: 32s - loss: - ETA: 19s  - ETA: 12s - loss: 0.0355 - a - ETA: 10s - loss: 0.0354 - - ETA: 0s - loss: 0.0355 - accuracy: 0.\n",
      "Epoch 182/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0351 - accuracy: 0.9759 - val_loss: 0.0330 - val_accuracy: 0.9725loss: 0.0404 - accuracy: 0.9 - ETA: 56s - loss: 0.0450 - accuracy: 0 - ETA: 55s - loss: 0.04 - ETA: 52s - loss: 0.0344 - accuracy: 0.978 - ETA: 51s - loss: 0.0352 - accuracy - ETA: 50s - loss: 0.0350 - accuracy: 0.97 - ETA - ETA:  - ETA: 2s - loss: 0\n",
      "Epoch 183/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0343 - accuracy: 0.9769 - val_loss: 0.0330 - val_accuracy: 0.972556s - loss: 0.0348 - accurac - ETA: 55s - loss: 0.0396 - accur - ETA: 44s - loss: 0 - ETA: 40s - loss: 0.0331 - accurac - ETA: 38s - loss: 0.0325 - accuracy: 0. - ETA: 37s - loss: 0.0333 - accu - ETA:  - ETA: 28s - loss: 0.0347 - accuracy: 0 - ETA: 27s -  - ETA: 22s - loss: 0.0350 -  - ETA: 19s - loss: 0.0348 - accuracy: 0.9 - ETA: 18s - loss: 0.0348 -  - ETA: 15s  - ETA: 5s - loss: 0.0347 - \n",
      "Epoch 184/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9783 - val_loss: 0.0330 - val_accuracy: 0.97250 - E - E - ETA: 0s - loss: 0.0345 - accuracy: \n",
      "Epoch 185/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9759 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 186/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9773 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 187/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0352 - accuracy: 0.9773 - val_loss: 0.0330 - val_accuracy: 0.97259 -\n",
      "Epoch 188/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0338 - accuracy: 0.9797 - val_loss: 0.0330 - val_accuracy: 0.9725TA: 15s -  - ETA: 9s - loss: 0.0325 - accuracy: 0.9 - ETA: 9s - loss: 0.0326 - \n",
      "Epoch 189/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9784 - val_loss: 0.0330 - val_accuracy: 0.97250382  - ETA: 51s - loss: 0.0334 - a - ETA: 40s - loss: 0.0326 - accur - ETA: \n",
      "Epoch 190/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0350 - accuracy: 0.9771 - val_loss: 0.0330 - val_accuracy: 0.9725- ETA: 7s - loss: 0.035 - ETA: 6s - ETA: 2s -\n",
      "Epoch 191/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0346 - accuracy: 0.9783 - val_loss: 0.0330 - val_accuracy: 0.9725: 38s - loss: 0.0371 - accuracy:  - ETA: 36s - loss: 0.0367 - - ETA: 33s - loss: 0.0359 - accuracy: 0 - ETA: 16s - loss: 0.0348 - accuracy - ETA: 14s - loss: 0.0349 - accuracy: 0.9 - ETA: 14s - loss: 0.0348 - ETA: 10s - loss:  -\n",
      "Epoch 192/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9785 - val_loss: 0.0330 - val_accuracy: 0.9725\n",
      "Epoch 193/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9777 - val_loss: 0.0330 - val_accuracy: 0.9725acy: 0.\n",
      "Epoch 194/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0348 - accuracy: 0.9759 - val_loss: 0.0330 - val_accuracy: 0.97250338 - accura - ETA: 35s - - ETA: 29s - loss: 0.0353 - accu - ETA:  - ETA: 2s - loss: 0.0351 - accuracy:  - ETA: 2s - loss: 0.035 - ETA: 0s - loss: 0.0347 - accuracy: 0. - ETA: 0s - loss: 0.0348 - accuracy: 0.97\n",
      "Epoch 195/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0344 - accuracy: 0.9772 - val_loss: 0.0330 - val_accuracy: 0.9725 - ETA: 20s - loss: 0.0341 - accuracy: - ETA: 19s - loss: \n",
      "Epoch 196/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0342 - accuracy: 0.9793 - val_loss: 0.0330 - val_accuracy: 0.97250.0328 - accuracy: 0 - ETA: 30s - loss: 0.03 - ETA: 27s - loss - ETA\n",
      "Epoch 197/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0341 - accuracy: 0.9783 - val_loss: 0.0330 - val_accuracy: 0.9725 - - ETA: 46s - loss:  - ETA: 42s - loss: 0.035 - ETA: 38s - loss: 0.0355 - accurac - ETA: 36s - loss: 0.0356 - - ETA: 33s - loss: 0.0354 - accuracy: 0.9 - ETA: 33s - loss: 0.0356 - accura -  - ET - ETA: 16s - l - ETA - ETA: 6s - - ETA: 3s - loss: 0.0339 - accuracy: 0. - ETA: \n",
      "Epoch 198/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0356 - accuracy: 0.9755 - val_loss: 0.0330 - val_accuracy: 0.9725 52s -  - ETA: 22s - loss: 0.0359 - accuracy: 0.97 - ETA: 21s - loss: 0.0357 - accuracy: 0 - ETA: 20s -\n",
      "Epoch 199/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0349 - accuracy: 0.9761 - val_loss: 0.0330 - val_accuracy: 0.9725- loss: 0.0348 - accuracy:  - ETA: 26s - loss: 0.0357 \n",
      "Epoch 200/200\n",
      "10320/10320 [==============================] - 65s 6ms/sample - loss: 0.0341 - accuracy: 0.9791 - val_loss: 0.0330 - val_accuracy: 0.97253 - ETA: 32s  - ETA: 26s - loss: 0.0327 -  - ETA: 23s -  - ETA: 17s - loss: 0.0345 - - \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x,train_label_enc,validation_data=(val_x,val_label_enc), batch_size=32, epochs=1000, verbose=1,shuffle=True, callbacks = [reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = scalar.fit_transform(test_images_array.reshape(1950,196*196))\n",
    "test_image_array = test_image.reshape(1950,196,196,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950/1950 [==============================] - 5s 3ms/sample - loss: 5.6721 - accuracy: 0.43900s - loss: 4.9664 - ac\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_image_array,test_label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(test_image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_bool = np.argmax(y_predict,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_score,auc,recall_score,roc_curve,precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 67,   0,  36,  18,  29,   0],\n",
       "       [ 95,  58,   1,  42,  90,  14],\n",
       "       [ 55,  30, 322, 173,  20,   0],\n",
       "       [ 50,  41,  77, 409,  23,   0],\n",
       "       [  0,  24, 126,   0,   0,   0],\n",
       "       [  0,   0,   0, 150,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_image_label,y_predict_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44666666666666666"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67/(67+36+18+29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.412813675115717"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(test_image_label,y_predict_bool,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.438974358974359"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(test_image_label,y_predict_bool,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.45      0.32       150\n",
      "           1       0.38      0.19      0.26       300\n",
      "           2       0.57      0.54      0.55       600\n",
      "           3       0.52      0.68      0.59       600\n",
      "           4       0.00      0.00      0.00       150\n",
      "           5       0.00      0.00      0.00       150\n",
      "\n",
      "    accuracy                           0.44      1950\n",
      "   macro avg       0.29      0.31      0.29      1950\n",
      "weighted avg       0.41      0.44      0.42      1950\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_image_label,y_predict_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7238888888888889\n"
     ]
    }
   ],
   "source": [
    "fpr,tpr,thresholds = roc_curve(test_image_label,y_predict_bool,pos_label=5)\n",
    "print(auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 4, 3, 2, 1, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test\\00_5\n",
      "1\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test\\06_10\n",
      "2\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test\\11_15\n",
      "3\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test\\16_20\n",
      "4\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test\\21_25\n",
      "5\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test\\26_30\n"
     ]
    }
   ],
   "source": [
    "path = r'D:\\ILBS_14_8_21_Sanjeev\\ILBS_Clustered_Volumes\\test'\n",
    "images = []\n",
    "for index, name in enumerate(os.listdir(path)):\n",
    "    print(index)\n",
    "    folder = os.path.join(path, name)\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = Sequential()\n",
    "# model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "#                  input_shape=(196, 196,1)))\n",
    "# model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model1.add(Flatten())\n",
    "# model1.add(Dense(128, activation='relu'))\n",
    "# model1.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# model1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model1.fit(train_images_array,train_label_enc,validation_split=0.2, batch_size=32, epochs=150, verbose=1,shuffle=True, callbacks = [reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

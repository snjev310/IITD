{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout, BatchNormalization, MaxPool2D\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.listdir(r'D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image = []\n",
    "path = 'D:\\\\ILBS_14_8_21_Sanjeev\\\\ILBS_Cropped_Volumes'\n",
    "for folder in data_folder:\n",
    "    images = []\n",
    "    IMG_HEIGHT = IMG_WIDTH =196\n",
    "    for row in os.listdir(path+'\\\\'+folder):\n",
    "        fpath = path+'\\\\'+folder+'\\\\'+row\n",
    "        #print(fpath)\n",
    "        image= cv2.imread( fpath, cv2.IMREAD_GRAYSCALE)\n",
    "        image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "        max_val = np.max(image)\n",
    "        image=np.array(image)\n",
    "        image = image.astype('float32')\n",
    "       # image /= max_val\n",
    "        #image = np.expand_dims(image, axis=0)\n",
    "        images.append(image)\n",
    "    mean_vol = np.mean(images)\n",
    "    dev_vol = np.std(images)\n",
    "    images = (images-mean_vol)/dev_vol\n",
    "    #images_arr = \n",
    "    #print(folder)\n",
    "    #print(len(images), images[0].shape)\n",
    "    all_image.append(np.array(images).reshape([IMG_HEIGHT,IMG_WIDTH,150]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = np.array(all_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 196, 150)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = merged_data[0:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = merged_data[90::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 196, 150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196, 196, 150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.read_excel('D:/ILBS_14_8_21_Sanjeev/Work_to_be_Completed_ILBS/HVPG value with CT images.xlsx',engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>HVPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9109</td>\n",
       "      <td>2019-01-30</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19699</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31322</td>\n",
       "      <td>2019-02-15</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45341</td>\n",
       "      <td>2019-02-13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49565</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID       Date  HVPG\n",
       "0   9109 2019-01-30    21\n",
       "1  19699 2019-02-13    12\n",
       "2  31322 2019-02-15    17\n",
       "3  45341 2019-02-13    16\n",
       "4  49565 2019-02-06    10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for row in df_f.values.tolist():\n",
    "    #print(row[0])\n",
    "    if row[0]=='9109':\n",
    "        row[0]='00910'\n",
    "    else:\n",
    "        row[0]=row[0]\n",
    "    #print(row[0])\n",
    "    for folder in data_folder:\n",
    "        #print((row[0]))\n",
    "        if str(row[0])==str(folder):\n",
    "            labels.append([folder,row[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame(labels,columns=['path','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9109</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19699</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31322</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45341</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49565</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    path  label\n",
       "0   9109     21\n",
       "1  19699     12\n",
       "2  31322     17\n",
       "3  45341     16\n",
       "4  49565     10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.array(df_labels['label'][0:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.array(df_labels['label'][90::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 196, 196, 150)\n",
      "(90,)\n",
      "(9, 196, 196, 150)\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 196, 150)\n",
      "(90,)\n",
      "(196, 196, 150)\n",
      "(9,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0].shape)\n",
    "print(train_y.shape)\n",
    "print(test_x[0].shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = [np.array(x) for x in train_x]\n",
    "train_x_t = np.array(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 196, 196, 150, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_t = np.expand_dims(train_x_t,axis=4)\n",
    "train_x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = [np.array(y) for y in test_x]\n",
    "#test_x_t = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_x_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(train_y)\n",
    "#y_test = keras.utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MaxPool3D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c1ea90093651>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPool3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"same\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MaxPool3D' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(input_shape=(196,196,150,1),filters=32,kernel_size=(3,3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=64,kernel_size=(3,3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=128, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=128, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=256, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=256, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=256, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=512, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=512, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2)))\n",
    "model.add(Conv3D(filters=512, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=512, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv3D(filters=512, kernel_size=(3,3,2), padding=\"same\", activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool3D(pool_size=2,strides=(2,2,2),name='vgg16'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(512, activation='relu', name='fc1'))\n",
    "model2.add(Dropout(0.25))\n",
    "model.add(Dense(256, activation='relu', name='fc2'))\n",
    "model2.add(Dropout(0.25))\n",
    "model.add(Dense(28, activation='softmax', name='output'))\n",
    "\n",
    "model.compile(loss=keras.losses.mean_squared_error,\n",
    "              optimizer=keras.optimizers.Adadelta(0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                           patience=15, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_x_t,y_train,validation_split=0.1, batch_size=8, epochs=500, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = Sequential()\n",
    "# model1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "#                  input_shape=(256,256,150)))\n",
    "# model1.add(BatchNormalization())\n",
    "# model1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model1.add(BatchNormalization())\n",
    "# model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model1.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "# model1.add(BatchNormalization())\n",
    "# model1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model1.add(Flatten())\n",
    "# model1.add(Dense(256, activation='relu'))\n",
    "# model1.add(Dense(28, activation='softmax'))\n",
    "\n",
    "# model1.compile(loss=keras.losses.mean_squared_error,\n",
    "#               optimizer=keras.optimizers.Adadelta(0.001),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# model1.summary()\n",
    "\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                               patience=15, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model1.fit(train_x_t,y_train,validation_split=0.1, batch_size=8, epochs=500, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2 = Sequential()\n",
    "#model2.add(Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    " #                input_shape=(196,196,150)))\n",
    "#model1.add(BatchNormalization())\n",
    "#model2.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#model1.add(BatchNormalization())\n",
    "#model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model2.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "#model1.add(BatchNormalization())\n",
    "#model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model2.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "#model1.add(BatchNormalization())\n",
    "#model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model2.add(Flatten())\n",
    "#model2.add(Dense(256, activation='relu'))\n",
    "#model2.add(Dropout(0.25))\n",
    "#model2.add(Dense(128, activation='relu'))\n",
    "#model2.add(Dense(28, activation='softmax'))\n",
    "\n",
    "#model2.compile(loss=keras.losses.mean_squared_error,\n",
    "#              optimizer=keras.optimizers.Adadelta(0.001),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "#model2.summary()\n",
    "\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "#                             patience=8, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model2.fit(train_x_t,y_train,validation_split=0.1, batch_size=8, epochs=1000, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss', 'val_loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy', 'val_accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model_1.evaluate(test_x_t, y_test, verbose = 1) \n",
    "\n",
    "# print('Test loss:', score[0]) \n",
    "# print('Test accuracy:', score[1])\n",
    "score = model1.evaluate(test_x_t, y_test, verbose = 1) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

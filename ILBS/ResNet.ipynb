{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fc1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, MaxPool2D\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d0aa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc20ce1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,636,712\n",
      "Trainable params: 25,583,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet import ResNet50\n",
    "model = ResNet50()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f5901e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 7, 7, 1024)\n",
      "(None, 4)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten,Dropout,Dense,Activation,Input\n",
    "from keras.models import Model\n",
    "new_input = Input(shape=(224, 224, 1))\n",
    "model1 = ResNet50(include_top = False, input_shape=(112,112,3))\n",
    "layer = model1.get_layer('conv4_block6_out').output\n",
    "print(layer.shape)\n",
    "x = Flatten()(layer)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,activation = 'relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "x = Dense(256,activation = 'relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "out = Dense(4,activation = 'softmax')(x)\n",
    "model = Model(model1.input,out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d53bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 118, 118, 3)  0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 56, 56, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 56, 56, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 56, 56, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 58, 58, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 28, 28, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 28, 28, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 28, 28, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 28, 28, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 28, 28, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 28, 28, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 28, 28, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 28, 28, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 28, 28, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 28, 28, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 28, 28, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 28, 28, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 28, 28, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 28, 28, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 28, 28, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 28, 28, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 28, 28, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 28, 28, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 28, 28, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 28, 28, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 28, 28, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 28, 28, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 28, 28, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 14, 14, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 14, 14, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 14, 14, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 14, 14, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 14, 14, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 14, 14, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 14, 14, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 14, 14, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 14, 14, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 14, 14, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 14, 14, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 14, 14, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 14, 14, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 14, 14, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 14, 14, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 14, 14, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 14, 14, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 14, 14, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 14, 14, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 14, 14, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 14, 14, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 14, 14, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 14, 14, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 14, 14, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 7, 7, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 7, 7, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 7, 7, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 7, 7, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 7, 7, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 7, 7, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 7, 7, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 7, 7, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 7, 7, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 7, 7, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 50176)        0           conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50176)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          25690624    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            1028        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 34,412,164\n",
      "Trainable params: 34,381,572\n",
      "Non-trainable params: 30,592\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a84ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_maps(path):\n",
    "    images = []\n",
    "    for index, name in enumerate(os.listdir(path)):\n",
    "        folder = os.path.join(path, name)\n",
    "        for file_class in os.listdir(folder):\n",
    "            im_folder = os.path.join(folder, file_class)\n",
    "            for im in os.listdir(im_folder):\n",
    "                img = cv2.imread(os.path.join(im_folder, im))\n",
    "                #print(img.shape)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "                    img1 = cv2.resize(img, (112, 112))\n",
    "                    img = np.dstack((img1,img1,img1))\n",
    "                if img is not None:\n",
    "               #     img = (img-np.mean(img))/np.std(img)\n",
    "                    images.append((np.array(img), index)) \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eb09442",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_set = import_maps(r'C:\\Users\\AIIMS-IITD\\Desktop\\Sanjeev\\4_class_cluster_volume\\Train')\n",
    "image_test_set = import_maps(r'C:\\Users\\AIIMS-IITD\\Desktop\\Sanjeev\\4_class_cluster_volume\\Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f04c25c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17005"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335db2ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb6376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_all = [i[0] for i in image_train_set]\n",
    "train_images_array = np.array(train_images_all)\n",
    "#train_images_array=np.expand_dims(train_images_array,axis=3)\n",
    "train_image_label = [i[1] for i in image_train_set]\n",
    "train_image_label = np.array(train_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92a31fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_all = [i[0] for i in image_test_set]\n",
    "test_images_array = np.array(test_images_all)\n",
    "test_images_array=np.expand_dims(test_images_array,axis=3)\n",
    "test_image_label = [i[1] for i in image_test_set]\n",
    "test_image_label = np.array(test_image_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05075550",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler(copy=False)\n",
    "train_images = scalar.fit_transform(train_images_array.reshape(len(train_images_array), 112*112*3))\n",
    "train_images_array = train_images.reshape(len(train_images_array), 112,112, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1e82063",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = scalar.fit_transform(test_images_array.reshape(len(test_images_array),112*112*3))\n",
    "test_image_array = test_image.reshape(len(test_images_array),112,112,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6233dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, val_x, train_y, val_y = train_test_split(train_images_array,train_image_label,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e7b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "train_label_enc = enc.fit_transform(train_image_label.reshape(-1, 1)).toarray()\n",
    "#val_label_enc = enc.fit_transform(val_y.reshape(-1, 1)).toarray()\n",
    "test_label_enc = enc.fit_transform(test_image_label.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa6b83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer = keras.optimizers.SGD(0.001),metrics=['accuracy','AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6534d82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "518/518 [==============================] - 61s 67ms/step - loss: 0.9716 - accuracy: 0.6051 - auc: 0.8405 - val_loss: 4.6645 - val_accuracy: 0.2831 - val_auc: 0.5095ss: 1.8145 - accuracy: 0.3381 - ETA: 29s - loss: 1.7051 - accuracy: - ETA: 28s - loss: 1.6044 - accu - ETA: 26s - loss: 1.5132 - acc - ETA: 24s - loss: 1.4456 - accuracy: 0.4128 - auc: 0 - ETA: 24s - loss: 1.4318 - accuracy: 0.4173 - auc: 0. - ETA: 24s - loss: 1.4254 - accuracy: 0.4192 - auc - ETA: 23s - loss: 1.4094 - accuracy: 0. - ETA: 22s - loss: 1.3776 - accuracy: 0.4346 - auc:  - ETA: 22s - loss: 1.3671 - accuracy: 0.4379 - auc: 0 - ETA: 21s - loss: 1.3577 - accuracy: 0.4414 -  - ETA: 20s - loss: 1.3381 - accuracy: 0.4482 -  - ETA: 20s - loss: 1.3229 - accuracy: 0.4541 - auc: - ETA: 19s - loss: 1.3119 - accuracy: 0.4576 - auc - ETA: 19s - loss: 1.2996 - accuracy: 0.4628 - auc - ETA: 18s - loss: 1.2874 - accuracy: 0.4668 - auc: - ETA: 18s - loss: 1.2766 - accuracy: 0. - ETA: 16s - loss: 1.2530 - accuracy: 0.4826 - auc: 0.7 - ETA: 16s - loss: 1.2508 - accuracy: 0.4835 - - ETA: 16s - loss: 1.2381 - accuracy: 0.4882 - auc: - ETA: 15s - loss: 1.2260 - accuracy: 0.4921 - auc: - ETA: 15s - loss: 1.2187 - accuracy: 0.4956 - auc:  - ETA: 14s - loss: 1.2107 - accuracy: 0.4992 - auc:  - ETA: 14s - loss: 1.2014 - accuracy: 0.5028 - auc: 0 - ETA: 14s - loss: 1 - ETA: 11s - loss: 1.1501 - accuracy: 0.5285 - auc: 0.77 - ETA: 11s - loss: 1.1492 - accuracy: 0.5289 - auc: - ETA: 10s -  - ETA: 8s - loss: 1.1097 - accuracy: 0.5465 - - ETA: 8s - loss: 1.1035 - accuracy: 0.5489 - - ETA: 8s - loss: 1.0959 - accuracy: 0. - ETA: 7s - E - ETA: 2s - loss: 1.0104 - accuracy: 0.5886 - auc - ETA - ETA: 0s - loss: 0.9832 - accuracy: 0.6002 - auc: 0.83 - ETA: 0s - loss: 0.9828 - accuracy: 0.6004 - auc:  - ETA: 0s - loss: 0.9792 - accuracy: \n",
      "Epoch 2/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 0.2495 - accuracy: 0.9091 - auc: 0.9895 - val_loss: 1.8519 - val_accuracy: 0.4598 - val_auc: 0.7073 0. - ETA: 26s - loss: 0.4288 -  - ETA: 21s - loss: 0.3785 - - ETA: 19s - los - ETA: 16s - loss: 0.3430  - ETA: 14s - loss: - ETA: 8s - loss: 0 - ETA: 7s - - ETA: 6s - loss: 0.2795 - accuracy: 0.8983 - auc - ETA: 5s - loss: 0.2777 - accuracy: 0.8992 - auc: 0.98 - ETA: 5s - loss: 0.2775 - accuracy: 0.8993 - auc: 0.98 - ETA: 5s - loss: 0.2770 - accuracy: 0.89 - ETA: 5s - loss: 0.2748 - accuracy: 0.9003 - auc - ETA: 5s - loss: 0.2737 - accuracy - ETA: 4s - loss: 0.2701 - accuracy: 0.90 - ETA: 3s - loss: 0.2677 - accuracy:  - ETA: 3s - ETA: 1s - loss: 0.2 - ETA: 0s - loss: 0.2516 - accuracy: 0.9082 -\n",
      "Epoch 3/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 0.0620 - accuracy: 0.9802 - auc: 0.9993 - val_loss: 2.6434 - val_accuracy: 0.4264 - val_auc: 0.6780 0.1008 - accuracy: 0.9661 - - ETA: 28s - loss: 0.0984 - accuracy: 0.96 - ETA: 27s - loss: 0.1012 - accuracy - ETA: 26s - loss: 0.0910 - accuracy: 0.96 - ETA: 25s - loss: 0.0871 - accuracy: 0.9706 - a - ETA: 24s - loss: 0.0872 - accuracy: 0.9704 - auc: - ETA: 24s - loss: 0.0881 - accuracy: 0.9690 - a - ETA: 23s - loss: 0.0882 - accuracy: 0.9692 - auc: 0. - ETA: 23s - loss: 0.0876 - accuracy: 0.9695 - auc:  - ETA: 22s - loss: 0.0856 - accuracy: 0.9701 - auc: 0 - ETA: 22s - loss: 0.0853 - accuracy: 0.9700 - auc: 0 - ETA: 22s - loss: 0.0855 - a - ETA: 20s - loss: 0.0803 - accuracy: 0.9732 - auc: 0 - ETA: 19s - loss: 0.0797 - accuracy: 0.9734 -  - ETA: 19s - loss: 0.0794 - accuracy: 0.9733 - ETA: 18s - loss: 0.0796 - accuracy: 0.9731 - auc:  - ETA: 18s - loss: 0.0792 - accu - ETA: 16s - loss: 0.0769 - accuracy: 0. - ETA: 15s - loss: 0.0782 - accuracy: 0.9740 - auc: 0.99 - ETA: 15s - loss: 0.0779 - accuracy: 0.9741 - - ETA: 14s - loss: 0.0769 - accuracy: 0.9 - ETA: 13s - loss: 0.0749 - accuracy: 0.9755 - au - ETA: 12s - loss: 0.0740 - accuracy: 0.9756 - au - ETA: 12s - loss: 0.0736 - ac - ETA: 10s - loss: 0.0712 - accuracy: 0.9767 - ETA: 9s - loss: 0.0707 - accuracy: 0.9769 - auc:  - ETA: 9s - loss: 0.0704 - accuracy: 0.9770 - auc - ETA: 9s - loss: 0.0703 - accuracy: 0.9771 - auc - ETA: 8s - loss: 0.0697 -  - ETA: 8s - loss: 0.0684 - accuracy: 0.9779 - auc - ETA: 7s - loss: 0.068 - ETA: 6s - loss: 0.0672 - accuracy: 0. - ETA: 6s - loss: 0.0679 -  - ETA: 5s - loss: 0.0666 - accuracy: 0.9786 - ETA: 4s - loss: 0.0657 - accuracy: 0.9790 - auc:  - ETA: 4s - loss: 0.0 - ETA: 3s - loss: 0.0645 - accura - ETA: 2s - loss: 0.0640 - accuracy - ETA: 2s - loss: 0.0640 - accuracy: 0.9796 - auc: 0.99 - ETA: 1s - l - ETA: 0s - loss: 0.0623 - accuracy: 0.9801 -\n",
      "Epoch 4/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 0.0260 - accuracy: 0.9932 - auc: 0.9999 - val_loss: 3.0720 - val_accuracy: 0.4261 - val_auc: 0.6627 - accuracy: 0 - ETA: 28s - loss: 0.0232 - accuracy: - ETA: 26s - loss: 0.0290 - accuracy: 0.9938 - ETA: 25s - loss: 0.0299 - accuracy - ETA: 24s - loss: 0.0292 - accuracy: 0.9932 - au - ETA: 23s - loss: 0.0316 -  - ETA: 21s - loss: 0.0306 - accuracy: 0.9928 -  - ETA: 21s - loss - ETA: 18s - loss: 0.0293 - accuracy: 0.9929 - auc: 0.99 - ETA: 18s - loss: 0.0300 - accuracy: 0.99 - ETA: 17s - loss: 0.0304 - accuracy: 0.9926 - auc: - ETA: 16s - loss: 0.0303 - accuracy: 0.99 - ETA: 15s - loss: 0.0297 - accuracy: 0.9928 - a - ETA: 15s - loss: 0.0295 - accuracy - ETA: 13s - loss - ETA: 6s - loss: 0.0280 - accuracy: 0.9926 - auc:  - ETA: 6s - loss: 0.0279 - accuracy: 0.9926 - auc: 0.99 - ETA: 6s - loss: 0.0279 - accuracy: 0.9927 - a - ETA: 6s - loss: 0.0279 - accu - ETA: 3s - loss: 0.0270 - accuracy: 0.9929 - auc: 0. - ETA: 3s - l - ETA: 1s - loss: 0.0263 - accuracy: 0.99 - ETA: 1s - l\n",
      "Epoch 5/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 0.0144 - accuracy: 0.9963 - auc: 1.0000 - val_loss: 3.3537 - val_accuracy: 0.4249 - val_auc: 0.6560.0176 - acc - ETA: 28s - loss: 0.0163 - accuracy: 0.9955 - auc: 1.000 - ETA: 27s - loss: 0.0163 - accuracy: 0.9 - ETA: 26s - los - ETA: 24s - loss: 0.0138 - accuracy: 0.9972  - ETA: 23s - loss: 0.0147 - accuracy: 0.9973 - auc: 1.00 - ETA: 23s - loss: 0.0146 - accuracy: 0.997 - ETA: 22s - loss: 0.0171 - accuracy: 0.9961 - auc: 1.0 - ETA: 22s - loss: 0.0169 - accuracy: 0.9961 - auc: 1. - ETA: 22s - loss: 0.0170 - accuracy: 0.9960 - ETA: 21s - loss: 0.0165 - accuracy: 0.9962 - au - ETA: 20s - loss: 0.0164 - accuracy: 0.9964 - auc:  - ETA: 20s - loss: 0.0166 - accuracy: 0.9962 - - ETA: 19s - loss: 0.0164 - accuracy: 0.9963 - a - ETA: 18s - loss: 0.0163 - accuracy: 0.9962 - au - ETA: 18s - loss: 0.0163 - accuracy: 0.9962 - auc - ETA: 17s - loss: 0.0165 - accuracy: 0.9962 - au - ETA: 17s - loss: 0.0162 - accuracy: 0.9963  - ETA: 16s - loss: 0.0157 - accuracy: 0.9963 - auc: 1.000 - ETA: 16s - loss: 0.0157 - accuracy: 0.9963 - auc: 1 - ETA: 15s - loss: 0.0161 - accuracy: 0 - ETA: 14s - loss: 0.0155 - accuracy: 0.9963 - auc: 1.000 - ETA: - ETA: 11s - loss: 0.0158 - accuracy: 0.99 - ETA: 10s - loss:  - ETA: 6s - loss: 0.0150 - accuracy: 0.9962 - auc: 1.00 - ETA: 6s - loss: - ETA: 3s - loss: 0.014 - ETA: 2s - loss: 0.0146 - accuracy - ETA: 1s - loss: 0.014 - ETA: 0s - loss: 0.0145 - accuracy: 0.\n",
      "Epoch 6/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 0.0089 - accuracy: 0.9979 - auc: 1.0000 - val_loss: 3.5317 - val_accuracy: 0.4264 - val_auc: 0.6508- loss: 0.0112 - a - ETA: 27s - loss: 0.0102 - accuracy: 0.9965 - auc: 1.000 - ETA: 27s - loss: 0.0101 - accura - ETA: 26s - loss: 0.0099 - accuracy: 0.9977 - auc: 1.000 - ETA: 26s - loss: 0.0100 - accuracy: 0.9977 - auc: 1 - ETA: 25s - loss: 0.0101 - accuracy: 0.9975 -  - ETA: 25s - loss: 0.0095 - accuracy: 0.9978 - au - ETA: 24s - loss: 0.0090 - accuracy: 0. - ETA: 23s - loss: 0.0097 - accuracy: 0.9978 - auc: 1 - ETA: 22s - loss: 0.0095 - accuracy: 0.9979 - auc: 1.000 - ETA: 22s - loss: 0.0095 - accuracy: 0.9979 - a - ETA: 22s - loss: 0.0097 - accuracy: 0.9981 - auc: 1 - ETA: 21s - loss: 0.0097 - accuracy: 0.9981 - auc: 1. - ETA: 21s - loss: 0.0107 - accuracy: 0.9980 - ETA: 20s - loss: 0.0103 - accuracy: 0.9 - ETA: 19s - loss: 0.0098 - accuracy: 0.9983 - a - ETA: 19s - loss: 0.0099 - accuracy: 0.9981 - auc: 1.0 - ETA: 18s - loss: 0.0098 - accuracy: 0.9982 - a - ETA: 18s - loss: 0.0097 - accuracy: 0.99 - ETA: 17s - loss: 0.0097 - accuracy: 0.9 - ETA: 15s - loss: 0.0095 - accuracy: 0.9981 - auc: 1.0 - ETA: 15s - loss: 0.0094 - accuracy: 0.9982 - auc: 1. - ETA: 15s - loss: 0.0095 - accuracy: 0.9982 - auc: 1.0 - ETA: 15s - loss: 0.0094 - accuracy: 0.9982 - auc: - ETA: 14s - loss: 0.0092 - accuracy: 0.9983 - auc: 1 - ETA: 14s - loss: 0.0092 - accuracy: 0.9983 - auc: 1 - ETA: 14s - loss: 0.0092 - accuracy: 0.9983  - ETA: 13s - loss: 0.0089 - accuracy: 0.9984 - auc: 1.000 - ETA: 13s - loss:  - ETA: 10s - loss: 0.0090 - accuracy: 0.9983 - auc: 1 - ETA: 10s - loss: 0.0089 - accuracy: 0.9983 - auc: 1 - ETA: 10s - loss: 0.0088 - accuracy: 0.998 - ETA: 5s - loss: 0.009 - ETA: 2s - loss: 0.0090 - accu - ETA: 2s - loss: 0.0091 - accuracy: 0.9979 - a -\n",
      "Epoch 7/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0071 - accuracy: 0.9982 - auc: 1.0000 - val_loss: 3.8594 - val_accuracy: 0.4241 - val_auc: 0.6401curacy: 0 - ETA: 27s - loss: 0.0083 - - ETA: 25s - loss: 0.0089 - accuracy: 0.9980 - auc:  - ETA: 25s - loss: 0.0091 - accuracy:  - ETA: 23s - loss: 0.0090 - accuracy: 0.9977 - auc: 1 - ETA: 23s - loss: 0.0088 - accurac - ETA: 21s - loss: 0.0090 - accuracy: 0.9979 - auc: 1. - ETA: 21s - loss: 0.0088 - accuracy: 0.9980 - auc: 1.000 - ETA: 21s - loss: 0.0087 - accuracy: 0.9980 - - ETA: 21s - loss: 0.0087 - accuracy: 0.9980 - au - ETA: 20s - loss: 0.0085 - accurac - ETA: 18s - loss: 0.0079 - accuracy: 0.9983 - auc: 1.000 - ETA: 18s - loss: 0.0078 - accuracy: 0.9983 - a - ETA: 18s - loss: 0.0081 - acc - ETA: 16s - loss: 0.0078 - accuracy: 0.9985 - auc: - ETA: 16s - loss: 0.0077 - accuracy: 0.9985 - auc: 1.00 - ETA: 15s - loss: 0.0076 - accuracy:  - ETA: 14s - los - ETA: 11s - loss: 0.0078 - accuracy: 0.998 - ETA: 11s - loss: 0.0076 - accuracy: 0.9982 - auc:  - ETA: 10s - loss: 0.0075 - accuracy: 0.9983 - auc: 1.000 - ETA: 10s - loss: 0.0075 - accuracy: 0.9983 - auc: 1. - ETA: 10s - - ETA: 6s - loss: 0.0074 - accuracy: 0.9981 - auc - ETA: 6s - loss: 0.0077 - accuracy: 0.9979 - ETA: 5s - loss: 0.0077 - accuracy: 0.9979 - auc:  - ETA: 5s - loss: 0.0076 - accuracy:  - ETA: 5s - loss: 0 - ETA: 3s - loss: 0 - ETA: 0s - loss: 0.0072 - accuracy: 0.9981 - a - ETA: 0s - loss: 0.0072 - accuracy: 0.9982\n",
      "Epoch 8/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0064 - accuracy: 0.9986 - auc: 1.0000 - val_loss: 3.7522 - val_accuracy: 0.4261 - val_auc: 0.6582s - loss: 0.0052 - accuracy: 0.9991 - auc: 1.000 - ETA: 27s - loss: 0.0051 - accuracy: 0.9991 - ETA: 2 - ETA: 22s - loss: 0.0051 - accuracy: 0.9991 - auc: 1 - ETA: 22s - loss: 0.0050 - accuracy - ETA: 21s - loss: 0.0050 - accuracy: - ETA: 19s - loss: 0.0051 - accuracy: 0.9990 - auc: 1 - ETA: 19s - loss: 0.0053 - accuracy: 0.9989 - auc: 1.000 - ETA: 19s - loss: 0.0053 - accuracy: 0.9989 - auc: 1 - ETA: 19s - loss: 0.0054 - accuracy: 0.9987 - - ETA: 18s - loss: 0.0055 - accuracy: 0.9988 - auc: 1. - ETA - ETA: 14s - loss: 0.0068 - accuracy: - ETA: 13s - loss: 0.0067 - accuracy: 0.9985 - auc: 1.000 - ETA: 13s - loss: 0.0067 - accur - ETA: 11s - loss: 0.0064 - accuracy: 0.9986 - auc: - ETA: 11s - loss: 0.0064 - accuracy: 0.9985 - auc: 1. - ETA: 10s - loss: 0.0064 - accuracy: 0.9985 - auc: 1.0 - ETA: 6s - loss: - ETA: 3s - loss: 0.0066  - ETA: 0s - loss: 0.0062 - accuracy: 0.9986 - a\n",
      "Epoch 9/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 0.0045 - accuracy: 0.9990 - auc: 1.0000 - val_loss: 3.8913 - val_accuracy: 0.4303 - val_auc: 0.6502s: 0.0072 - accuracy: 0.9979 - ETA:  - ETA: 26s - loss: 0.0086 - accuracy: 0.9971 - auc: 1. - ETA: 26s - loss: 0.0085 - accuracy: - ETA: 21s - loss: 0.0072 - accuracy: 0.9978 - auc:  - ETA: 20s - loss: 0.0071 - accuracy: 0.9979 - auc: 1 - ETA: 20s - loss: 0.0070 - accuracy: 0 - ETA: 19s - loss: 0.0066 - accuracy: 0.9982 - ETA: 18s - loss: 0.0063 - accuracy: 0.9983 -  - ETA: 17s - loss: 0.0060 - accuracy: 0.9 - ETA: 16s - loss: 0.0058 - accuracy: 0.99 - ETA: 15s - loss: 0.0057 - accuracy: 0.9986 - auc: 1 - ETA: 15s - loss: 0.0056 - accuracy: 0.9986 - ETA: 14s - loss: 0.0054 - accuracy: 0.9987 - au - ETA: 13s - loss: 0.0053 - accuracy: 0.9987 - au - ETA: 13s - loss: 0.0053 - accuracy: 0.9987 - auc - ETA: 12s - loss: 0.0052 - accuracy: 0. - ETA: 11s - loss: 0.0050 - ETA: 9s - loss: 0.0048 - accura - ETA: 8s - loss: 0.0047 - accuracy: 0.9989 - ETA: 8s - loss: 0.0047 - accuracy - ETA: 7s - loss: 0.0047 - accuracy: 0.9990 - ETA: 7s - loss: 0.0046 - accuracy: 0.9990 - auc: 1.00 - ETA: 7s - loss: 0.0047 - accuracy: 0.9989 - auc:  - ETA: 7s - loss: 0.0047 - accuracy: 0.9989 - auc:  - ETA: 6s - loss: 0.0046 - accuracy: 0.99 - E - ETA: 4s - ETA: 3s - loss: 0.0046 - accuracy: 0.9990 - auc: 1.00 - ETA: 3s - loss: 0.0046 - accuracy: 0.9990 - auc: 1.00 - ETA: 2s - loss: 0.0046 - accuracy: 0.9990 - a - - ETA: 0s - loss: 0.0046 - accuracy - ETA: 0s - loss: 0.0045 - accuracy: 0.9990 - auc: 1.\n",
      "Epoch 10/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0041 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 4.0441 - val_accuracy: 0.4226 - val_auc: 0.6459 - loss: 9.6240e-04 - accuracy: 1.0000 - ETA: 29s - loss: 9.6423e-04 - accuracy:  - ETA: 27s - loss: 0.0012 - accuracy: 1.0 - ETA: 26s - loss: 0.0074 - accuracy: 0.9970 - auc:  - ETA: 26s - loss: 0.0091 - accuracy: 0.9964 - auc: 1.000 - ETA: 26s - loss: 0.0090 - accuracy: 0.9965 - auc - ETA: 25s - loss: 0.0082 - accuracy: 0.9969 - auc: 1.0 - ETA: 25s - loss: 0.0080 - accuracy: 0.9970 - auc - ETA: 25s - loss: 0.0088 -  - ETA: 23s - loss: 0.0074 - accuracy: 0.9977 - - ETA: 22s - loss: 0.0070 - a - ETA: 20s - loss: 0.0065 - accuracy: 0.9979 - auc: 1.000 - ETA: 20s - loss: 0.0065 - accuracy: 0.9979 - auc: 1 - ETA: 20s - loss: 0.0064 - accuracy:  - ETA: 18s - loss: 0.0061 - accuracy: 0.9980 - auc: 1.00 - ETA: 18s - loss: 0.0060 - accura - ETA: 17s - loss: 0.0059 - accuracy: 0.9 - ETA: 15s - loss: 0.0057 - accuracy: 0.9981 -  - ETA: 15s - loss: 0.0055  - ETA: 13s - loss - ETA: - ETA: 8s - loss: 0.0 - ETA: 7s - loss: 0.0046 - accu - ETA: 6s - loss: 0.0045 - accuracy: 0.9985 - auc:  - ETA: 6s - loss: 0.0045 - accuracy: 0.9985 - auc: 1. - ETA: 4s - loss: 0.0044 -  - ETA: 1s - loss: 0.0042 - accuracy:  - ETA: 1s - loss: 0.0\n",
      "Epoch 11/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0042 - accuracy: 0.9990 - auc: 1.0000 - val_loss: 4.2036 - val_accuracy: 0.4307 - val_auc: 0.6445 0.0019 - accuracy: 1.0000 - a - ETA: 25s - loss: 0.0059 - accurac - ETA: 24s - loss: 0.0049 - accuracy: 0.9992 - auc: 1. - ETA: 23s - loss: 0.0062 - accuracy: 0.9987 - auc - ETA: 23s - loss: 0.0059 - accuracy:  - ETA: - ETA: 18s - loss: 0.0048  - ETA: 16s - loss: 0 - ETA: 13s - loss: 0.0045 - accuracy: 0.9990 - E - ETA: 5s - loss: 0.0044 - accuracy: 0.99 - ETA: 3s - loss: 0.0043 - ac - ETA: 2s - loss: 0.0043 - accuracy: 0.9989 - a - ETA: 2s - loss: 0.0043 - accuracy: 0.9990 - auc: 1.00 - ETA: 2s - loss: 0 - ETA: 1s - loss: 0.0042 - accuracy: 0.9990 - auc: 1.00 - ETA: 0s - loss: 0.0042 \n",
      "Epoch 12/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0030 - accuracy: 0.9992 - auc: 1.0000 - val_loss: 4.2383 - val_accuracy: 0.4192 - val_auc: 0.6411 loss: 0.0024 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 0.0029 - accuracy: 1.0000 - auc - ETA: 29s - loss: 0.0026 - accuracy: 1.0000 - - ETA: 28s - loss: 0.0023 - accuracy: 1.0000 - auc:  - ETA: 28s - loss: 0.0021 - accuracy: 1.0000 - auc: 1.000 - ETA: 28s - loss: 0.0021 - accura - ETA: 26s - loss: 0.0024 - accuracy: 0.9996 - auc: 1 - ETA: 26s - loss: 0.0023 - accuracy: 0.9996 - auc: 1.0 - ETA: 26s - loss: 0.0022 - accuracy: 0.9996 - au - ETA: 25s - loss: 0.0023 - a - ETA: 23s - loss: 0.0028 - accuracy: 0.9995 - a - ETA: 23s - loss: 0.0029 - accuracy: 0.9995 - auc: 1.000 - ETA: 22s - loss: 0.0029 - accu - ETA: 21s - loss: 0.0026 - accuracy: 0.9996 - a - ETA: 20s - loss: 0.0025 - accuracy: 0.9 - ETA: 19s - loss: 0.0025 - accuracy: 0.9997 - auc:  - ETA: 19s - loss: 0.0025 - accuracy: 0.9997 - auc:  - ETA: 19s - loss: 0.0025 - accuracy:  - ETA: 17s - loss: 0.0026 - accuracy: 0.9996 - auc:  - ETA: 17s - loss: 0.0025 - accuracy: 0.9996 - au - ETA: 16s - loss: 0.0025 - accuracy: 0.9996 - auc: 1.000 - ETA: 16s - loss: 0.0025 - accuracy: 0.9996 - auc: 1.0 - ETA: 16s - loss: 0.0025 - a - ETA: 14s - loss: 0.0027 - accuracy: 0.9995 - auc - ETA: 14s - loss: 0.0026 - accuracy: 0.9996 - auc: 1. - ETA: 14s - loss: 0.0026 - accuracy: 0.9996 - auc: 1. - ETA: 13s - loss: 0.0026 - accuracy: 0.9996 - auc: 1.0 - ETA: 13s -  - ETA: 10s - loss: 0.0027 - accuracy: 0.9994 - auc: 1.00  - ETA: 6s - loss: - - ETA: 1s - loss: 0.0030 - accuracy: 0.99 - ETA: 0s - loss: 0.0030 - accuracy:  - ETA: 0s - loss: 0.0030 - accuracy: 0.9992 - auc\n",
      "Epoch 13/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0029 - accuracy: 0.9993 - auc: 1.0000 - val_loss: 4.2163 - val_accuracy: 0.4119 - val_auc: 0.642319 - accuracy: 0.9997 - auc - ETA: 24s - loss: 0.0019 - accuracy: 0.9997 - auc - ETA: 24 - ETA: 21s - loss: 0.0025 - accuracy:  - ETA: 19s - loss: 0.0028 - accuracy: 0.9993 - auc: 1 - ETA: 19s -  - ETA: 16s - loss: 0.0039 - accuracy: 0.9988 - auc: 1. - ETA: 16s - loss: 0.0039 - accuracy: 0.9989 - auc: 1.000 - ETA: 16s - loss: 0.0039 - accuracy: 0.9989 - auc: 1.000 - ETA: 16s - loss: 0.0039 - accuracy: 0.9989 - auc:  - ETA: 15s - loss: 0.003 - ETA: 13s - loss: 0.0034 - accuracy: 0.9990 - auc:  - ETA: 13s - loss: 0.0034 - accuracy: 0.9991 - auc: 1.000 - ETA: 13s - loss: 0.0034 - accuracy: 0.9991 - ETA: 12s - loss: 0.0034 - accuracy: 0.9991 - auc: 1 -  - ETA: 7s - loss: 0.0030  - ETA: 6s - loss: 0.0029 - accuracy: 0.9992 - auc:  - ETA: 6s - loss: 0.0029 - accuracy: 0.9993 - auc: 1. - ETA: 5s - loss: 0.0029 - accuracy: 0.9993 - a - ETA: 5s - loss: 0.0029 - accu - ETA: 4s - loss: 0.0029 - accura - ETA: 3s - loss: 0.0030 - accu - ETA: 3s - loss:\n",
      "Epoch 14/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0020 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 4.2603 - val_accuracy: 0.4142 - val_auc: 0.6414- ETA: 31s - loss: 5.8122e-04 - accuracy: 1.0000  - ETA: 30s - loss: 0.0011 - - ETA: 28s - loss: 0.0015 - accuracy: 1.0000 -  - ETA: 27s - loss: 0.0015 - accuracy:  - ETA: 26s - loss: 0.0015 - accuracy: 1.0000 - auc:  - ETA: 25s - loss: 0. - ETA: 19s - loss: 0.0016 - accuracy: 0.9998 -  - ETA: 18s - loss: 0.0017 - accuracy: 0.9998 - auc - ETA: 18s - loss: 0.0016  - ETA: 16s - loss: 0.0021 - accuracy: 0.9997 - auc: 1. - ETA: 15s - loss: 0.0021  - ETA: 13s - loss: 0.0019 - accuracy: 0.9998 - auc:  - ETA: 13s - loss: 0.0020 - accuracy: 0.9998 - auc: 1.00 - ETA: 13s - loss: 0.0020 - accuracy: 0.9998 - auc - ETA: 12s - loss: 0.0020 - accuracy: 0.9998 - auc: 1.0 - ETA: 12s - loss: 0.0021 - accuracy: 0.9998 - auc: - ETA: 12s - loss: 0.0020 - accuracy: 0.9998 - auc: 1.0 - ETA: 12s - loss: 0.0020 - accuracy: 0.9998 - auc: 1.0 - ETA: 11s - loss: 0.0020 - accuracy: 0.9998 - au - ETA: 11s - loss: 0.0020 - accuracy: 0.9998 - - ETA: 10s - loss: 0.0020 - accuracy: 0.9998 - auc: 1.00 - ETA: 10s - loss: 0.0021 - accuracy: 0.999 - ETA: 9s - loss: 0.0020  - - ETA: 4s - loss: 0.0020 - accuracy: 0.99 - ETA: 2s - loss: 0.0019 - accuracy: 0.99 - ETA: 1s - loss: 0.001 - ETA: 0s - loss: 0.0020 - accuracy: 0.9998 - auc: 1.00 - ETA: 0s - loss: 0.0020 - accuracy: 0.9998 - auc: 1. - ETA: 0s - loss: 0.0020 - accuracy: 0. - ETA: 0s - loss: 0.0020 - accuracy: 0.9997 - auc: 1.00\n",
      "Epoch 15/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0019 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 4.3228 - val_accuracy: 0.4138 - val_auc: 0.6372TA: 31s - loss: 4.4873e-04 - accuracy: 1.0000 - auc: 1 - ETA: 30s - loss: 8. - ETA: 27s - loss: 0. - ETA: 25s - loss: 0.0020 - accuracy:  - ETA: 23s - loss: 0.0018 - accuracy: 0.99 - ETA: 18s - loss: 0.0017 - accuracy: 0.9997 - auc: 1 - ETA: 18s - loss: 0.0018 - accuracy: 0.9996 - auc: 1.00 - ETA: 18s - loss: 0.0018 - accuracy: 0.9996 - auc: 1.00 - ETA: 18s - loss: 0.0018 - accuracy: 0.9996 - auc:  - ETA: 17s - loss: 0.0017 - accuracy: 0.9996 - au - ETA: 17s - loss: 0.0017 - accuracy: 0.9996 - auc: 1. - ETA: 16s - loss: 0.0017 - accuracy: 0.9996 - auc: 1. - ETA: 16s - loss:  - ETA: 14s - loss: 0.0018 - accuracy: 0.9996 - a - ETA: 13s - loss: 0.0018 - accuracy: 0.9996 - auc: 1.000 - ETA: 13s - loss: 0.0018 - accuracy: 0.9996 - auc: 1.000 - ETA: 13s - loss: 0.0018 - accuracy: 0.9996 - auc: 1 - ETA: 13s - loss: 0.0017 - accuracy: 0.9996 - auc: 1. - ETA: 12s - loss: 0.0017 - accura - ETA: 11s - loss: 0.0017 - accuracy: 0.9996 - auc: 1.0 - ETA: 10s - loss: 0.0017 - accuracy: 0.9996 - auc:  - ETA: 10s - loss: 0.0016 - accuracy: 0.9996 - auc - ETA: 9s - loss: 0.0016 - accuracy: 0.9996 - au - ETA: 9s - l - ETA: 8s - loss: 0.0016 - accuracy: 0.9997 - auc: 1.00 - ETA: 8s - loss: 0.0016 - accuracy - ETA: 7s - loss: 0.0016 - accuracy: 0.9997 - ETA: 6s - loss: 0.0016 - accu - ETA: 6s - loss: 0.0016 - accuracy: 0.9997 - a - ETA: 3s - loss: 0.0019 - accuracy:  - ETA: 3s - loss: 0.0019 - accuracy: 0.9997 - - ETA: 2s - loss: 0.0019 - accuracy: 0.9997 - ETA: 2s - loss: 0.0019 - accuracy: 0.9997 - a - ETA: 2s - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 16/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0025 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 4.4201 - val_accuracy: 0.4069 - val_auc: 0.6388- ETA: 32s - loss: 2.9558e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 31s - loss: 2.4666e-04 - accuracy: 1.000 - ETA: 30s - loss: 0.0013 - accuracy: 1.0000 - auc: - ETA: 29s - loss: 0.0013 - accuracy: 1.0000 - auc: 1 - ETA: 29s - loss: 0.0012 - a - ETA: 27s - loss: 0.0014 - accuracy: 0.9995 - a - ETA: 26s - loss: 0.0013 - accuracy: 0.9996 - auc: 1. - ETA: 26s - loss: 0.0012 - accuracy: 0.9996  - ETA: 25s - loss: 0.0011 - accuracy: 0.9997  - ETA: 24s - loss: 0.0013 - accuracy: 0.9997 - auc: 1.000 - ETA: 24s - loss: 0.0013 - accuracy: 0.9997 - auc - ETA: 24s - loss: 0.0013 - accuracy: 0.9997 - au - ETA: 23s - loss: 0.0014 - accuracy: 0.9998 - auc: - ETA: 23s - loss: 0.0013 - accuracy: 0.9998 - - ETA: 22s - loss: 0.0013 - accuracy: 0.9998 - auc:  - ETA: 21s - loss: 0.0013 - accuracy: 0.9998 - auc: 1.000 - ETA: 21s - loss: 0.0013 - accuracy: 0.9998  - ETA: 21s - loss: 0.0012 - accuracy:  - ETA: 19s - loss: 0.0013 - accura - ETA: 18s - loss: 0.0012 - accuracy: 0.9999 - au - ETA: 17s - loss: 0.0012 - accuracy: 0.9999 - auc: 1 - ETA: 17s - loss: 0.0011 - accuracy: 0.9999 - auc: 1. - ETA: 17s - loss: 0.0011 - accuracy: 0.9999 - auc: - ETA: 16s - loss: 0.0011 - accuracy: 0.9999 - auc: 1.00 - ETA: 16s - loss: 0.0011 - ETA: 14s - loss: 0.0012 - accuracy: 0.99 - ETA: 13s - loss: 0.0030 - accuracy - ETA: 12s - loss: 0.0029 - accuracy: 0.9992 - a - ETA: 11s - loss: 0.0029 - accuracy: 0.99 - ETA: 10s - loss: 0.0028 - accur - ETA: 9s - loss: 0.0027 - accuracy - ETA: 8s - loss: 0.0026 - accuracy: 0.99 - ETA: 8s - loss: 0.0026 - accuracy: 0.9993 - auc: 1.00 - ETA: 8s - loss: 0.0026 - accuracy: 0.9993 - auc: 1.00 - ETA: 8s - loss: 0.0026 - accuracy: 0.9993 - auc:  - ETA: 6s - loss: 0.0028 - accuracy\n",
      "Epoch 17/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0015 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.3402 - val_accuracy: 0.4119 - val_auc: 0.6439- loss: 0.0023 - accuracy: 0.99 - ETA: 26s - loss: 0.0035 - a - ETA: 24s - loss: 0.0026 - accuracy: 0.9991 - a - ETA: 24s - loss: 0.0023 - accuracy - ETA: 22s - loss: 0.0021 - accuracy: 0.9993 -  - ETA: 21s - loss: 0.0020 - accuracy: 0.9994 - auc: 1.000 - ETA:  - ETA: 18s - loss: 0.0018 - accuracy - ETA: 16s - loss: 0.0017 - accuracy: 0.9996 - auc: 1. - ETA: 16s - loss: 0.0017 - accuracy: 0.9996 - auc: 1.000 - ETA: 16s - loss: 0.0017 - accuracy: 0.9996 - auc: 1.000 - ETA: 16s - loss: 0.0017 - accuracy: 0.9996 - au - ETA: 16s - loss: 0.0017 - acc - ETA: 14s - loss: 0.0016 - accuracy: 0.9997 - auc: 1. - ETA: 14s - loss: 0.0017 - accuracy: 0.9997 - auc: - ETA: - ETA: 6s - loss: 0.0016 - accuracy: 0. - - ETA: 3s - loss: 0.0016 - accuracy: 0.9997 - auc: 1.00 - E\n",
      "Epoch 18/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0015 - accuracy: 0.9996 - auc: 1.0000 - val_loss: 4.7377 - val_accuracy: 0.4192 - val_auc: 0.6260s: 0.0017 - accuracy: 0.9996 - auc: 1.0 - ETA: 17s - loss: 0.0018 - accuracy: 0.9996 - auc:  - ETA: 17s - loss: 0.0017 - accuracy: 0.9996 - auc: 1.000 - ETA: 1 - ETA: 0s - loss: 0.0016 - accuracy: 0.99 - ETA: 0s - loss: 0.0015 - accuracy: 0.9996 - auc\n",
      "Epoch 19/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0018 - accuracy: 0.9996 - auc: 1.0000 - val_loss: 4.5393 - val_accuracy: 0.4172 - val_auc: 0.6345TA: 29s - loss: 5.9906e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 29s - loss: 5.9196e-04 - a - ETA: 27s - loss: 6.5597e-04 - accuracy: 1.0000 - auc: 1 - - ETA: 22s - loss: 0.001 - ETA: 20s - loss: 0.0034 - accuracy: 0.9991 - auc - ETA: 20s - loss:  - ETA: 17s - loss: 0.0029 - accuracy: 0.99 - ETA: 16s - loss: 0.0027 - accuracy: 0.9993 - auc: - ETA: 16s - loss: 0.0027 - accuracy: 0.9994 - auc: - ETA: 16s - loss: 0.0026 - accuracy: 0.99 - ETA: 14s - loss: 0.0025 - accuracy: 0.9994 - auc - ETA: 14s - loss: 0.0025 - accuracy: 0.9994 - auc: 1.00 - ETA: 14s - loss: 0.0025 - accuracy: 0. - ETA: 13s - loss: 0.0024 - accuracy: 0.9995 - auc: 1.000 - ETA: 13s - loss: 0.0024 - accuracy: 0.9995 - auc: 1.0 - ETA: 13s - loss: 0.0024 - accurac - ETA: 11s - loss: 0.0024 - accuracy: 0.9994 - auc: 1.00 - ETA: 11s - loss: 0.0023 - accuracy: 0.9994  - ETA: 8s - loss: 0.0021 - accu - ETA: 7s - loss: 0.0021 - accuracy: 0.9995 - - ETA: 6s - loss: 0.0020 - accura - ETA: 6s - loss: 0.0021 - accuracy: 0.9996 - - ETA: 5s - loss: 0.0 - ETA: 2s - ETA: 1s - loss: 0.0018 - accuracy: 0.99 - ETA: 0s - loss: 0.0018 - accuracy: \n",
      "Epoch 20/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.3061e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.3794 - val_accuracy: 0.4192 - val_auc: 0.6386s - loss: 4.4799e-04 - accuracy: - ETA: 28s - loss: 5.1639e-04 - accuracy: 1.000 - ETA: 27s - loss: 5.7735e-04 - accuracy: 1.0000 - a - ETA: 26s - loss: 5.6026e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 5.5379e-04 - accuracy: 1.0000 - a - ETA: 2 - ETA: 22s - loss: 6.6904e-04 - accuracy: 1.0000 - au - ETA: 21s - loss: 6.3838e-04 - accuracy: 1.0000 - auc - ETA: 21s - loss: 6.2529e-04 - accuracy: - ETA: 19s - loss: 6. - ETA: 17s - loss: 6.1278e-04 - a - ETA: 15s - loss: 6.1825e-04 - accuracy:  - ETA: 14s - loss: 6.2735e-04 - accuracy: 1 - ETA: 12s - loss: 6.2973e-04 - accuracy: 1.0000  - ETA: 11s - loss: 9.0830e-04 - accuracy: 0.9999 - a - ETA: 11s - loss: 8.9053e-04 - accuracy: 0.9999 - - ETA: 10s - loss:  - ETA: 6s - loss: 9.2613e-04 - accuracy: 0.9998 - auc - ETA: 6s - loss: 9.1851e-04 - accuracy: 0.9998 - auc:  - ETA: 6s - loss: 9.1530e-04 - accuracy: 0.9998 - - ETA: 6s - loss: 9.0578e-04 - accuracy: 0.99 - ETA: 5s - loss: 8.9157e-04 - accuracy: 0. - ETA: 3s - loss: 8.5812e-04 - accuracy: 0.9999 - a - ETA: 2s - loss: 8 - ETA: 1s - loss: 8.5690e-04 -  - ETA: 0s - loss: 8.4334e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 8.4236e-04 - accuracy: 0.9999 - auc: 1. - ETA: 0s - loss: 8.3979e-04 - accuracy: 0.\n",
      "Epoch 21/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0016 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 4.4007 - val_accuracy: 0.4203 - val_auc: 0.6446 ETA: 32s - loss: 2.6459e-04 - accuracy: 1.0000 - auc - ETA: 31s - loss: 0.0040 - accuracy: 0.9978 - ETA: 29s - loss: 0.0030 - accuracy: 0.99 - ETA: 28s - loss: 0.0020 - a - ETA: 26s - loss: 0.0016 - accuracy: 0.9996 - auc: 1.000 - ETA: 26s - loss: 0.0016 - accuracy: 0.9996 - auc: 1.00 - ETA: 26s  - ETA: 23s - loss: 0.0014 - accuracy: 0. - ETA: 22s - loss: 0.0013 - accuracy: 0.9996 - au - ETA: 21s - loss: 0.0013 - accur - ETA: 19s - loss: 0.0011 - accuracy: 0.9997 - a - ETA: 19s - loss - ETA: 16s - loss: 0.0018 - accuracy: 0.9995 - auc: - ETA: 16s - loss: 0.00 - ETA: 13s - loss: 0.0018 - accuracy: 0.9995 - auc:  - ETA: 13s - loss: 0.0017 - accuracy: 0.9995 - auc: 1.0 - ETA: 13s - l - ETA: 10s - loss: 0.00 - ETA: 8s - los - ETA: 7s - l - ETA: 6s - loss: 0.0015  - ETA: 4s - loss: 0.0015 - accuracy - ETA: 4s - loss: 0.0016 - accuracy:  - ETA: 3s - loss: 0.0016 - accuracy: 0.9995 - auc: 1.00 - ETA: 3s - loss: 0.0016 - ac - ETA: 2s - loss: 0 - ETA: 1s - loss:\n",
      "Epoch 22/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0015 - accuracy: 0.9996 - auc: 1.0000 - val_loss: 4.2905 - val_accuracy: 0.4249 - val_auc: 0.6436 - loss: 4.2595e-04 - accuracy: 1.0000 - ETA: 29s - loss: 3.5631e- - ETA: 26s - loss: 5.3 - ETA: 24s - loss: 0.0036 - accur - ETA: 22s - lo - ETA: 20s - loss: 0.0 - ETA: 18s - loss: - ETA: 15s - loss: 0.0020 - accuracy: 0.99 - ETA: 14s - loss: 0.0019 - accuracy: 0 - ETA: 13s - loss: 0.0018 - accuracy: 0.9996 - a - ETA: 12s - loss: 0.0017 - accuracy: 0.9996 - auc - ETA: 11s - loss: 0.0017 - accuracy: 0.9996 - auc: 1 - ETA: 11s - loss: 0.0017 - accuracy: 0 - ETA: 10s - loss: 0.0017 - accuracy: 0.9996 - auc: 1. - ETA: 10s - loss: 0.0017 - accuracy: 0.9996 - auc: 1.000 - ETA: 10s - loss: 0.0017 - accuracy: 0.9 - ETA: 9s - loss: 0.001 - ETA: 2s - loss: 0.0015 - accu - ETA: 1s - loss: 0.0015 - accuracy: 0.9997 - auc - ETA: 1s - loss: 0.0015 - accura - ETA: 0s - loss: 0.0015 - accuracy: 0.9996 - auc: 1. - ETA: 0s - loss: 0.0015 - accuracy: 0.9996 - auc - ETA: 0s - loss: 0.0015 - accuracy: 0.9996 - auc: 1.00 - ETA: 0s - loss: 0.0015 - accuracy: 0.9996 - auc: 1.00\n",
      "Epoch 23/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0013 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.3939 - val_accuracy: 0.4249 - val_auc: 0.6464 26s - loss: 9.1944e-04 - accuracy: 1.0000 - a - ETA: 25s - loss: 9.1000e-04 - accuracy: - ETA: 24s - loss: 0.0015 - ETA: 22s - loss: 0.0013 - accuracy: 0.9998  - ETA: 21s - loss: 0.0012 - accuracy: 0.99 - ETA: 20s - loss: 0.0012 - accuracy: 0. - ETA: 19s - loss: 0.0011 - accuracy: 0.9998  - ETA: 18s - loss: 0.0010 -  - ETA: 16s - loss: 9.9777e-04 - accuracy: 0.99 - ETA: 15s - loss: 9.4841e-04 - a - ETA: 13s - loss: 0.0011 - accuracy: 0. - ETA: 12s - loss: 0.0011 - accur - ETA: 10s - loss: 0.0011 - accuracy: 0.9998 - auc: 1.000 - ETA: 10s - loss: 0.0011 - accuracy: 0.9998 - auc: 1.0 - ETA: 10s - loss: 0.0011 - accuracy: 0.9998 - auc: 1.000 - ETA: 10s - loss: 0.0011 - accura - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.0010 - accuracy: 0.9998 - a - ETA: 8s - loss: 0.0011 - accuracy: 0.9998 - auc - ETA - ETA: 4s - loss: 0.0011 - accuracy: 0.9998 - auc: 1.00 - ETA: 4s - loss: 0.0011 - accuracy: 0.99 - ETA: 3s - loss: 0.0011 - accuracy: 0.9998 - ETA: 0s - loss: 0.0013 - accuracy: 0. - ETA: 0s - loss: 0.0013 - accuracy: 0.9998 -\n",
      "Epoch 24/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0013 - accuracy: 0.9996 - auc: 1.0000 - val_loss: 4.7680 - val_accuracy: 0.4142 - val_auc: 0.627030s - loss: 0.0049 - accuracy: 0. - ETA: 29s - loss: 0.0025 - accuracy: 0.9991 - auc: 1.000 - ETA: 29s - loss: 0.0024 - - ETA: 27s - loss: 0.0024 - accuracy: 0.9 - ETA: 26s - loss: 0.0020 - accuracy: 0.9993 - a - ETA: 25s - loss: 0.0019 - accuracy: 0.9993 - au - ETA: 24s - loss: 0.0017 - acc - ETA: 23s - loss:  - ETA: 20s - loss: 0.0013 - accur - ETA: 18s - loss: 0.0014 - accuracy: - ETA: 17s - loss: 0.0013 - accuracy: 0.9996 - auc - ETA: 16s - loss: 0.0012 - accuracy: 0.9996 - auc: 1.0 - ETA: 16s - loss: 0.0012 - accuracy: 0.9 - ETA: 15s - loss: 0.0012 - accuracy: 0.9995 - ETA: 14s - loss: 0.0012 - accuracy: 0.99 - ETA: 13s - loss: 0.0011 - accura - ETA: 11s - loss: 0.0011 - accuracy: 0.9996 -  - ETA: 11s - loss: 0.0010 - accuracy: 0.9996 - au - ETA: 10s - loss: 0.0010 - accuracy: 0.9996 -  - ETA: 6s - loss: 9.1253e-04 - accuracy: 0.9997 - auc - ETA: 5s - loss: 9.1926e-0 - ETA: 4s - loss: 0.0011 - accuracy: 0.9996 - auc: 1.00 - ETA: 4s - loss: 0.0011 - accuracy: 0.9996 - auc: 1. - ETA: 4s - loss: 0.0011 - ac - ETA:  - ETA: 1s - loss: 0.0013 - accuracy: 0.9996 - auc: 1. - ETA: 1s - loss: 0.0013 - ac - ETA: 0s - loss: 0.0013 \n",
      "Epoch 25/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0012 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.6193 - val_accuracy: 0.4169 - val_auc: 0.6359uracy: 1.00 - ETA: 18s - loss: 0.0019 - accuracy: 0.9996 - auc: 1. - ETA: 17s - loss: 0.0018 - accuracy: 0.9996 - auc: 1. - ETA: 17s - loss: 0.0018 - accur - ETA: 16s - loss: 0.0017 - accuracy: - ETA: 14s - loss: 0.0016 - accurac - ETA: 13s - loss: 0.0015 - accuracy: 0. - ETA: 11s - loss: 0.0015 - accuracy: 0.9997 - a - ETA: 11s - loss: 0.0014 - accu - ETA: 9s - loss: 0.0013 - accuracy - ETA: 9s - loss: 0.0013 - accuracy: 0.9997 - auc:  - ETA: 8s - loss: 0.0013 - accuracy: 0.9997 - a - ETA: 8s - loss: 0.0013 - accuracy: 0.9998 - auc:  - ETA: 6s - loss: 0.0013 \n",
      "Epoch 26/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0012 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.6403 - val_accuracy: 0.4126 - val_auc: 0.6416: 1.0000 - auc: 1.00 - ETA: 26s - loss: 7.0076e-04 - accu - ETA: 24s - loss: 5.9780e-04 - accuracy: 1.0000  - ETA: 23s - loss: 5.5681e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 23s - loss: 5.5087e-04 - accuracy: 1.0000 -  - ETA: 22s - loss: 5.6441e-04 - a - ETA: 21s - loss: 4.9681e-04 - accuracy: 1.0000 - auc - ETA: 20s - loss: 4.7950e-04 - accuracy - ETA: 15s - loss: 0.0016 - ETA: 13s - loss: 0.0017 - accuracy: 0. - ETA: 11s - loss: 0.0016 - accuracy: 0.9998  - ETA: 11s - - ETA: 5s - loss: 0.0012 - accuracy: 0.9999 - - ETA: 4s - loss: 0.0 - ETA: 3s - loss: 0.0012 -  - ETA: 2s - loss: 0.001 -\n",
      "Epoch 27/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.8643e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.6071 - val_accuracy: 0.4264 - val_auc: 0.6389 26s - loss: 7.5669e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 7.4890e-04 - accura - ETA: 24s - loss: 6.5958e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 6.5839e-04 - accuracy: 1.0000 - a - ETA: 24s - loss: 6.7060e-04 - accuracy: 1.0000 - auc - ETA: 23s - loss: 6.4832e-04 - accuracy: 1.0000 - auc: 1. - ETA: 23s - loss: 6.9290e-04 - a - ETA: 21s - loss: 6.3212e-04 - - ETA: 19s - loss: 6.6868e-04 - ETA: 13s - loss: 7.2980e-04 - accuracy: 0.9999  - ETA: 12s - loss: 7.2571e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 12s - loss: 7.3009e-04 - accuracy: 0.9999 - auc: 1. - ETA: 12s - loss: 7.2947e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 12s - loss: 7.2731e-0 - ETA: 9s - loss: 8.9976e-04 - accuracy: 0.9997 - auc - ETA: 9s - loss: 8.9384e-04 - accu - ETA: 6s - loss: 8.6085e-0 - ETA: 5s - loss: 8.3965e-04 - accuracy - ETA: 4s - loss: 8.3832e-04 - accuracy: 0. - ETA: 4s - l - ETA: 0s - loss: 7.9449e-04 - accuracy: 0.\n",
      "Epoch 28/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.9101e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.9126 - val_accuracy: 0.4226 - val_auc: 0.6292- loss: 1.5795e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 1.6337e-04 - accuracy: 1. - ETA: 29s - loss: 1. - ETA: 26s - loss: 2.2539e-04 - acc - ETA: 24s - loss: 3.0442e-04 - accuracy: 1.0000 - auc: - ETA: 24s - loss: 2.8 - ETA: 21s - loss: 4.5251e-04 - accuracy: 0.999 - ETA: 20s - loss: 5.4197e-04 - accuracy - ETA: 19s - loss: 5.0869 - ETA: 17s - loss: 4.7477e-04 - accuracy: 0.9999 - auc: 1 - ETA: 16s - loss: 4.9239e-04 - ac - ETA: 14s - loss: 4.7671e-04 - ETA: 9s - loss: 4.7022e-04 - accuracy: 0.99 - ETA: 8s - loss: 4.6083e-04 - ac - ETA: 7s - loss: 4.4937e-04  - ETA: 4s - loss: 4.5319e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 4s - loss: 4.5301e-04 - accuracy: 0.9999 - auc:  - ETA: 4s - l - ETA: 3s - loss: 6 - ETA: 1s - loss: 5.9464e-04 - accuracy: 0. - ETA: 1s - loss: 5.8779e-0\n",
      "Epoch 29/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0012 - accuracy: 0.9996 - auc: 1.0000 - val_loss: 4.6321 - val_accuracy: 0.4261 - val_auc: 0.6449 ETA: 25s - loss: 0.0037 - accuracy: 0.9982 - auc: 1.0 - ETA: 24s - loss: 0.0036 - accuracy: 0.9982 - au - ETA: 24s - loss: 0.0034 - accuracy: 0.9984 -  - ETA: 23s - loss: 0.0031 - accuracy: 0.9 - ETA: 22 - ETA: 19s - loss: 0.0022 - accuracy: 0 - ETA: 18s - loss: 0.0020 - accuracy: 0.9991 - au - ETA: 17s - loss: 0.0019 - a - ETA: 15s - loss: 0.0017 - accuracy: 0.9993  - ETA: 14s - loss: 0.0017 - accuracy: 0. - ETA: 13s - loss: 0.0016 - accuracy: 0.9994 - auc: 1 - ETA: 13s - loss: 0.0016 - accurac - ETA: 11s - loss: 0.001 - ETA: 7s - loss: 0.0 - ETA: 6s - loss: 0.0013 - accuracy: 0.9995 - auc: 1.00 - ETA: 6s - loss: 0.0013 - accuracy: 0.99 - ETA: 6s - loss: 0.0013 - accuracy: 0.9995 - ETA: 5s - loss: 0.0013 - accuracy: 0.9996 - auc: 1.00 - ETA: 5s - loss: 0.0013 - accuracy: 0. - ETA: 5s - loss: 0.0013 - accuracy: 0.9996 - auc - ETA: 4s - l - ETA: 1s - loss: 0.0012 - accuracy: 0.9996 - auc: 1. - ETA: 1s - loss: 0.0012 - accuracy: 0.9996 - - ETA: 1s - loss: - ETA: 0s - loss: 0.0012 - accuracy: 0.9996 - auc: 1.00\n",
      "Epoch 30/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 0.0013 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 4.6156 - val_accuracy: 0.4180 - val_auc: 0.6367 - loss: 5.1297e-04 - accurac - ETA: 25s - loss: 4.6203e-04 - accuracy: 1.0000 - auc - ETA: 25s - loss: 4.4222e-04 - accuracy: 1 - ETA: 23s - loss: 3.9014e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 23s - loss: 3.8726e-04 - accur - ETA: 21s - loss: 0.0 - ETA: 19s - loss: 0.0019  - ETA: 17s - loss: 0.0021 -  - ETA: 15s - loss: 0.0019 - accuracy: 0.9990 - auc - ETA: 15s - loss: 0.0018 - acc - ETA: 13s - loss: 0.0017 - accu - ETA: 0s - loss: 0.0013 - accuracy:  - ETA: 0s - loss: 0.0013 - accuracy: 0.9995 - auc: \n",
      "Epoch 31/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.5219e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.5850 - val_accuracy: 0.4234 - val_auc: 0.6422.9544e-04 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 2.7419e-04 - accur - ETA: 27s - loss: 3.1057e-04 - accuracy: 1.0000 - auc: - ETA: 26s - loss: 3.0491e-04 - accuracy: 1.0000 - auc: 1 - ETA: 26s - loss: 0.0014 - accuracy: 0.9996 - auc: 1.0000 - ETA: 26s - loss: - ETA: 23s - loss: 9.7868e-04 - accuracy: 0.9998 - - ETA: 23s - loss: 9.3496e-04 - accuracy:  - ETA: 21s - loss: 8.6516e-04 - accuracy: 0.9998 - auc: 1. - ETA: 21s - loss: 0.0011 - accuracy: 0.9996 - ETA: 20s - loss: 0.0012 - accuracy: 0.9995 - auc: 1.00 - ETA: 20s - loss: 0.0012 - accuracy: 0.9995 - auc: 1.000 - ETA: 20s - loss: 0.0012 - accuracy: 0.99 - ETA: 19s - loss: 0.0012 - accuracy:  - ETA: 18s - loss: 0.0013 - accuracy: 0.9994 - auc: 1.00 - ETA: 18s - loss: - ETA: 15s - loss: 0.0012 - accuracy: 0.9995 - auc: 1.000 - ETA - ETA: 11s - loss: 0.0011 - accuracy: 0.9996 - a - ETA: 11s - loss: 0.0010 - accuracy: 0.9996 - - ETA: 10s - loss: 0.0010 - accu - ETA: 9s - loss: 9.8078e - ETA: 8s - loss: 9.4535e-0 - ETA: 3s - loss: 8.1628e-04 - accuracy: 0.9997 - auc: 1. - ETA: 3s - loss: 8.1289e-04 - accuracy: 0.99 - ETA: 2s - ETA: 1s - loss: 7.6969e-04 - accura - ETA: 0s - loss: 7.5679e-04 - accuracy: 0.9998 - auc: \n",
      "Epoch 32/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.3822e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.8153 - val_accuracy: 0.4241 - val_auc: 0.6361s: 2.7928e- - ETA: 27s - loss: 8.2025e-04 - accuracy: 0.9995  - ETA: 2 - ETA: 23s - loss: 7.0395e-04 - accuracy - ETA: 21s - loss: 7.2779e-04 - accuracy: 0.9998 - auc - ETA: 21s - loss: 7.042 - ETA: 19s - loss: 6.6685e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 18s - loss: 6.6379e-04 - accuracy: 0.9998 - auc: - ETA: 18s - loss: 6.4610e-04 - accuracy: 0.9999 - auc - ETA: 18s - loss: 6.2681e-04 - accuracy: 0.9 - ETA: 16s - loss: 6.0365e-04 - accuracy: 0.9999 - au - ETA: 16s - loss: 5.8528e-04 - accuracy: 0. - ETA: 15s - loss: 5.6013e-04 - accuracy: 0 - ETA: 13s - loss - ETA: 8s - loss: 8.8029e-0 - ETA: 7s - loss: 8.4870e-04 - accura - ETA - ETA: 5s - loss: 8.0003e-04 - accuracy: 0.99 - ETA: 4s - loss: 7.8697e-04 - accuracy: 0. - ETA: 3s - loss: - ETA: 2s - loss: 7.7687e-04 - accu - ETA: 1s -\n",
      "Epoch 33/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.6396e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.6040 - val_accuracy: 0.4146 - val_auc: 0.6413: 30s - loss: 1.0054e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 9.8427e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 9.4694e-05 - accuracy: 1.0000 - - ETA: 29s - loss: 2.2416e-04 - - E - ETA:  - ETA: 0s - loss: 5.6441e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 5.5851e-04 - accuracy: 0.9999 - auc:  - ETA: 0s - loss: 5.5661e-04 - accuracy: 0.9999 -\n",
      "Epoch 34/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.4985e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.7844 - val_accuracy: 0.4092 - val_auc: 0.6362- loss: 3.7260e-04 - acc - ETA: 27s - loss: 0.0018 - accuracy: 0.9995 - auc: 1.00 - ETA: 27s - loss: 0 - ETA: 25s - loss: 0.0 - ETA: 19s - loss: 9.6317e-04 - accuracy: 0.9998 - auc: - ETA: 18s - loss: 9.5178e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 18s - loss: 9.4783e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 18s - loss: 9.4158e-04 - accuracy: 0. - ETA: 17s - loss: 8.9325e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 17s - loss: 8.8944e-04 - accuracy: 0.99 - ETA: 16s - loss: 8.9472e-04 - accuracy: 0.999 - ETA: 15s - loss: 8.4926e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 15s - loss: 8.4700e-04 - accur - ETA: 13s - loss: 7.9968e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 13 - ETA: 10s - loss: 7.7487e-04 - accuracy: 0.9999 - au - ETA: 9s - loss: 7.617 - ETA: 8s - l - ETA: 7s - loss: 6.9552e-04 - accu - ETA: 2s - loss: 6.8174e-04 -  - ETA: 1s - loss: 6.6628e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 6.6243e-04 - accuracy: 0.9999 - auc - ETA: 0s - loss: 6.5829e-04 - accuracy: 0.9999\n",
      "Epoch 35/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.8132e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.7982 - val_accuracy: 0.4188 - val_auc: 0.6418TA: 22s - loss: 9.2300e-04 - accuracy:  - ETA: 20s - loss: 8.2579e-04 - accuracy: 0.9 - ETA: 19s - loss: 7.5609e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 19s - loss: 7.4867e-04 - accuracy: 0.9998 -  - ETA: 18s - loss: 7.2204e-04 - accuracy: 0 - ETA: 17s - loss: 6.8152e-04 - accuracy: 0.9999 - a - ETA: 16s - loss: 6.7407 - ETA: 14s - loss: 6.6279e-04 - accuracy: 0.9999 - auc: 1 - ETA: 14s - loss: 6.5380e-04 - accuracy: 0.99 - ETA: 13s - loss: 6.2582e-04 - accuracy: 0.9999 - auc: 1 - ETA: 12s - loss: 6.1758e-04 - accuracy: 0.9999 - a - E - ETA: 1s - loss: 4.9362e-04 - accuracy: 0.9999 - auc: 1. - ETA: 1s - loss: 4.9228e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 4.8664e-04 - accura - ETA: 0s - loss: 4.7847e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 36/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.9566e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.6726 - val_accuracy: 0.4161 - val_auc: 0.6391TA: 30s - loss: 1.0493e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 1.0116e-04 - accuracy: 1.0000 - - ETA: 29s - loss: 3.8738e-04 - accuracy: 1.0000 - a - ETA: 28s - loss: 5.1293e-04 - accuracy: 1.0000 - - ETA: 27s - loss: 4.5457e-04 - accuracy: 1.0000 - - ETA: 27s - loss: 4.3064e-04 - ETA: 25s - loss: 3.6591e-04 - accuracy: 1.0 - ETA: 24s - loss: 4.7017e-04 - accuracy: 1.0 - ETA: 22s - loss: 4.3204e-04 - accuracy: 1.0000 - a - ETA: 22s - loss: 4.0641e-04 - accuracy: 1.0000 -  - ETA: 21s - loss: 4.0024e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 3.9362e-04 - accuracy - ETA: 20s -  - ETA: 12s - loss: 6.4057e-04 - ac - ETA: 10s - ETA: 8s - loss: 5.7293e-04 - accuracy:  - ETA: 6s - - ETA: 0s - loss: 5.5718e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 5.5610e-04 - accuracy\n",
      "Epoch 37/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 9.4680e-04 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 4.7762 - val_accuracy: 0.4195 - val_auc: 0.6430 0.9994 - auc: 1. - ETA: 27s - loss: 9.6433e-04 - accura - ETA: 26s - loss: 7.6184e-04 - accuracy: 0.9996 - auc: 1.000 - ETA: 26s - loss: 7.5242e-04 - accuracy: 0.9996 - - ETA: 25s - loss: 6.5891e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 25s - loss: 6.5400e-04 - accuracy: 0.9997 - auc - ETA: 25s - loss: 6.0969e-04 - accuracy: 0.9997 - auc: - ETA: 24s - loss: 5.8559e-04 - accuracy: 0. - ETA: 23s - loss: 5.1062e-04 - accuracy: 0.9998 - - ETA: 22s - loss: 4.8552e-04 - accuracy: 0.9998 - auc: 1.00 - ETA:  - ETA: 19s - loss: 0.0019 - accuracy: 0.9994 - auc: 0.9 - ETA: 19s - loss: 0.0019 - accuracy: 0.9994 - ETA: 18s - loss: 0.0018 - accuracy: - ETA: 13s - loss: 0.0013 - accuracy: 0.9 - ETA: 12s - loss: 0.0013 - accuracy: 0 - ETA: 10s - loss: 0.0012 - accuracy: 0.9 - ETA: 9s - loss: 0.001 - ETA: 8s - loss: 0.0011 -  - - ETA: 0s - loss: 9.5579e-04 - accuracy: 0.9997 -\n",
      "Epoch 38/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.2391e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.7349 - val_accuracy: 0.4184 - val_auc: 0.6406: 23s - loss: 6.1014e-04 - accuracy:  - ETA: 22s - loss: 7.0481e-04 - accuracy: 0.9998 - auc - ETA: 21s - loss: 6.9395e-04 - accuracy: 0.9998 - a - ETA: 21s - loss: 6.5973e-04 - accuracy: 0.999 - ETA: 20s - loss: 6.3127e-04 - accu - ETA: 18s - loss: 5.7725e-04 - accuracy: 0.9999 - auc: - ETA: 18s - loss: 5.8412e-04 - accuracy: 0.9999 - - ETA: 17s - loss: 5.6099e-04 - accuracy: 0.9 - ETA: 16s - loss: 6.1183e-04 - accuracy: 0.9999 - auc: - ETA: 15s - loss: 5.9560e-04 - accu - ETA: 14s - loss: 5.5356e-04 - accuracy: 0.9999 - auc: - ETA: 13s - loss: 5.4297e-04 -  - ETA: 11s - loss: 5.0257e-04 - accuracy: 0.9999  - ETA: 10s - - ETA: 8s - ETA: 6s - loss: 4.3151e-04 - accuracy: 0.9999 - a - ETA: 4s - loss: 4.1724e-04 - accuracy: 0.99 -\n",
      "Epoch 39/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 4.0597e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.0684 - val_accuracy: 0.4192 - val_auc: 0.6299- loss: 1.4398e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 29s - l - ETA: 26s - loss: 3.3535e-04 - accuracy: 1 - ETA: 25s - loss: 2.9652e-04 - accuracy: 1.00 - ETA: 24s - loss: 2.8020e-04  - ETA: 22s - loss: 2.9236e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 22s - loss: 2.8970e-04 - accuracy: 1.0000 - - ETA: 21s - loss: 2.8575e-04 - accuracy: 1.0000 - auc:  - ETA: 21s - loss: 2.8117e-04 - accuracy: 1. - ETA: 20s - loss: 2.9729e- - ETA: 18s - loss: 3.3647e-04 - accuracy: 1.0000 - auc - ETA: 17s - loss: 3.4072e-04 - accuracy: 1.00 - ETA: 6s - loss: 3.0850e-04 - accuracy: 1.0000 - ETA:  - ETA: 2s - loss: 4.3115e-04 - accuracy: 0.9999 - a - ETA: 0s - loss: 4.0902e-04 - accuracy: 0.9999 - auc\n",
      "Epoch 40/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.4662e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.8569 - val_accuracy: 0.4142 - val_auc: 0.6333A: 30s - loss: 3.2887e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 3.0435e-04 - accuracy: 1.0000  - ETA: 29s - loss: 2.2871e-04 - - ETA: 27s - loss: 1.9234e-04 - accuracy: 1.0 - ETA: 26s - loss: 2.0632e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 2.0410e-0 - ETA: 23s - loss: 1.7730e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: - ETA: 20s - loss: 2.2190e-04 - accuracy: 1 - ETA: 18s - loss: 2.1861e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 2.1743e-04 - accuracy: - ETA: 17s - loss: 3.2995e-04 - accuracy: 0 - ETA: 16s - loss: 3.1548e-04 - accurac - ETA: 14s - loss: 3.0263e-04 - accuracy: 0.9999 - a - ETA: 14s - loss: 3.0457e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 14s - loss: 3.0189e-04 - accuracy: 0.9999 - auc: - ETA: 13s - loss: 2.9942e-04 - accuracy: 0.9999 - auc: 1. - ETA: 13s - loss: 2 - ETA: 10s - loss: - ETA: 9s - loss: 2.9988e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 8s - loss: 2.9961e-04 - accuracy: 0.99 - ETA: 8s - loss: 2.9502e-04 - accu - ETA:  - ETA: 5s - loss: 6.9663e-04 - ac - ETA: 4s - loss: 6.7215e-04 - accuracy - ETA: 4s - loss: 6.6002e-04 - accuracy: 0.9999 - auc - ETA: 3s - loss: 6.5472e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 3s - loss: 6.5335e-04 - accuracy: 0.9999 - auc: 1. - ETA: 3s - loss: 6.5021e-04 -  - ETA: 2s - loss: 6.3593e-04 - accuracy: 0.9999 - a - ETA - ETA: 0s - loss: 6.6037e-04 - accuracy: 0.9999 - ETA: 0s - loss: 6.5292e-04 - accuracy: 0.9999 -\n",
      "Epoch 41/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.0096e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.9091 - val_accuracy: 0.4153 - val_auc: 0.6379curacy: 0. - ETA: 26s - loss: 9.7166e-04 - accuracy: - ETA:  - ETA: 21s - loss: 7.7483e-04 - accu - ETA: 19s - loss: 6.9365e-04 - accuracy: 0.9997 - auc - ETA: 19s - loss: 6.8084e-04 -  - ETA: 17s - loss: 6.1756e-04 - accuracy: 0.9997 - auc: 1 - ETA: 16s - loss: 6.0549e-04 - accuracy: 0.9997 - auc: 1.00 - ETA: 16s - ETA: 13s - loss: 5.1109e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 13s - lo\n",
      "Epoch 42/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.2129e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.1340 - val_accuracy: 0.4138 - val_auc: 0.63114 - accuracy: - ETA: 22s - loss: 7.04 - ETA: 19s - loss: 6.3509e-04 - accuracy: 0.9997 - auc: 1. - ETA: 19s - loss: 6.3239e-04 - accuracy: 0.9997 - auc: 1.0 - ETA: 19s - loss: 6.2318e-04 - accuracy: 0.9997 - auc:  - ETA: 19s - loss: 6.0771e-04 - accuracy: 0.999 - ETA: 18s - loss: 5.6901e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 18s - loss: 5.6760e-04 - accuracy: 0.9997 - auc: 1. - ETA: 17s - loss: 5.5792e-04 - accuracy: 0.9997 - auc: 1 - ETA: 17s - loss: 5.4669e-04 - accuracy:  - ETA: 16s - loss: 5.2006e-04 - accura - ETA: 14s - loss: 4.9149e-04 - accuracy: 0.9998 - auc:  - ETA: 14s - loss: 4.8744e-04 - accuracy: 0.9998 -  - ETA: 13s - loss: 4.7552e-04 - accuracy: 0.9998 - ETA: 12s - loss: 4.8062e-04 - accuracy: 0.9998 - ETA: 12s - loss: 7.6403e-04 - accuracy: 0.9996 - auc: 1.000 - ETA: 11s - loss: 7.6311e-04  - ETA: 7s - loss: 7.4169e-04 - accuracy: 0.9997 - ETA: 7s - loss: 7.3354e-04 - accuracy: 0.9997 - auc: 1. - ETA: 7s - loss: 7.3001e-04 - accuracy: 0.9997 - auc:  - ETA: 7s - loss: 7.2583e-04 - ac - ETA: 6s - loss: 7.0795e-04 - accuracy: 0.9997 - auc: 1. - ETA: 6s - loss: 7.0462e-04 - accuracy: 0.99 - ETA: 5s - loss: 6.9202e-04  - ETA: 0s - loss: 6.1022e-04 - accuracy: 0.9998 - a\n",
      "Epoch 43/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.0350e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.8381 - val_accuracy: 0.4230 - val_auc: 0.64190032 - accuracy: 0.9 - ETA: 24s - loss: 0.0026 - accuracy: 0.9995 - auc: 0. - ETA: 23s - loss: 0.0 - ETA: 21s - loss: 0.0020 - accuracy: 0.9996 - auc - ETA: 20s - loss: 0.00 - ETA: 18s - loss: 0.0016 - accuracy: 0.9997 - auc: 0.999 - ETA: 18s - loss: 0.0016 - accuracy: 0.9997 - - ETA: 17s - loss: 0.0015 - a - ETA: - ETA: 12s -  - ETA: 10s - loss: 0.0010 - accuracy: 0.9998 -  - ETA: 9s - loss: 0.0010 - accuracy: 0.9998 - auc: 1. - ETA: 9s - loss: 0.0010 - accuracy: 0.9998 - - ETA: 7s - loss: 9.4296e-04 - accuracy:  - ETA: 6s - loss: 9.2195e-04 - accuracy: 0.99 - ETA: 5s - loss: 9.1783e-04 - accuracy: 0.99 - ETA: 5s - loss: 9.0506e-04 - accuracy: 0.9999 - a - ETA: 4s - loss: 9.0945e-04 - accuracy: 0.9999 - auc:  - ETA: 4s - loss: - ETA: 3s - loss: 8.6212e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 3s - loss: 8.603\n",
      "Epoch 44/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.0418e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 4.9040 - val_accuracy: 0.4176 - val_auc: 0.6369021 - accuracy: 0.9992 - auc: 1.000 - ETA: 26s - loss: 0.0020 - accuracy: 0.9992 - auc:  - E - ETA: 22s - loss: 0.0012 - accuracy: 0.9996 - au - ETA: 21s - loss: 0.0 - ETA: 15s - loss: 8.2262e-04 - accuracy: 0. - ETA: 14s - loss: 8.3267e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 14s - loss: 8.2720e-04 - accuracy: 0.9998 - auc: - ETA: 13s - loss: 9.0263e-04 - accuracy: 0.9997 - auc: 1. - ETA: 13s - loss: 8.9101e-0 - ETA: 11s - loss: 8.6495e-04 - accuracy - ETA: 10s - loss: 9.0825e-04 - accurac - ETA: 5s - loss: - ETA: 4s - loss: 7.6698e-04 - accuracy: 0.9997 - ETA: 3s - loss: 7.5702e - ETA: 2s - loss: 7.4962e-04 - accuracy: 0.9997 - auc: 1.00 - ETA: 2s - loss: 7.4846e-04 - accura - ETA: 1s - loss: 7.3364e-04 - accuracy: 0.9997 - auc: 1.00 - ETA: 1s - l\n",
      "Epoch 45/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.2143e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 4.9209 - val_accuracy: 0.4161 - val_auc: 0.6367- - ETA: 25s - loss: 2.1001e-04 - accuracy: 1.0000 - au - ETA: 25s - loss: 1.9687 - ETA: 23s - loss: 0.0013 - accuracy: 0 - ETA: 21s - loss: 0.0013 - accuracy: 0.9996 - auc: 1.000 - ETA - ETA: 18s - loss: 9.7820e-04 - accuracy: 0.9997 - auc: 1.00 - ETA: 18s - loss: 9.7061e-04 - accuracy: 0.9997 - auc: 1.00 - ETA: 17s - loss: 9.6274e- - ETA: 15s - loss: 8.5130e-04 - accuracy: 0.9998 - auc: 1 - ETA: 15s - loss: 8.3419e-04 - accuracy: 0.9998 - auc: - ETA: 14s - loss: 8.2044e-04 - accuracy: 0.9998 - au - ETA: 14s - loss: 7.9861e-04 - accuracy: 0.9998 - auc: 1 - ETA: 14s - loss: 7.8696e-04 - accuracy: 0.99 - ETA: 13s - loss: 7.6609e-04 - accuracy: 0 - ETA: 11s - loss: 7.2042e-04 - accuracy: 0.9 - ETA: 10s - loss: 7.2943 - ETA: 9s - loss: 6.9257e-04 - accura - ETA: 8s - loss: 6.7841e-04 - accuracy: 0.99 - ETA: 7s - loss: 6.6603e-04 - accuracy - ETA: 7s - loss: 6.5006e-04 - accuracy: 0.99 - ETA: 6s - loss: 6.3941e - ETA: 5s - loss: 6.1339e-04 - accuracy: 0.99 - ETA: 2s - l - ETA: 1s - loss: 5.4114e-04 - accuracy:  - ETA: 0s - loss: 5.3155e-04 - accuracy: 0.9999 - auc:  - ETA: 0s - loss: 5.2852e-04 - accuracy: 0.9999 - ETA: 0s - loss: 5.2172e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 46/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.5459e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.0094 - val_accuracy: 0.4134 - val_auc: 0.6360 accuracy: 1.0000 -  - ETA: 21s - loss: 3.6942e-04 - accur - ETA: 20s - loss: 3.3398e-04 - accuracy: 1.0000 - a - ETA: 19s - loss: 3.2340e-04 - accuracy: 1.0000 - - ETA: 18s - loss: 3.0936e-04 - accuracy: 1.0000 - auc:  - ETA: 18s - loss: 3.4086e-04 - accura - ETA: 16s - loss: 3.9994e-04 - a - ETA: 14s - loss: 3.9576e-04 - accuracy: 1.0000 - auc: - ETA: 14s - loss: 3.8735e-04 - accuracy: 1.0000 - auc: 1 - ETA: 14s - loss: 3.8527e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 3.8395e- - ETA: 11s - loss: 3.9634e-04 - accuracy: 1.0000 - auc - ETA: 11s - loss: 4.0302e- - ETA: 9s - loss: 3.8 - ETA: 1s - l - ETA: 0s - loss: 4.5846e-04 - accuracy: 0.9999 - a\n",
      "Epoch 47/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.0047e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.1419 - val_accuracy: 0.4096 - val_auc: 0.63385189e-04 - accuracy: 1.0000 - - ETA: 28s - loss: 2.0832e-04 - - ETA: 26s - loss: 2.9540e-04 -  - ETA: 24s - loss: 2.3854e-04 - accuracy: 1.0000 - au - ETA: 24s - loss: 4.0503e-04 - accu - ETA: 22s - loss: 4.8093e-04 - accuracy: 1. - ETA: 21s - loss: 4.5400e-04 - accuracy: 1 - ETA: 20s - - ETA: 17s - loss: 3.6226e-04 - accuracy: 1.0000 -  - ETA: 16s - loss: 3.4796e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 3.4609e-04 - accura - ETA: 14s - loss: 3.2623e-04 - accuracy: 1.0000 - au - ETA: 14s - loss: 3.1538e-04 - accuracy:  - ETA: 13s - loss: 6.2438e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 12s - loss: 6.2041e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 12s - loss: 6.165\n",
      "Epoch 48/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.4952e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2791 - val_accuracy: 0.4050 - val_auc: 0.6284ccur - ETA:  - ETA: 15s - loss: 6.1858e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 15s - loss: 6.1256e-04 - accuracy: 0. - ETA: 8s - loss: 5.4334e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 8s - loss: 5.4192e-04 - accuracy:  - ETA: 7s - loss: 5.2572e-04  - ETA: 6s - - ETA: 4s - loss: 4.8292e-04 - accuracy: 0. - ETA: 4s - loss: 4.7740e-04 - accuracy: 0.9999 - a - ETA: 4s - loss: 4.7242e-04 - accuracy: 0.9999 - - ETA: 3s - loss: 4.6775e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 3s - loss: 4.6675e-04 - ac - ETA: 2s - loss: 4.5401e-04 -  - ETA: 1s - loss: 4.4373e-04 - accura - ETA: 1s - loss: 4.6106e-04 - accuracy: 0.9999 - auc - ETA: 0s - loss: 4.5901e-04 - accuracy: 0.9999 - auc: 1. - ETA: 0s - loss: 4.5664e-04 - accuracy: \n",
      "Epoch 49/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.0524e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.1039 - val_accuracy: 0.4061 - val_auc: 0.6329TA: 30s - loss: 9.6733e-05 - accuracy: 1.0000 - auc: 1 - ETA: 30s - loss:  - ETA: 27s - loss: 3.0834e-04 - accuracy: 1.0000 - au - ETA: 26s - loss: 2.7816e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 2.7455e-04 - acc - ETA: 17s - loss: 2.5574e-04 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 2.5435e-04 - accuracy:  - ETA: 15s - loss: 2.4762e-04 - accuracy: 1.000 - ETA: 14s - loss: 2.6161e-04 - accu - ETA: 13s - loss: 2.5136e-04 - accuracy: 1.0000  - ETA: 12s - loss: 2.4557e-04 - accuracy: 1.0000 -  - ETA: 11s - loss: 2.4630e-04 - accuracy: 1.0000 - auc: 1. - ETA: 11s - loss: 2.4699e-04 - accuracy: 1.0000 - au - ETA: 10s - loss: 2.4223e-04 - accuracy: 1.0000 - auc: 1 - ETA: 10s - loss: 2.4792e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 2.4685e-04 - acc - ETA: 9s - loss: 2.3894e-04 - accuracy: 1.0000 - auc:  - ETA: 9s - loss: 2.3813e-04 - accuracy: 1.0000 - ETA: 8s - los - ETA:  - ETA: 3s - loss: 2.1518e-04 - ac - ETA: 2s - loss: 2.1826e-04 - accuracy: 1.0000 - - ETA: 0s - loss: 2.0537e-04 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 50/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.2654e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.0169 - val_accuracy: 0.4054 - val_auc: 0.6380 loss: 9.2656e-05 - - ETA: 26s - loss: 0.0024 - accuracy: 0.9992 - auc: 1 - ETA: 26s - loss: 0.0022 - accuracy: 0 - ETA: 24s - loss: 0.0018 - accur - ETA: 23s - loss: 0.0015 - accuracy: 0 - ETA: 22s - loss: 0.00 - ETA: 19s - loss: 0.0011 - accuracy: 0.999 - ETA: 18s - loss: 9.9191e-04 - accuracy - ETA: 17s - loss: 9.1409e-04 - accuracy: 0.9 - ETA: 16s - loss: 9.1521e-04 - accuracy: - ETA: 14s - loss: 9.3647e-04 - accuracy - ETA: 13s - loss: 8.8118e-04 - accuracy: 0.9997 -  - ETA: 12s - loss: 8.5685e-04 - accuracy: 0. - ETA: 6s - loss: 6.9458e - ETA: 5s - loss: 6.6813e-04 - accuracy: 0.9998 - auc: 1. - ETA: 5s - loss: 6.6517e-04 - accuracy: 0. - ETA: 5s - loss: 6.8216e-04 \n",
      "Epoch 51/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.8015e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.0647 - val_accuracy: 0.4111 - val_auc: 0.63514012e-04 - accuracy: 1.0000 - a - ETA: 28s - loss: 2.5129e-04 - accuracy - ETA: 27s - loss: 2.6385e-04 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 2.3994e-04 - accuracy: 1.0000 - auc:  - ETA: 26s - loss: 2.292 - ETA: 24s - loss: 2.2684e- - ETA: 21s - loss: 1.8203e-04 - a - ETA: 20s - loss: 2.1690e-04 - accuracy: 1. - ETA: 18s - loss: 2.0769e-04 - accuracy: - ETA: 13s - loss: 2.1892e-04 - accura - ETA: 11s - loss: 2.1482e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 11s - loss: 2.1288e-04 - accuracy: 1.0000 - auc: 1. - ETA: 11s - loss: 2.1083e-04 - accuracy: 1.0000 - a - ETA: 10s - loss: 2.1030e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 10s - loss: 2.0969e-04 - accuracy:  - ETA: 9s - loss: 2.0573e-0 - ETA: 6s - loss: 2.8416e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - - ETA: 1s - loss: 2.7860e-04 - accuracy - ETA: 0s - loss: 2.8238e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 2.8133e-04 - accuracy: 1.0000 - auc - ETA: 0s - loss: 2.8137e-04 - accuracy: 1.0000 - auc: \n",
      "Epoch 52/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.3250e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.0475 - val_accuracy: 0.4126 - val_auc: 0.6349TA: 30s - loss - ETA: 27s - loss: 8.6164e-05 - accuracy: 1.000 - ETA: 26s - loss: 9 - ETA: 23s - loss: 5.8791e-04 - accuracy: 0. - ETA: 22s - loss: 5.5729e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 22s - loss: 5.5076e-04 - accuracy: 0.9998 - auc: 1. - ETA: 22s - loss: 5.4194e-04 - accuracy: 0.9998  - ETA: 21s - loss: 5.2923e-04 - accuracy: 0.9998 -  - ETA: 20s - loss: 5.1656e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 20s - loss: 5.1071e-04 - accuracy: 0.9998 - ETA: 20s - loss: 4.8160e-04 - accuracy: 0.99 - ETA: 19s - loss: 4.4882e-04 - accur - ETA: 17s - loss: 5.0263e-04 - accuracy: 0.999 - ETA: 16s - loss: 4.7790e-04 - accuracy: 0.9999 - au - ETA: 15s - loss: 4.8262e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 15s - loss: 4.8083e-04 - accuracy: 0.9999 - auc: 1 - ETA: 15s  - ETA: 12s - loss: 5.3910e-04 - ETA: 10s - loss: 4.9530e- - ETA:  - ETA: 7s - loss: 4.5013e-04 - accuracy: 0.9998 - a - ETA: 6s - loss: 4.4504e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 6s - loss: 4.4397e-04 - accuracy: 0. - ETA: 6s - loss: 4.3496e-04 - accuracy: 0.9999 - a - ETA: 5s - loss: 4.3065e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 5s - ETA: 0s - loss: 4.3277e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 53/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 4.8398e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.0330 - val_accuracy: 0.4107 - val_auc: 0.6331TA: 30s - loss: 1.3294e-04 - accuracy: 1.0000 - auc: 1 - ETA: 30s - - ETA: 27s - loss: 1.9096e-04 -  - ETA: 21s - loss: 2.4336e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - loss: 2.4085e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - loss: 2.3824e-04 - accuracy: 1.0000 - au - ETA: 20s - loss: 2.4376e-04 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 2.3917e-04 - accuracy:  - ETA: 18s - loss: 2.3951e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 18s - loss: 2.3849e-04 - accuracy: 1.0000 - auc: 1 - ETA: 18s - loss: 2.3559e-04 - accuracy: 1.0000 - a - ETA: 17s - loss: 2.2900e-04 - accuracy: 1.0000 -  - ETA: 17s - loss: 2.2744e - ETA: 14s - loss: 2.3825e-04 - accuracy: 1.0000 -  - ETA: 14s - loss: 2.2902e-04 -  - ETA: 12s - loss: 3.2723e-04 - accuracy: 0.99 - - ETA: 4s - loss: 5.1195e-04 - accuracy: 0. - E - ETA: 2s - loss: 4.9566e-04 -  - ETA: 1s - loss: 4.8609e-04 - accuracy - ETA: 0s - loss: 4.8097e-04 - accuracy: \n",
      "Epoch 54/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.5574e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1743 - val_accuracy: 0.4134 - val_auc: 0.6333: 30s - loss: 3.9476e-05 - accuracy: 1.0000 -  - ETA: 29s - loss: 6.6201e-05 - accuracy: 1.0000 - auc: 1 - ETA: 29s - loss: 7.1655e-05 - - ETA: 27s - loss: 9.5461e-05 - accuracy: 1.0000 - auc: 1 - ETA: 27s - loss: 1.1604e-04 - accura - ETA: 25s - loss: 1.371 - ETA: 23s - loss: 1.4829e-04 - accu - ETA: 21s - loss: 1.9652e-04 - accuracy: 1.0000 - a - ETA: 20s - loss: 1.8691e-04 - accuracy: 1 - ETA: 19s - loss: 4.7976e-04 - accuracy: 0.9998 - auc:  - ETA: 19s - loss: 4.6712e-04 - accuracy: 0 - ETA: 17s - loss: 4.2952e-04 - - ETA: 15s - loss: 3. - ETA: 13s - loss: 3.7528e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 13s - loss: 3.7989e-04 - accuracy: - ETA: 12s - loss: 3.6609e-04 -  - ETA: 10s - loss: 5.5806e-04 - accuracy: 0.9998 - a - ETA: 9s - loss: 5.4932e-04 - accura - ETA: 8s - loss: 5.6829e-04 - accuracy: 0.9998 - a - ETA - ETA: 3s - loss: 4.8649e-04 - accuracy - ETA: 2s - loss: 4.7608e-04 - accuracy: 0.9999 - auc: 1. - ETA: 2s - loss: 4.7466e-04 - ac - ETA: 1s - loss: 4.7344e-04 - accuracy: 0.9999 - ETA: 0s - loss: 4.6713e-04 - \n",
      "Epoch 55/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.3123e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.0577 - val_accuracy: 0.4057 - val_auc: 0.6322s: 2 - ETA: 25s - loss: 1.8094e - ETA: 23s - loss: 1.54 - ETA: 12s -  - ETA: 5s - loss: 4.8829e-04 -  - ETA: 4s - loss: 4.7600e-04 - accuracy: 0. - ETA: 4s - l - ETA: 0s - loss: 4.3681e-04 - accuracy: 0. - ETA: 0s - loss: 4.3230e-04 - accuracy: 0.9998 - auc: 1.\n",
      "Epoch 56/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.6798e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1830 - val_accuracy: 0.4065 - val_auc: 0.6321: 29s - loss: 1.1651e-04 - accuracy: 1.0000 - auc:  - ETA: 29s - loss: 1.1853e-04 - ETA: 27s - loss: 1.3402e-04 - accuracy: 1.0000 - - ETA: 26s - loss: 1.5314e-04 - accuracy: - ETA: 25s - loss: 1.3698e-04 - accuracy: 1.0000 - auc: 1. - ETA: 24s - loss: 1.3335 - ETA: 22s - loss: 1.6820e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 1.6760e-04 - accuracy: 1.0000 - auc: 1 - ETA: 22s - loss: 1.6428e-04 - accuracy: 1 - ETA: 20s - - ETA: 17s - loss: 1.4076e-04 - accuracy: 1.0000 - auc: - ETA: 17s - loss: 1.3704e-04 - accur - ETA: 15s - loss: 1.2 - ETA: 13s - loss: 1.2726e-04 - accuracy: 1.0000 - auc - ETA: 12s - loss: 3.0042e-04 - accuracy: 0.9999 - auc: 1. - ETA: 12s - loss: 2.9674e-04 - accuracy: 0.9999  - ETA: 11s - loss: 2.9626e-04 - accuracy: 0.9999 - auc: - ETA: 10s - loss: 2.9082e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 10s - loss: 2.9021e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 10s - loss: 2.8854e-04 - accuracy: 0.9999 - au - ETA: 10s - loss: 2.8361e-04 - accuracy: 0.99 - ETA: 9s - loss: 2 - ETA: 8s - loss: 2.6716e-04 -  - ETA: 7s - loss: 2.6912e-04 - accuracy: 0.9999 - auc:  - - ETA: 5s - loss: 2.6417e-04 - accuracy: 0.9999 - - ETA: 4s - loss: 2.6108e-04 - accuracy: 0.9999 - - ETA: 4s - loss: 2.6156e-04 - accuracy: 0.9999 - auc - ETA: 4s - loss: 2.6089e-04 - accuracy:  - ETA: 3s - loss: 2 - ETA: 2s - loss: 2.6942e-04 - accuracy: 0.9999 - - ETA: 1s - loss: 2.6620e-04 - accuracy: 0.9999 - auc: 1. - ETA: 1s - ETA: 0s - loss: 2.6804e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 57/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.3061e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2854 - val_accuracy: 0.4069 - val_auc: 0.6271 - loss: 7.0852e-04 - accur - ETA: 28s - loss: 3.1056e-0 - ETA: 26s - loss: 1.9150e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 25s - loss:  - ETA: 23s - loss: 1.5175e-04 - accuracy: 1.0000 - auc - ETA: 22s - loss: 1.4479e-04 - accuracy:  - ETA: 21s - loss: 1.6540e-04  - ETA: 19s - loss: 2.1222e-04 - accuracy: 1.00 - ETA: 18s - loss: 2.0906e-04 - accuracy:  - ETA: 16s - loss: 2.1421e-04 - accuracy: 1.0000 - auc:  - ETA:  - ETA: 12s - loss: 2.0461e-04 - accuracy: 1.0000 - auc: 1. - ETA: 12s - loss: 2.0642e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 12 - ETA: 9s - loss: 2.1270e-04 - accuracy: 1. - ETA: 9s - loss: 2.1985e-04 - accuracy: 1. - ETA: 8s - loss: 2.2755e-04 - accuracy: 1.0000 - a - ETA: 8s - loss: 2.2758e-04 - accuracy: 1.0000 - auc: 1. - ETA: 8s - loss: 2.2648e-04 - accuracy: 1.0000 - auc:  - ETA: 7s - loss: 2.248 - ETA: 6s - loss: 2.2142e-04 - accuracy: 1.0000 - auc - ETA: 6s - loss: 2.196 - ETA: 5s - loss: 2.1861e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 5s - loss: 2.1811e-04 - accuracy: 1.00 - ETA: 4s - loss: 2.1410e-04 -  - ETA:  - ETA: 1s - loss: 2.4038e-04 - accuracy: 1.0000 - a - ETA: 1s -\n",
      "Epoch 58/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.5142e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1770 - val_accuracy: 0.4057 - val_auc: 0.6327s: 2.7197e-04 - accurac - ETA: 27s - loss: 2.1939e-04 - accuracy: 1.0000 - ETA: 26s - loss: 1.9808e-04 - accuracy: 1.0000 - auc:  - ETA: 21s - loss: 1.9079e-04 - accuracy: 1.0000  - ETA: 21s - loss: 1.7847e-04 - accuracy:  - ETA: 19s - loss: 1.7279e-04 - accuracy: 1.0000 - ETA: 18s - loss: 1.6493e- - ETA: 16s - loss: 1.6567e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 1.6438e-04 - accuracy: 1.0000 - auc: - ETA: 16s - loss: 3.6645e-04 - accuracy: 0.9999 - ETA: 15s - loss: 3.4991e - ETA: 7s - loss: 3.0471e-04 - accu - ETA: 6s - loss: 2.9577e-04 - accuracy: 0.9999 - auc - ETA: 6s - loss: 2.9339e-04 - accuracy: 0.99 - ETA: 5s - loss: 2.9011e-0 - ETA: 4s - loss: 2.8029e-04 - accuracy: 0.9999 - auc: 1. - ETA: 4s - loss: 2.7908e-04 - accuracy - ETA: 4s - loss: 2.7387e-04 - accuracy: 0.9999 - auc: 1.00 - E - ETA: 2s - loss: 2.6480e-04 - accura - ETA: 1s - loss:\n",
      "Epoch 59/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.6095e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1030 - val_accuracy: 0.4069 - val_auc: 0.6361y: 1.0000  - ETA: 27s - loss: 1.0797e-04 - accuracy: 1.0000  - ETA: 26s - loss: 9.3553e-05 - accuracy: 1.0000 -  - ETA: 25s - loss: 3.2636e-04 - acc - ETA: 24s - loss: 2.7129e-04 - accurac - ETA: 22s - loss: 2.3278e-04 - accuracy: 1.0000 - au - ETA: 22s - loss: 2.2342e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 22s  - ETA: 18s - loss: 2.1341e-04 - accuracy: - ETA: 17s - loss: 2.2670e-04 - accuracy: 1 - ETA: 16s - loss: 2.1509e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 16s - loss: 2.1429e- - ETA: 13s - ETA: 10s - loss: 2.5781e-04 - accuracy: 1.0000 - auc: 1 - ETA: 10s - loss: 2.6251e-04 - accuracy: 1.0000  - ETA: 9s - loss: 2.5649e-04 - accuracy: 1.0000 - a - ETA: 9s - loss: 2.5 - ETA: 1s - loss: 3.7091e-04 - accuracy: 0.9999 - ETA: 1s - loss: 3.6639e-04 - ac - ETA: 0s - loss: 3.6698e-04 - accuracy: 0.\n",
      "Epoch 60/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.3993e-04 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 5.6658 - val_accuracy: 0.4046 - val_auc: 0.6229: 1.0000 - auc: 1.00 - ETA: 28s - loss: 1.9193e-04 - accuracy: 1.0 - ETA: 26s - loss: 1.5016e-04 - accuracy: 1.00 - ETA: 25s - loss: 3.0175e-04 - accuracy: 1.0000 - auc: 1. - ETA: 25s - loss: 4.6806e-04 - accuracy: 1.0000 - auc: 1 - ETA: 25s - loss: 5.4622e-04 - accuracy: 1.0000 - auc - ETA: 24s - loss: 5.0768e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 5.0305e-04 - accuracy: 1.0000 - auc: 1. - ETA: 24s - loss: 4.8609 - ETA: 22s - loss: 4.3888e-04 - accuracy: 1.0000 - auc - ETA: 21s - loss: 4.1773e-04 - acc - ETA: 19s - loss: 3.6261e-04 - accuracy: 1.0000 - auc: 1 - ETA: 19s - loss: 3.5377e-04 - accuracy: 1.00 - ETA: 18s - loss: 4.7433e-04 - accuracy: 0.9999 - auc - ETA: 18s - loss: 6.6540e-04 - accuracy: 0.9997 -  - ETA: 17s - loss: 6.3230e-04 - accuracy: - ETA: 15s - loss: 5.8724e-04 - accuracy: 0.9998 - auc: - ETA: 15s - loss: 5.7223e-04 - accuracy: 0.9998 - ETA: 14s - loss: 5.4238e-04 - accuracy: 0.9998  - ETA: 13s - ETA: 10s - loss: 4.4627e-04 - accuracy: 0.9 - - ETA: 1s -\n",
      "Epoch 61/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.4444e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.0694 - val_accuracy: 0.4084 - val_auc: 0.6354 accuracy: 1.0000 -  - ETA: 22s - loss: 1.6386e-04 - accuracy: 1.0000  - ETA: 21s - loss: 1.5991e-04 - accuracy: 1.0000 - auc: - ETA: 21s - loss: 1.5342e-04 - - ETA: 19s - loss: 2.5736e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 19s - loss: 2.5754e-04 - - ETA: 13s - loss: 2.7412e-04 - ac - ETA: 11s - loss: 2.5904e-04 - accuracy: 1. - ETA: 10s - loss: 2.5145e-04 - accuracy: 1 - ETA - ETA: 7s - loss: 2.3 - ETA: 6s - loss: 2.2881e-04 - accuracy: 1.0000 - a - ETA: 6s - ETA: 2s - loss: 2.0 - ETA: 1s - loss: 2.4810e-0\n",
      "Epoch 62/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.1859e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1604 - val_accuracy: 0.4069 - val_auc: 0.6357loss: 9.8791e-05 - accuracy: 1. - ETA: 24s - loss: 8.9470e-05 - accuracy: 1.0000 - au - ETA: 23s -  - ETA: 20s - loss: 9.2152e-05 - accuracy: 1.00 - ETA: 19s - loss: 8.5823e-05 - accuracy: 1.0000 - auc:  - ETA: 19s - loss: 8.3627e-05 - accuracy: 1.0000 - auc: 1 - ETA: 18s - loss: 8.2481e-05 - accuracy: - ETA: 17s - loss: 9.7828e-05 - accuracy: 1.0000 - - ETA: 16s - loss: 9.8226e-05  - ETA: 14s - loss: 9.6133e-05 - accuracy: 1.0000 - a - ETA: 14s - loss: 1.0049e-04 - accuracy: 1.000 - ETA: 13s - loss: 9.9311e-05 - acc - ETA: 11s - loss: 7.5529e-04 - accuracy: 0.9999 - auc: 1. - ETA: 11s - loss: 7.4741e-04 - accuracy: 0.99 - ETA: 10s - loss: 7 - ETA: 8s - loss: 6.7182e-04  - E - ETA: 5s - loss: 6.0914e-04 - accuracy: 0.9999 - auc: 1. - ETA: 5s - loss: 6.0635e-04 - accuracy - E - ETA: 3s - loss: 5.6294e-04 - accu - ETA: 2s - loss: 5.5015e-04 - accuracy: 0.99 - ETA: 1s - loss: 5.4579e-04  - ETA: 0s - loss: 5.2978e-04 - accura\n",
      "Epoch 63/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.8004e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.3444 - val_accuracy: 0.4142 - val_auc: 0.6311 ETA: 19s - loss: 2.1269e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 2.1392e-04 - - ETA: 17s - loss: 1.9823e-04 - accuracy: 1.0000 - ETA: 16s - loss: 1.9916e-04 - accuracy:  - ETA: 15s - loss: 1.8803e-04 - accuracy: 1.0 - ETA: 14s - loss: 1.8278e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 1.8472e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: - ETA: 8s - loss: 2.6496e-04  - ETA: 7s - loss: 2.5847e-04 - accuracy: 0.9999 - - ETA: 6s - loss: 2.5474e-04 - accuracy: 0.9999 - auc:  - ETA: 6s - loss: 2.5 - ETA: 5s - loss: 2.5480e-04 - accuracy: 0.9999 - a - ETA: 5s - loss: 2.5335e-04 - accuracy: 0.9999 - a - ETA: 4s - loss: 2.5632e-04  - ETA: 3s - loss: 2.4842e-04 - accuracy: 0. - ETA: 3s - loss: 2.4484e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 3s - loss: 2\n",
      "Epoch 64/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9504e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.1663 - val_accuracy: 0.4199 - val_auc: 0.635129s - loss: 5.9145e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 29s - loss: 5.7978e-05 - accuracy: 1.0000 - auc: 1. - ETA: 29s - loss: 5.5336e-05 - accuracy: 1.0000 - au - ETA: 28s - loss: 6.9641e-05 - accuracy: 1.0000 -  - ETA: 27s - loss: 8.0076e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 27s - loss: 7.8526e-05 - accuracy: 1.0000 - auc: 1. - ETA: 27s - loss: 7.4078e-05 - accuracy: 1 - ETA: 26s - loss: 1.1630e-04 - accuracy: - ETA: 25s - loss: 1.0306e-04 - accuracy: 1.0 - ETA: 24s - loss: 2.3287e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 24 - ETA: 20s - loss: 1.7933e-04 - accuracy: 1.0000 - auc: - ETA: 20s - loss: 1.8583e-04 - accuracy: 1.0000 - auc: - ETA: 19s - loss: 2.0175e-04 - accuracy: 1.00 - ETA: 18s - loss: 1.9169e-04 - accuracy: 1.0000 - auc:  - ETA: 18s - loss: 1.8741e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 17s - loss: 1.8586e-04 - accuracy: 1.0000 - - ETA: 17s - loss: 1.7811e - ETA: 6s - loss: 2.0977e-0 - ETA: 5s - loss: 2.1063e - ETA: 4s - loss: 2.0327e-04 - accuracy: 1.00 - ETA: 3s - loss: 2.0041e-04 - accuracy: 1.0000 - auc:  - ETA: 3s - loss: 1.9924e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 1.9885e-04 -  - ETA: 2s - loss: 1.9473e-04 - accuracy: 1.0000 - ETA: 1s - - ETA: 0s - loss: 1.9589e-04 - accuracy: 1.0000 - auc: \n",
      "Epoch 65/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.5378e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.0958 - val_accuracy: 0.4126 - val_auc: 0.6375TA: 22s - loss: 1.4019e-04 - acc - ETA: 20s - loss: 1.6539e-04 - accuracy: 1.0000  - ETA: 8s - loss: 1 - ETA: 7s - loss: 1.7746e - ETA: 6s - loss: 1.7251e-04 - accuracy: 1.0000 - auc - E - ETA: 4s - loss: 1.6454e-04 - accuracy: 1.0000 - a - ETA: 3s - loss: 1.6415e-04 - accuracy: 1.0000 - auc:  - ETA: 3s - - ETA: 2s - loss: 1.5908e-04 - accuracy: 1.0000 - auc: 1. - ETA: 1s - loss: 1.5866e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 1.5839e-04 - accuracy: 1.0000 - auc - ETA: 1s\n",
      "Epoch 66/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.1356e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2502 - val_accuracy: 0.4188 - val_auc: 0.633729s - loss: 8.0168e-0 - ETA: 22s - loss: 8.3378e-05 - ac - ETA: 20s - loss: 8.6575e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - loss: 8.6117e-05 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 8.4765e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - lo - ETA: 17s - loss: 8.2524e-05 - accuracy: 1.0000 - au - ETA: 16s - loss: 8.4584e-05 - accuracy: - ETA: 11s - loss: 8.4363e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 11s - loss: 8.4136e-05 - - ETA: 9s - l - ETA: 8s - loss: - ETA: 6s - loss: 1.037 - ETA: 5s - loss: 1.0842e-04 - accuracy: 1.00 - ETA: 5s - loss: 1.0794e-04 - accuracy: 1.0000 - auc:  - ETA: 4s - l - ETA: 3s - los - ETA: 1s - loss: 1.0520e-04 - ac - ETA: 1s - loss: 1.0932e-04 - accuracy: 1.0000 - auc - ETA: 0s - loss: 1.0859e-04 - accu\n",
      "Epoch 67/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.0965e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2175 - val_accuracy: 0.4130 - val_auc: 0.6381.8984e-04 - accuracy: 1 - ETA: 27s - loss: 1.5004e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 27s - loss: 1.4748e-04 - accuracy: 1.0000  - ETA: 26s - loss: 2.3408e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 26s - loss: 2.2870e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 2.2599e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 26s - loss: 2.2024 - ETA: 24s - loss: 4.4239e-04 - accuracy:  - ETA: 14s - loss: 4.6839e-04 - accuracy: 0.9998 - ETA: 13s - loss: 4.77 - ETA: 1 - ETA: 6s - loss: 3.7361e-04 - accuracy: 0.9998 - auc:  - ETA: 6s - loss: - ETA: 4s - loss: 3.5276e-04 - accuracy: 0.9999 - ETA: 4s - loss: 3.4765e-04 - accura\n",
      "Epoch 68/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 2.1570e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1337 - val_accuracy: 0.4142 - val_auc: 0.6405 - loss: 9.0041e-05 - accuracy: - ETA: 28s - loss: 1.5898e-04 - accuracy:  - ETA: 27s - loss: 0.0010 - accuracy: 0.9995 -  - ETA: 26s - loss: 8.8147e-04 - accuracy: 0.9996 - auc: - - ETA: 21s - loss: 5.0203e-04 - accuracy: 0.9998 - - ETA: 20s - loss - ETA: 17s - loss: 3.9000e-04 - accuracy: 0.99 - ETA: 16s - loss: 3.7127e-0 - ETA: 14s - loss: 3.3654e-04 - accuracy: 0.99 - ETA: 13s - loss: 3.1894e-04 - accuracy: 0.9999 - auc: 1. - ETA: 13s - loss: 3.1393e- - ETA: 10s - los - ETA: 6s - loss: 2.4938e-0 - ETA: 5s - loss: 2.4468e-04 - accuracy: 0.9999 - auc - ETA: 5s - loss: 2.4247e-04 - accuracy: 0.9999 - auc:  - ETA: 5s - loss: 2.4388e-04 - accuracy: 0.99 - ETA: 4s - loss: 2.4001e-04 - accura - ETA: 3s - loss: 2.344 - ETA: 2s - loss: 2.2701e-04 - ac - ETA: 1s - loss: 2.2199e-04 - accu - ETA: 1s - loss: 2.1696e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 2.1663e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 2.1619e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 2.1394e-04 - accuracy: 0.9999 -\n",
      "Epoch 69/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.2303e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.0508 - val_accuracy: 0.4176 - val_auc: 0.6450: 30s - loss: 1.4237e-05 - accuracy: 1.00 - ETA: 29s - loss: 2.0855e-04 - acc - ETA: 27s - loss: 1.5699e-04 - accuracy: 1.0000 - ETA: 26s - loss: 1.2837e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 1.2663e-04 - accuracy: - ETA: 25s - loss: 1.2373e-04 - accuracy: 1.0 - ETA: 24s - loss: 1.5541e-04 - accuracy: 1.0000 - auc: 1. - ETA: 24s - loss: 1.5071e-04 - accuracy: 1.0000 -  - ETA: 23s - loss: 2.9720e-04 - accuracy: 1.0000 - auc:  - ETA: 23s - loss: 2.8918e-04 - accuracy: 1.0000 - auc - ETA: 22s - loss: 2.8139e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 22s - loss: 2.7983e-04 - accuracy: 1. - ETA: 21s - loss: 2.5327e-04 - accuracy: 1.0000 - au - ETA: 20s - loss: 2.4047e-04 - ETA: 14s - loss: 4.4788e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 14s - loss: 4.4528e-04 -  - ETA: 12s - loss: 4.0165e-04 - accuracy: 0.9998 - auc: - ETA: 11 - ETA: 9s - loss: 3.9597e-04 - accuracy: 0.9998 - ETA: 8s - loss: - ETA: 7s - loss: 3.8255e - ETA: 4s - - ETA: 2s - loss: 3.3140e-04 - accura\n",
      "Epoch 70/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.1552e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2039 - val_accuracy: 0.4218 - val_auc: 0.6397 accuracy: 1.0000 - auc: 1.000 - ETA: 28s - loss: 3.6896e-04 - accuracy: 1.0000 -  - ETA: 28s - loss: 3.5819e-04 - accuracy: 1.00 - ETA: 27s - loss: 2.86 - ETA: 24s - loss: 2.0049e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 1.9887e-04 - accuracy: 1.0000  - ETA: 23s - loss: 1.8769e-04 - accuracy: 1.00 - ETA: 22s - loss: 1.6684e-04 - accuracy: 1.0000 - auc - ETA: 21s - loss: 1.7486e-04 - accu - ETA: 20s - loss: 1.8943e-04 - accuracy: 1.0000  - ETA: 19s - loss: 1.8118e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 1.8029e-04 - accuracy: 1.0000 - auc: - ETA: 18s - loss: 1.7678e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 1.7533e-04 - accuracy: 1 - ETA: 17s - loss: 2.2834e-04 - accuracy: 1 - ETA: 16s - loss: 2.1933e-04 - accuracy: 1 - ETA: 15s - loss: 2.5037e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 2.4948e-04 - accuracy: 1.0000 - - ETA: 14s - loss: 2.4528e-04 - accuracy: 1 -  - ETA: 5s - loss: 2.3815e-04 - accuracy: 1.0000 - auc: 1.00 - E - ETA: 3s - los\n",
      "Epoch 71/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.9948e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4108 - val_accuracy: 0.4130 - val_auc: 0.6386 30s - loss: 4.1194 - ETA: 28s - loss: 0.0014 - accuracy: 0.9994 - auc: 1.000 - ETA: 27s - loss: 0.0013  - ETA: 26s - loss: 9 - ETA: 23s - loss: 6.5467e- - ETA: 20s - loss: 5.3730e-04 - accuracy: 0.9998 - auc - ETA: 20s - loss: 5.1660e-04 - accu - ETA: 18s - loss: 4.5803e-04 - accuracy: 0.9 - ETA: 17s - loss: 4. - ETA: 14s - loss: 4.1075e-0 - ETA: 12s - loss: 3.9473e-04 - accuracy: 0 - ETA: 11s - loss: 3.7509e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 10s - loss: 3.733 - ETA: 9s - loss: 3.5842e-04 - accuracy: 0.9999 - auc - ETA: 9s - loss: 3.5578e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 9s - loss: 3.5488e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 5.1078e-04 - accura\n",
      "Epoch 72/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.5669e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2329 - val_accuracy: 0.4142 - val_auc: 0.6367ccuracy: - ETA: 27s - - ETA: 24s - loss: 4.7188e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 23s - loss: 4.6076e-04 - accuracy: 1.0000 - ETA: 22s - loss: 4.7914e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 4.7576e-04 - accuracy: 1.0 - ETA: 18s - loss: 3.2789e-04 - accuracy: 1.0000 - auc:  - ETA: 17s - loss: 3.2022e-04 - accuracy: 1.0000 - a - ETA: 17s - loss: - ETA: 14s - loss: 3.0660e-04 - accuracy: - ETA: 12s - loss: 3.0293e-04  - ETA: 10s - loss: 2.8121e-04 - accuracy: 1.0000 - auc: - ETA: 10s - ETA: 2s - loss: 2.7421e-04 - accuracy: 1. -\n",
      "Epoch 73/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.4338e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2739 - val_accuracy: 0.4077 - val_auc: 0.6285- accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 6.4640e-05 - accuracy: 1.00 - ETA: 27s - loss: 5.7000e-05 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 3.4256e-04 - a - ETA: 24s - loss: 2.8273e-04 - accu - ETA: 23s - loss: 2.3521e-04 - accuracy: 1.0000 - auc: 1. - ETA: 23s - loss: 2.2846e-04 - ETA: 20s - loss: 2.0542e-04 - accuracy: 1.0000 - auc:  - ETA: 20s -  - ETA: 17s - loss: 1.7150e-04 - accuracy: 1.0000  - ETA: 16s - loss: 1.7023e-04 - accuracy: 1.0000 - auc: 1.000 -  - ETA: 12s - loss: 1.4419e-04 - accuracy: 1.0000 - auc: 1 - ETA: 12s - loss: 1.4305e-04 - accur - ETA: 10s - loss: 5.9696e-04 - accuracy: 0.9999 - ETA: 9s - loss: 5.7585e-0 - ETA: 8s - loss: 5.5362e-04 - accuracy: 0.9999 - auc - E - ETA: 6s - loss: 5.1 - ETA: 5s - loss: 4.9454e-04 - ac - ETA: 2s - loss: 4.7508e-04 - accu\n",
      "Epoch 74/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.0792e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.1922 - val_accuracy: 0.4100 - val_auc: 0.63040034 - accuracy: 0.9993 - ETA: 25s - loss: 0.0030 - accuracy: 0.9994 - auc:  - ETA: 24s - loss: 0.0028 - accuracy: 0.9994 - auc: 0.99 - ETA: 24s - loss: 0.0027 - accuracy: 0.9994 - auc: 0.999 - ETA: 24s - loss: 0.0027 - accuracy: 0.9994 - auc:  - ETA: 24s - lo - ETA: 21s - loss: 0.0020 - accuracy: 0.9996 - auc: 0.999 - ETA: 2 - ETA: 18s - loss: 0.0015 - ac - ETA: 16s - loss: 0.0014 - accuracy: 0.9997 - auc: 0.99 - ETA: 16s - loss: 0.0014 - accuracy: 0. - ETA: 15s - loss: 0.0013 - a - ETA:  - ETA: 2s - loss: 8.6157e-04  - ETA: 1s - loss: 8.336 - ETA: 0s - loss: 8.1425e-04 - accuracy: 0.9998 - auc - ETA: 0s - loss: 8.0845e-04 - accuracy: 0.9998 - auc: 1.00\n",
      "Epoch 75/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.7426e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4384 - val_accuracy: 0.4161 - val_auc: 0.6288844e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 24s - loss: - ETA: 21s - loss: 3.2739e-04 - a - ETA: 19s - loss: 3.3219e-04 - accuracy: 0.9998 - auc: 1.000 - ETA - ETA: 12s - loss: 3.0362e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 11s - loss:  - ETA: 9s - loss: 2.9778e-04 - accuracy: 0.9999 - auc - - ETA: 7s - loss: 2.7491e-04 - accuracy: 0.9999 - a - ETA: 6s - loss: 2.7096e-04 - ac - ETA: 5s - loss: 2.6906e-04 - accuracy: 0.9999 - auc - ETA: 5s - l - ETA: 2s - loss: 2.8367e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 2s - loss: - ETA: 0s - loss: 2.7419e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 2.7370e-04 - accuracy: 0.\n",
      "Epoch 76/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9723e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7086 - val_accuracy: 0.4134 - val_auc: 0.6269 accuracy: 1.0000 - auc:  - ETA: 24s - loss: 1.0 - ETA: 21s - loss: 9.7031e-05 - accuracy: 1.0000 - auc: - ETA: 21s - loss: 9.4016e-05 - accuracy: 1.0000  - ETA: 20s - loss: 8.8384e-0 - ETA: 18s - loss: 8.6822e-05 - ETA: 16s - loss: 1.0114e-04 - accurac - ETA: 14s - loss: 1.1744e-04 - accuracy: 1.0000 - auc - ETA: 14s - loss: 1.1576e-04 - accuracy  - ETA: 7s - - ETA: 5s - loss: 1 - ETA: 0s - loss: 1.9847e-04 - accuracy: 0.9999 - auc\n",
      "Epoch 77/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.1117e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4202 - val_accuracy: 0.4096 - val_auc: 0.6284.0031 - accuracy: 0.9985 - ETA: 23s - loss: 0. - ETA: 21s - l - ETA: 18s - loss: 8.8598e- - ETA: 16s - loss: 7.4678e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 16s - - - ETA: 3s - loss: 4.5779e-04 - accuracy: 0.9999 - a - ETA: 3s - loss:\n",
      "Epoch 78/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.4165e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4981 - val_accuracy: 0.4126 - val_auc: 0.6236ETA: 24s - loss: 2.3288e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 24s - loss: 2.2880e-04 - accuracy: 1.00 - ETA: 23s - loss: 2.0395e-04 - accuracy: 1.0000  - ETA: 22s - loss: 2.8328e-04 - accuracy: 1.0000 - auc: - ETA: 22s - loss - ETA: 19s - loss: 2.3430e-04 - - ETA: 17s - loss: 2.1 - ETA: 14s - loss: 1.9255e-04 - ETA: 9s - loss: 2.0910e-04 - accuracy: 1. - ETA: 8s - loss: 2.1173e-04 - accuracy: 1.0000 - - ETA: 8s - loss: 2.0867e-04 - accuracy: 1. - ETA: 5s - loss: 1.9717e-04 - accuracy: 1.0000 - - ETA: 5s - loss: 1.944\n",
      "Epoch 79/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.5835e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4577 - val_accuracy: 0.4038 - val_auc: 0.62351.2198e-04 - accuracy: 1.0000  - ETA: 18s - loss: 1.1710e-04 - accuracy: 1.0000  - ETA: 17s - loss: 1.1097e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 17s - loss: 1.1054e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 17s - loss: 1.1020e- - ETA: 15s - loss: 1.0267 - ETA: 7s - loss: 5.6970e-04 - accuracy: 0.9998 - - ETA: 7s - loss: 5.6171e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 6s - loss: 5.6034e-04 - accuracy: 0.9998 - ETA: 6s - loss: 5.5 - ETA: 3s - - ETA: 1s - l\n",
      "Epoch 80/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.8209e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4020 - val_accuracy: 0.4203 - val_auc: 0.6312.7384 - ETA: 27s - loss: 2.0323e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 27s - - ETA: 23s - loss: 1.2791e-04 - accuracy:  - ETA: 22s - loss: 1.2665e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 1.3392e-04 - accuracy: 1.0000 - auc - ETA: 22s - loss: 1.3033e-04 - accuracy: 1.000 - ETA: 21s - loss: 1.5017e-04 - accurac - ETA: 19s - loss: 1.5325e-04 - accuracy: 1.0000 - auc:  - ETA: 19s - loss: 1.4918e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 1.4806e-04 - accuracy: 1.0000 - auc - ETA: 18s - loss: 1.4471e-04 - accurac - ETA: 17s - loss: 1.4033e-04 - accuracy: 1.0000 - a - ETA: 16s - loss: 6.5404e-04 - accuracy: 0.9 - ETA: 15s - loss: 6.1853e-04 - accuracy: 0.9998 - auc - ETA: 14s - loss: 6.0700e-04 - accuracy: 0.9 - ETA: 13s - loss: 5.7073e-04 - accuracy: 0.9 - ETA: 7s - loss: 4.5910e-04 - accuracy: 0.9998 - auc: 1. - ETA: 7s - loss: 4.5685e-04 - accuracy: 0.99 - ETA: 6s - loss: 4.5356e-04 - accuracy - ETA: 6s - loss: 4.4204e-04 - accuracy: 0.9999 - - ETA: 5s - loss: 4.3680e-04 - accuracy: 0.9999 - - ETA: 5s - loss: 4.3445e-04 - accuracy: 0.9999 - auc - ETA: 5s - los - ETA: 3s - loss: 4.1298e-04 - accuracy: 0.99 - ETA: 3s - loss: 4.0684e-04 - accuracy: 0.99 - ETA: 0s - loss: 3.7937e-04 - accuracy: 0.9999 - auc - ETA: 0s - loss: 3.8240e-04 - accuracy: 0.9999\n",
      "Epoch 81/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.6715e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2809 - val_accuracy: 0.4080 - val_auc: 0.629830s - loss: 2.3531e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 2.2707e-05 - accuracy: 1.0000 - a - ETA: 29s - loss: 3.3721e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 9.6870e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 8.9378e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 29s - loss: 8.4766e-05 -  - ETA: 27s - loss: 0.0016 - E - ETA: 21s - loss: 9.75 - ETA: 18s - loss: 8.5852e-04 - accur - ETA: 13s - loss: 6.5850e-04 - accuracy: 0.9999 - a - - ETA: 7s - loss: 5.0425e - ETA: 6s - loss: 4.8326e - ETA: 4s - loss: 4.6558e-04 - accu - ETA: 1s - loss: 4.9392e-04 - accuracy: 0.9999 - auc: 1.00 -\n",
      "Epoch 82/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.7742e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.1156 - val_accuracy: 0.4123 - val_auc: 0.6394A: 18s - loss: 2.0032e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 18s - loss: 1.9974e-04 - a - ETA: 16s - loss: 1.8813e-04 - accuracy: 1.0000 - a - ETA: 16s - loss: 1.8271e-04 - accu - ETA: 10s - loss: 7.7949e-04 - accuracy: 0.9997 - auc:  - ETA: 9s - loss: 7.7037e-04 - accuracy: 0.9997 - auc - ETA: 7s - loss: 7.0262e-04 -  - ETA: 5s - loss: 6.3158e-04 - accuracy: 0.9998 - a - ETA: 4s - loss: 6.3183e-04 - accuracy - ETA: 4s - loss: 6.1865e-04 - accuracy: 0.99 - ETA: 3s - loss: 6.0886e-04 - accuracy: 0.9998 - auc - ETA: 1s - loss: 5.9121e-04 - accuracy:  - ETA: 0s - loss: 5.9259e-04 - accuracy: 0.9998 - - ETA: 0s - loss: 5.8662e-04 - accuracy: 0.9998 - auc:  - ETA: 0s - loss: 5.8322e-04 - accuracy: 0.9998 - a\n",
      "Epoch 83/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.7857e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2164 - val_accuracy: 0.4188 - val_auc: 0.6365 1.0165e-04 - accuracy: 1.0000 - - ETA: 28s - loss: 1.8937e-04 - accuracy: 1.0000 - auc: 1 -  - ETA: 24s - loss: 1.2995e-04 - accuracy: 1.0000 - au - ETA: 23s - loss: 1.2104e- - ETA: 21s - loss: 1.5455e-04 - acc - ETA: 2s - loss: 1.8726e-04 - accuracy:  - ETA: 2s - loss: 1.8345e-04 -  - ETA: 1s - loss: 1.8405e-04 - accura - ETA: 0s - loss: 1.7999e-04 - accuracy: 1.0000 -\n",
      "Epoch 84/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9163e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1930 - val_accuracy: 0.4241 - val_auc: 0.6394- ETA: 26s - loss: 5.8171e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 26s - loss: 5.5512e-05  - ETA: 24s - loss: 4.6637e-05 - accuracy: 1.0000 - - ETA: 19s - loss: 6.1556e - ETA: 16s - loss: 7.2765e-05 - accuracy: 1.0000 - au - ETA: 16s - loss: 7.1759e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 16s - loss: 7.4014e-05 - accuracy: 1.0000 -  - ETA: 15s - loss: 7.2555e-05 - accuracy: 1.0 - ETA: 14s - loss: 6.9324e-05 - accuracy: 1.0000 - auc:  - ETA: 13s - loss: 7. - ETA: 11s - loss: 1.3955e-04 - accuracy: 0.9999 - - ETA: 4s - loss: 1.6262e-04 - accuracy: 0.9999 - a - ETA: 3s - loss: 1.6667e-04 - accuracy: 0. - ETA: 1s - loss: 1.7693e-0\n",
      "Epoch 85/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 1.8815e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4831 - val_accuracy: 0.4211 - val_auc: 0.63030s - loss: 7.1537e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 6.7121e-05 - accuracy: 1.0000 - auc: 1. - ETA: 30s - loss: 6.7591e-05 - accuracy: 1.00 - ETA: 29s - loss: 8.6246e-05 - accuracy: 1.0000 -  - ETA: 28s - loss: 1.2271e-04 - accuracy: 1.0 - ETA: 27s - loss: 9.3375e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 27s - loss: 9.2123e-05 - accuracy: 1.00 - ETA: 26s - loss: 8.0581e-05 - accuracy: 1.0000 - auc: 1 - ETA: 25s - loss: 7.6691e-05 - accuracy: 1.0000 - auc: 1 - ETA: 25s - loss: 7.3374e-05 - a - ETA: 23s - loss: 7.9522e-05 - accuracy: 1.0000 - auc - ETA: 22s - loss: 7.6654e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 7.6104e-05 - a - ETA: 21s - loss: 6.8496e-05 - accuracy: 1.0000 - a - ETA: 20s - loss: 7.0943e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - loss: 7.0768e- - ETA: 17s - loss: 6.8114e-05 - accuracy: 1.0000 - auc: - ETA: 17s - loss: 7.8240e-05 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 7.7435e-05 - accur - ETA: 15s - loss: 7.3285e-05 - accuracy: 1.0000 - auc: - ETA: 15s - loss: 7.1882e-05 - accuracy - ETA: 13s - loss: 7.5149e-05 - accura - ETA: 12s - loss: 1.5701e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 12s - loss: 1.5679e-04 - accuracy: 0.9 - ETA: 11s - loss: 1.4990e-04 - accuracy: 0.9999 -  - ETA: 10s - loss: 1.4732e-04 - accuracy: 0.9999 - auc: 1 - ETA: 10s - loss: 1.4531e-04 - ETA: 9s - loss: 1.4115e-04 - accuracy: 0.9999 - - ETA: 8s - loss: 1.3923e-04 - accuracy:  - ETA: 8s - loss: 1.3740e-04 - accuracy: 0.9999 - ETA: 7s -\n",
      "Epoch 86/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9071e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2755 - val_accuracy: 0.4126 - val_auc: 0.634029s - loss: 7.8835e-05 - accuracy: 1.0000 - auc: 1. - ETA: 29s - - ETA: 26s - loss: 7.5202e-05 - accuracy: 1.0000 -  - ETA: 25s - loss: 8.0095e-05 - accuracy: 1.0000 -  - ETA: 24s - loss: 7.4648e-05 - ETA: 22s - loss: 6.6942e-05 - accu - ETA: 20s - loss: - ETA: 18s - loss: 1.9358e-04 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 1.9021e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 17s - loss: 1.8853e-04 - accuracy: 1.0000 - au - ETA: 17s - loss: 1.8173e-04 - accuracy: 1.0000 - auc - ETA: 16s - loss: 1.7746e-04 - accuracy: 1 - ETA: 15s - loss: 1.8747e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 15s - loss: 1.8676e-04 - accuracy: 1 - ETA: 14s - loss: 1.8139e-04 - accuracy: 1.00 - ETA: 13s - loss: 1.7649e-04 - accuracy: - ETA: 11s - loss: 1.6547e-04 - accuracy: 1.0000 - au - ETA: 11s - loss: 1.6231e-04 - accuracy: 1.0000 -  - ETA: 10s - loss: 1.6014e-04 -  - ETA: 7s - loss: 1.9905e-04 - accuracy: 1.0000 - auc - ETA: 6s - loss: 1.9828e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 1.978 - ETA: 3s - loss: 1.8498e-04 - ac - ETA: 2s - los - ETA: 1s - loss:\n",
      "Epoch 87/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.3380e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3010 - val_accuracy: 0.4134 - val_auc: 0.6357: 27s - loss: 1.8 - ETA: 25s - loss: 2.8511e-04 -  - ETA: 23s - loss: 2.3583e - ETA: 20s - loss: 2.4033e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - loss: 2.3912e-04 - accuracy: 1.000 - ETA: 19s - loss: 2.2420e-04 - accuracy: 1.0000 - auc:  - ETA: 19s - loss: 2.2298e-04 - accuracy: 1.00 - ETA: 18s - loss: 2.0663e-04 - accur - ETA: 16s - loss: 1.9530e-04 - accurac - ETA: 15s - loss: 1.8260e-04 - accuracy: 1.00 - ETA: 14s - loss: 1.7792e-04 - accuracy - ETA: 12s - loss: 1.7335e-04 - - ETA: 11s - loss: 1.7263e-04 - accuracy: 1.0000 - a - ETA: 10s - loss: 1.7348e-04 - accuracy: 1.000 - ETA: 2s - loss: 1.4389e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 1.4 - ETA: 1s - loss: 1.4002e-04 - accuracy - ETA: 0s - loss: 1.3751e-04 - \n",
      "Epoch 88/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.2265e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3315 - val_accuracy: 0.4142 - val_auc: 0.6390 loss: 6.4925e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 29s - loss: 6.3645e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 5.6070e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 5.0158e-05 - accuracy: 1.0000 - au - ETA: 28s - loss: 4.6748e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 4.7004e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 4.5496e-05 - accuracy: 1.0 - ETA: - ETA: 15s - loss: 5.2117e-04 - accuracy: 0.9999 - - ETA: 15s - loss:  - ETA: 12s - loss: 4.5258e-04 - accuracy: 0.9999 - ETA: 11s - loss: 4.3253e - ETA: 9s - loss: 4.0676e-04 - accuracy: 0.9999 - auc:  - ETA: 9s - loss: - ETA: 7s - los - ETA: 4s - loss: 3.4907e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 4s - loss: 3.4830e-04 - accuracy: 0.9999 - auc - ETA: 3s - loss: 3.468 - ETA: 0s - loss: 3.2757e-04 - accuracy: 0.\n",
      "Epoch 89/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.5763e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4892 - val_accuracy: 0.4192 - val_auc: 0.63310 -  - E - ETA: 23s - los - ETA: 20s - loss: 1.4804e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 19s - loss: 1.4576e-04 - accura - ETA: 18s - loss: 1.3223e-04 - accuracy: - ETA: 17s - loss: 1.4367e-04 - accuracy: 1.0000 -  - ETA: 16s - loss: 1.3910e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 1.3815e-04 - accuracy: 1.0000 - auc: - ETA: 15s - loss: 1.3965e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 15s - loss: 1.3918e-04 - accuracy: 1.0000 - auc: 1 - ETA: 15s - loss: 1.3952e-04 - accuracy: 1.0000 - auc: 1 - ETA: 15s - loss: 1.3718e-04 - accuracy: 1.0000 - auc: 1. - ETA: 15s - loss: 1.3554e-04 - accuracy: 1.0000 -  - ETA: 14s - los - ETA: 6s - loss: 1.6375e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 1.6336e-04 - accuracy: 1.0000 - auc:  - ETA: 6s - - ETA: 3s - loss: 1.6548e-04 - accuracy: 1.00 - ETA: 2s - loss: 1.6355e-0 - ETA: 1s - loss: 1.5815e-04 - accuracy: 1. - ETA: 0s - loss: 1.6065e-04 - accuracy - ETA: 0s - loss: 1.5861e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 1.5831e-04 - accuracy: 1.0000 - auc: \n",
      "Epoch 90/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9265e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3627 - val_accuracy: 0.4161 - val_auc: 0.6329 30s - loss: 3.2117e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 29s - loss: 2.9875e-05 - accuracy: 1.0000 - a - ETA: 29s - loss: 3.1105e-04 - accuracy:  - ETA: 27s - loss: 4.4399e-04 - accuracy: 1.0 - ETA: 26s - loss: 3.3724e-04 - ETA: 24s - loss: 3.9296e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 2 - ETA: 20s - loss: 3.3609e-04 - accuracy: 1.0000 -  - ETA: 19s - loss: 3.2101e-04 - accuracy: 1.000 - ETA: 18s - loss: 2.9857e-04 - accuracy: 1.0000 -  - ETA: 18s - loss: 2.8724e-04 - accuracy: 1.0000 - au - ETA: 17s - loss: 2.7598e-04 - accuracy: 1.0000 - - ETA: 16s - loss: 2.6273e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 16s - loss: 2.6169e-04 - a - ETA: 14s - loss: 2.6116e-0 - ETA: 12s - loss: 2.3610e-04 - accuracy: 1.0000 - a - ETA: 11s - loss: 2.2876e-04 - accura - ETA: 10s - lo - ETA: 6s - loss: 2.2945e-04 - accuracy: 1.0000 - auc: 1. - ETA: 6s - loss: 2.2834e-04 - accuracy: 1. - ETA: 6s - los - ETA: 4s - loss: 2.2045e-04 - accuracy: 1.0000 - ETA: 4s - los - ETA: 0s - loss: 1.9667e-04 - accura\n",
      "Epoch 91/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.0896e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3599 - val_accuracy: 0.4142 - val_auc: 0.6367- loss: 5.3703e-05 - accuracy: 1. - ETA: 28s - loss: 6.1320e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 27s - loss: 6.0188e-05 - accuracy: 1 - ETA: 26s - loss: 5.8377e-05 - accuracy: 1.0000 - au - ETA: 26s - loss: 5.8593e-05 - accur - ETA: 24s - loss: 6.3710e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 6.3592e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 6.3111e-05 - accuracy: 1. - ETA: 23s - loss: 5.6844e-05  - ETA: 3s - loss: 2.2575e-04 - accuracy: 1. - ETA: 2s - loss: 2.2257e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 2.2211e-04 - accuracy: 1.0000 - a -\n",
      "Epoch 92/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.1439e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3583 - val_accuracy: 0.4123 - val_auc: 0.6358TA: 26s - loss: 9.8688e-05 - accuracy: 1.0000 - auc: - ETA: 26s - loss: 9.0828e-05 - accuracy: 1. - ETA: 25s - loss: 9.9555e-05 -  - ETA: 23s - loss: 8.1826e-05 - ETA: 20s - loss: 1.7632e-04 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 2.0524e-04 - accuracy: 1.0000 - auc: - ETA: 20s - loss: 1.9915e-04 - accura - ETA: 18s - loss: 1.8517e-04 - accur - ETA: 17s - loss: 1.7052e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 17s - loss: 1.7045 - ETA: 14s - loss: 1.5060e-04 - accuracy: 1.00 - ETA: 13s - loss: 1.4819e - ETA: 11s - loss: 1.3587e-04 - accuracy: 1.0000 - auc:  - ETA: 11s - loss: 1.3370e- - ETA: 9s - loss: 1.2450e-04 - accuracy: 1.0000 - auc:  - ETA: 7s - loss: 1.2 - ETA: 5s - loss: 1.2324e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 5s - ETA: 4s - loss: 1.2378e - ETA: 2s - loss: 1.1996e-04 - accura - ETA: 1s - loss: - ETA: 0s - loss: 1.1630e-04 - accuracy: \n",
      "Epoch 93/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.7377e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2998 - val_accuracy: 0.4130 - val_auc: 0.6368auc:  - ETA: 19s - loss: 3.5754e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 19s - loss: 3.5570e-04 - accuracy: 0.9998 - au - ETA: 19s - loss: 3.4861e-04 - accuracy: 0.9998 - auc - ETA: 18s - loss: 3.3655e-04 - accuracy: 0.9999 - au - ETA: 13s - loss: 2. - ETA: 11s - loss: 2.2846e-04 - accuracy: 0.9999 - au - - ETA: 6s - loss: 2.0180e-04  - ETA: 5s - loss: 1.9593e-04 - accuracy:  - ETA: 0s - loss: 1.7688e-04 - accuracy: 0.9999 - a - ETA: 0s - loss: 1.7538e-04 - accuracy: 0.9999 -\n",
      "Epoch 94/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.3832e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2851 - val_accuracy: 0.4115 - val_auc: 0.6356: 30 - ETA: 27s - loss: 4.8859e-05 - accuracy: 1.0 - ETA: 26s - loss: 4.810 - ETA: 23s - loss: 5.1495e-05 - accuracy: 1. - ETA: 22s - loss: 4.8903e-05 - - ETA: 20s - loss: 5.0752e-05 - accuracy: 1.0000 - au - ETA: 20s - loss: 4.9373e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - loss: 4.9250e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 19s - loss: 4.9349e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 4.9098e-05  - ETA: 17s - loss: 8.0436e-05 - accuracy: 1.0000 - a - ETA: 17s - loss: 7.7615e-05 - accuracy: 1.0000 -  - ETA: 16s - loss: 7.4384e-05 - accuracy: 1.0000 - - ETA: 15s - loss: 6.7651e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 15s - loss: 6.7139e-04 - - ETA - ETA: 9s - loss: 5.6 - ETA: 8s - - ETA: 7s - loss: 5.0069e-04 - accu - ETA: 6s - loss: 5.3930e-04 - accuracy:  - ETA: 5s - loss: 5.2697e-04 - accura - ETA: 2s - loss: 4.7974e-04 - accura - ETA: 2s - loss: 4.6843e-04 - accuracy: 0.9999 - auc:  - ETA: 1s - loss: 4.6557e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 1s - loss: 4.6462e-04 - accuracy: 0. - ETA: 1s - loss: 4.5541e-04 - accura - ETA: 0s - loss: 4.4435e-04 - accuracy: 0.99\n",
      "Epoch 95/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.6176e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2423 - val_accuracy: 0.4111 - val_auc: 0.6337ss - ETA: 26s - loss: 1.1671e-04 - accuracy: 1.0000 - auc: - ETA: 26s - loss: 1.1221e-04 - accuracy: 1.0000 - auc: 1 - ETA: 25s - loss: 1.0654e-04 - accuracy: 1.0000 - auc - ETA: 25s - loss: 1.0357e-04 - accuracy: 1.0000 - a - ETA: 24s - loss: 9.7168e-05 - accuracy: 1.000 - ETA: 23s - loss: 9.0513e-05 -  - ETA: 22s - loss: 8.3722e-05 - accuracy: 1.0000 - - ETA: 21s - loss: 8.0083e-05 - acc - ETA: 19s - loss: 7.5697e-05 - accur - ETA: 17s - l - ETA: 14s - loss: 1.2942e-04 - accuracy: 1.000 - ETA: 13s - loss: 1.2481e-04 - accuracy: 1.0000 - auc: 1. - ETA: 13s - loss: 1.2319e-04 - accuracy: 1.00 - ETA: 12s - loss: 1.1723e-04 - accuracy: 1.0000 - auc - ETA: 12s - loss: 1.1523e-04 - accuracy: 1.0000 - a - ETA: 6s - loss: 9.6914e-05 - accuracy: 1.0000 - - ETA: 6s - loss: 9.6237e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 9.6392e-05 - accura - ETA: 5s - loss: 9.4505e-05 - accuracy: 1.0000 - a - ETA: 5s - loss: 9\n",
      "Epoch 96/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9781e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3277 - val_accuracy: 0.4103 - val_auc: 0.6327racy: 1 - ETA: 27s - loss: 7.8057e-05 - accuracy: 1.00 - ETA: 26s - loss: 6.6931e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 26s - loss: 6.6146e-05 - accuracy: 1.0000 - ETA: 25s - loss: 6.3135e-05 - accuracy: 1.0000 - auc: 1. - ETA: 25s - loss: 6.0861e - ETA: 22s - loss: 4.6113e-04 - accuracy: 0. - ETA: 21s - loss: 4.3760e-04 - accuracy: 0.9998 -  - ETA: 20s - loss: 4.1436e-04 - accuracy: 0.9998 - auc: 1. - ETA: 20s - loss: 4.0566e-04 - accuracy: 0.9998 - auc: 1. - ETA: 20s - loss: 3.9752e - ETA: 17s - loss: 3. - ETA: 15s - loss: 2.9986e-04 - accuracy: 0.9999 -  - ETA: 14s - loss: 2.8736e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 14s - loss: 2.8558e-04 - accuracy: 0.9999 -  - ETA: 13s - loss: 2.7362e-04 - accuracy: 0.9999 - a - ETA: 12s - loss: 2.6409e-04 - accuracy: 0.9999 - - ETA: 12s - loss: 2.5595e-04 - accuracy: 0.9999 - auc - ETA: 11s - loss: 2.5056e-04 - - ETA: 5s - loss: 2.0665e-04 - accuracy: 0.9999 - a - ETA: 5s - loss: 2.2567e-04 - accu - ETA: 4s - loss: 2.1916e-04 - accuracy: 0.99 - ETA: 3s - loss: 2.1547e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 3s - loss: 2.1500e-04 - accuracy: 0.9999 - auc - ETA: 3s - loss: 2.1385e-04 - accuracy: 0. - ETA: 3s - loss: 2.1538e-0\n",
      "Epoch 97/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.9386e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.5493 - val_accuracy: 0.4153 - val_auc: 0.6239s - loss: 6.6236e-04 - accuracy: 0.9992 - auc: 1.00 - ETA: 26s - loss: 6.4553e-04 - accuracy: 0.9992 - auc: 1.00 - ETA: 26s - loss: 6.3329e-04 - accuracy: 0. - ETA: 25s - loss: 5.1511e-04 - accuracy: 0.99 - ETA: 24s - loss: 4.8795e-04 - accuracy: 0.9995 - a - ETA: 23s - loss: 4.5023e-04 - accuracy: 0.9995 - ETA: 22s - loss: 4.0722e-04 - accuracy - ETA: 21s - loss: 3.6182e-04 - accuracy - ETA: 19s - loss: 3.2899e-04 - accuracy: 0.9997 - auc: - ETA: 19s - loss: 3.1762e-04 - accuracy: 0.9997 - auc: 1 - ETA: 19s - loss: 3.2032e-04 - accuracy: 0.9997 - auc: 1 - ETA: 18s - loss: 3.1277e-04 - accur - ETA: 17s - loss: 2.8856e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 17s - loss: 2.9021e-04 - accuracy: 0.9 - ETA: 16s - loss: 2.7203e-04 - accuracy: 0 - ETA: 14s - loss: 2.7388e-04 - ETA: 12s - loss: 2.6548e-04 - accuracy: 0.9998 - auc - ETA: 12s - loss: 2.5960e-04 - accuracy: 0.9 - ETA: 2s - loss: 2.0029e-04 - accura - ETA: 1s - loss: 3.0619e-04  - ETA: 0s - loss: 2.9773e-04 - accuracy: 0.\n",
      "Epoch 98/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.3858e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4483 - val_accuracy: 0.4096 - val_auc: 0.6291TA: 17s - loss: 1.2079e-04 - accuracy: 1.0000  - ETA: 16s - loss: 1.1740e-04 - accuracy: 1. - ETA: 15s - loss: 1.1019e-04 - accuracy: 1.000 - ETA: 14s - loss: 1.1688e-04 - ETA: 12s - loss: 1.0721e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 12s - loss: 1.0889e-04 - accuracy: 1.0000 - auc: 1 - ETA: 12s - loss: 1.1152e-04 - acc - ETA:  - ETA: 8s - ETA: 6s - loss: 1.4908e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 1.4871e - ETA: 5s - loss: 1.4415e-04 - accuracy: 1.00 - E - ETA: 3s - loss: 1.3743e-04 - accuracy: 1.0000 - - ETA: 3s - loss: 1.4812e-04 - accuracy: 1.0000 - auc: 1. - ETA: 2s - loss: 1.475 - ETA: 1s - loss: 1.4419e-04 - accuracy: 1.0000 - a - ETA: 1s - loss: 1\n",
      "Epoch 99/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 1.6257e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8225 - val_accuracy: 0.4088 - val_auc: 0.626427s - loss: 2.0274e-04 - accuracy: - ETA: 26s - loss: 1.5698e-04 - accuracy - ETA: 24s - loss: 1.3319e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 1.4047e-04 - accuracy: 1.0000 - a - ETA: 23s - loss: 1.2800e-04 - accuracy: 1.00 - ETA: 22s - loss: 1.1365e-04 - ETA: 20s - loss: 1.4551e-04 - accuracy: 1.0000 - auc - ETA: 20s - loss: 1.3963e-04 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 1.3638e-04 - accuracy: 1.0000 - auc: 1. - ETA: 19s - loss: 1.337 - ETA: 17s - loss: 1.6095e-04 - accuracy: 1.0000 - auc - ETA: 16s - loss: 1.7188e-04 - accuracy: 1.0000 -  - ETA: 16s - lo - ETA: 12s - loss: 1.4658e-04 - accura - ETA: 11s - loss: 1.3767e-04 - accuracy: 1.0000 - auc: 1. - ETA: 11s - loss: 1.3641e-04 - accuracy: 1.0000 - auc:  - ETA: 10s - loss: 1.3529e-04 - accuracy: 1.0000 - auc: 1 - ETA: 10s - loss: 1.3425e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 1.3330e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 10s - loss: 1.3279e-04 - accu - ETA: 5s - loss: 1.1672e-04 - accuracy: 1.0000 - ETA: 2s - loss: 1.1929e-04 - accuracy: 1.0000 - - ETA: 2s - loss: 1.1794e-04 - accuracy: 1.0000 - auc: 1. - ETA: 2s - loss: 1.1727e-04 - accuracy: 1.0000 - ETA: 1s - loss: 1.1617e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 1.1604e-04 - accuracy: 1.0000 - auc: 1.00 - ETA\n",
      "Epoch 100/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.0507e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3951 - val_accuracy: 0.4111 - val_auc: 0.6333loss: 9.9581e-05 - accuracy: 1.0 - ETA: 28s - loss: 1.4777e-04 - accuracy: 1.0000 - auc: 1.000 - E - ETA: 24s - loss: 2.4183e-04 - accuracy: 1.0000 - auc - ETA: 23s - loss: 2. - ETA: 21s - loss: 1.8174e-04 - accura - ETA: 19s - loss: 1.7654e-04 - accuracy:  - ETA:  - ETA: 15s - loss: 2.0587e-04 - accuracy: 1.0000 - ETA: 14s - loss: 1.9667e-04 - accuracy: 1.0000 - auc: 1 - ETA: 13s - loss: 1.9234e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 13s - loss: 1.9120e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 13s - loss: 1.9120e-04 - accuracy: 1.0000 - - ETA: 9s - loss: 1.7293e-04 - accuracy: 1. - ETA: 8s - loss: 1.6905e-04 - accuracy: 1.0000 - auc - ETA: 8s - loss: 1.6711e-04 - accuracy: 1.0000 - ETA: 8s - loss: 1.6681e-04 - accuracy: 1.0000 - auc - ETA: 7s - loss: 1.6519e-04 - accuracy: 1.0000 - auc:  - ETA: 7s - loss: 1.6689e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 7s - loss: 1.664 - ETA: 6s - loss: 1.6087e-04 - accuracy: 1.0000 - - ETA: 3s - ETA:  - ETA: 0s - loss: 2.0239e-04 - accuracy: 0.9999 - a - ETA: 0s - loss: 2.0675e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 2.0635e-04 - accuracy: 0.9999 - auc\n",
      "Epoch 101/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.3187e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4707 - val_accuracy: 0.4088 - val_auc: 0.6320A: 28s - loss: 4.5114e-05 - accuracy: 1.0000 - a - ETA: 28s - loss: 4.2377e-05 - acc - ETA: 26s - loss: 1.6232e-04 - accuracy: 1.0 - ETA: 25s - loss: 1.3890e-04 - accurac - ETA: 24s - loss: 1.1711e-04  - ETA: 21s - loss: 1.0683e-04 - accuracy: 1.0000 - auc:  - ETA: 21s - loss: 1.0350e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 21s - loss: 1.0286e-04 - accuracy: 1.0000 - - ETA: 20s - loss: 1.0257e-04 - accuracy: 1.0000 - auc - ETA: 20s - loss: 9.8 - ETA: 17s - loss: 1.2805e-04 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 1.2645e-04 - accuracy: - ETA: 16s - loss: 1.1998e-04 - accuracy: 1.0000 - auc: 1. - ETA: 15s - loss: 1.1881e-04 - accuracy: 1 - ETA: 14s - loss: 1.1204e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 14s - loss: 1.1067e-04 - accuracy: 1.000 - ETA: 13s - loss: 1.0634e-04 - accuracy: 1.0000 - au - ETA: 12s - loss: 1.0512e-04 - accuracy: 1.0000 - auc:  - ETA: 12s - loss: 1.0460e-04 - accur - ETA: 10s - loss: 1.0044e-04 - accuracy: 1.0000 - auc -  - E - ETA: 4s - loss: 8.1659e-05 - accuracy: 1.0000 - auc - ETA: 4s - loss: 8.4201e-05 - accuracy: 1.0000 - auc: 1. - ETA: 4s - loss: 8.3866e-05 - accuracy: 1.00 - ETA: 3s - loss: 8.292 - ETA: 2s - loss: 8.0214e-05 - accuracy: 1.00 - ETA: 1s - loss: 1.248 - ETA: 0s - loss: 1.3471e-04 - accuracy: 1.0000 - auc: 1. - ETA: 0s - loss: 1.3429e-04 - accuracy: 1.0000 - - ETA: 0s - loss: 1.3264e-04 - accuracy: 1.0000 - auc\n",
      "Epoch 102/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.7923e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2691 - val_accuracy: 0.4073 - val_auc: 0.6264228e-04 - accuracy: 1.0000 - auc: 1. - ETA: 27s - loss: 3.5623e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 27s - loss: 3.4944e-04 - accur - ETA: 26s - loss: 2.3249e-04 - accuracy: 1.0000 - auc: 1. - ETA: 26s - loss:  - ETA: 23s - loss: 0.0011 - accu - ETA: 21s - loss: 9.2457e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 20s - loss: 9.0268e-04 - accuracy: 0.9998  - ETA: 20s - loss: 8.2843e-04 - accuracy: 0.9998 - auc: 1 - ETA: 19s - loss: 8.0725e-04 - acc - ETA: 18s - loss: 7.1548e-04 - acc - ETA: 16s - loss: 6.3419e-04 - accuracy: 0.9999 - auc:  - ETA: 15s - loss: 6.2155e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 15s - loss: 6.1958e-04 - accur - ET\n",
      "Epoch 103/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.3668e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5125 - val_accuracy: 0.4130 - val_auc: 0.6336 30s - loss: 7.5435e-05 - accuracy:  - ETA: 28s - loss: 8.4080e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 8.0287e-05 - accu - ETA: 22s - loss: 7.4653e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 7.4199e-05 - accuracy: 1.00 - ETA: 21s - loss: 6.9005e-05 - accuracy: 1.0000 - auc - ETA: 21s - loss: 6.8248e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 21s - loss: 6.7884e-05 - accuracy: 1.0000 - auc:  - ETA: 20s - loss: 6.6498e-05 - accuracy: 1.0000 - auc:  - ETA: 20s - loss: 7.5487e-05 - accuracy: - ETA: 18s - loss: 7.0169e-05 - accurac - ETA: 17s - loss: 6.4258e-05 - accuracy: 1.000 - ETA: 16s - loss: 6.1917e-05 - accuracy: 1.0000 -  - ETA: 15s - loss: 6.1882e-05 - accurac - ETA: 14s - loss: 5.7827e-05 - accuracy: 1.0000 - auc - ETA: 13s - loss: 5.6778e-05 - accuracy: 1.0000 - ETA: 13s - loss: 5.9699e-05 - accuracy:  - ETA: 11s - loss: 1.5672e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 11s - loss: 1.5626e-04 - accuracy: 0.9999 - auc: 1. - ETA: 11s - loss: 1.549 - ETA: 9s - l - ETA: 7s - loss: 4.2257e - ETA: 6s - loss: 4.085 - ETA: 5s - loss: 3.9128e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 5s - loss: 3.9389e-04 - accuracy:  - ETA: 4s - loss: 3.8817e-04 - accuracy: 0. - ETA: 4s - loss: 3.8134e-04 - accu - ETA: 3s - loss: 3.7074e-04 - accuracy: 0.9999 - - ETA: 2s - loss: 3.6627e-04 - accuracy: 0.9999 - a - ETA: 2s - loss: 3.6247e-04 - accuracy: 0.9999 - auc - ETA: 2s - loss: 3.5988e-04 - accuracy: 0.9999 - ETA: 1s - loss: 3.5537e-04 -  - ETA: 1s - loss: 3.4678e-04 - accuracy: 0.9999 - a - ETA: 0s - loss: 3.4363e-04 - accuracy\n",
      "Epoch 104/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.7851e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3731 - val_accuracy: 0.4096 - val_auc: 0.6353 - accuracy: 0.9994 - auc - ETA: 27s - loss: 7.8168e-04 - accuracy: 0.9995 - auc: 1 - ETA: 27s - loss: 7.2326e-04 - accuracy: 0.9995 - auc: 1. - ETA: 26s - loss: 6.8247e-04 - accuracy: 0.9995 - auc: 1.00 - ETA: 26s - loss: 6.6406e-04 - accuracy: 0.9996 - auc: 1 - ETA: 26s - loss: 6.1529e - ETA: 24s - loss: 4.2356e-04 - accur - ETA: 22s - loss: 3.4890e-04 - accuracy: 0.9998 - ETA: 21s - loss: 3.3656e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 21s - loss: 3.3406e-04 - accurac - ETA: 20s - loss: 2.9709e-04 - accuracy: 0.9998 - auc - ETA: 19s - loss: 2.8558e-04 - accuracy: 0.9998 - auc: 1. - ETA: 19s - loss: 2.7837e - ETA: 16s - loss: 2.4185e-04 - accuracy - ETA: 15s - loss: 2.2647e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 15s - loss: 2.2443e-04 - accuracy: 0.9999 - auc:  - ETA: 15s - loss: 2.1912e-04 - ac - ETA: 13s - loss: 2.1730e-04 - accuracy: 0.9 - ETA: 12s - loss: 2.0605e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 11s - loss: 2.0554e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 11s - loss: 2.0434e-04 - accuracy: 0.9999 -  - ETA: - ETA: 4s - loss: 1.6055e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 4s - loss: 1.6020e-04 - ac - ETA: 3s - loss: 1.5839e - ETA: 0s - loss: 1.8057e-04 - accuracy: 0.9999\n",
      "Epoch 105/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.7710e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4394 - val_accuracy: 0.4088 - val_auc: 0.6321A: 30s - loss: 7.1503e-05 - accuracy: 1.0000 - au - ETA: 29s - loss: 5.2330e-05 - accuracy - ETA: 28s - loss: 6.4918e-0 - ETA: 21s - loss: 2.9767e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 2.9208e-04 - accuracy:  - ETA: 20s - loss: 2.6183e-04 - accuracy: 1.0000 - auc: 1.000 - ETA - - ETA: 12s - loss: 1.9744e-04 - accuracy: - ETA: 11s - loss: 2.2873e-04 - accuracy: 1.0000 - auc: 1. - ETA: 11s - loss: 2.2639e-04 - accuracy: 1.0000 - a - ETA: 10s - loss: 2.2011e-04 - accuracy: 1. - ETA: 5s - loss: 2.0148e-04 - ac - ETA: 4s - loss: 1.9982e-04 - ac - ETA: 3s - loss: 1.9792e-04 - ac - ETA: 0s - loss: 1.8174e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 1.8138e-04 - \n",
      "Epoch 106/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.5400e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3962 - val_accuracy: 0.4119 - val_auc: 0.6355: 30s - loss: 4.2767e-05 - accuracy: 1.0000 - au - ETA: 30s - loss: 7.3666e-05 - accuracy: 1.0000 - auc:  - ETA: - ETA: 25s - loss: 4.1596e-04 - accuracy: 1.0000 -  - ETA: 24s - loss: 3.7179e-04 - accuracy: 1.0000 - auc: - ETA: 24s - loss: 3.4873e-04 - accuracy: 1.0000  - ETA: 23s - loss: 3.1499e-04 - accu - ETA: 22s - loss: 2.6355e-04 - accuracy: 1.0000 - au - ETA: 21s - loss: 2.5100e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 2.5286e-04 - accuracy: 1.0000 -  - ETA: 20s - loss: 2.3967e-04 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 2.3344e-04 - accuracy: 1.0000 -  - ETA: 19s - loss: 2.2331e-04 - accuracy: 1.0000 -  - ETA: 18s - loss: 2.1023e-04 - accuracy: 1.0000 - auc: - ETA: 18s - loss: 2.0385e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 18s - loss: 2.0293e-04 - ac - ETA: 16s - ETA: 13s - loss: 1.8052e-04 - accuracy: 1.0000 - auc: 1. - ETA: 12s - loss: 1.7816 - ETA: 10s - loss: 1.6202e-04 - accuracy: 1.0000  - ETA: 9s - loss: 1.5755e-04 - accuracy: 1.0000 - ETA: 9s - loss: 1.5560e-04 - accuracy: 1.0000 - ETA: 8s - loss: 1.5251e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 8s - loss: 1.5 - ETA: 7s - loss: 1.9137e-04 - ac - ETA: 4s - loss: 1.7645e-04 - accura - ETA: 3s - loss: 1.7135e-0 - ETA: 2s - loss: 1.6713e-04 - accuracy: 1.0000 - ETA: 2s - loss: 1.6480e-0 - ETA: 1s - loss: 1.5979e-04 - accura - ETA: 0s - loss: 1.5636e-04 - accuracy: 1.0000 - auc: 1. - ETA: 0s - loss: 1.5577e-04 - accuracy: 1.00\n",
      "Epoch 107/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.7986e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4227 - val_accuracy: 0.4203 - val_auc: 0.640758e-04 - accuracy: 1.0000 - ETA: 26s - loss: 2.1523e-04 - ETA: 24s - loss: 1.5496e-04 - accuracy: 1.0000 - auc: 1. - ETA: 24s - loss: 1.4967e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 24s - loss: 1.4671e-04 - ac - ETA: 22s - loss: 1.6836e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 1.6612e-04 - accuracy: 1.0000 - auc: - ETA: 21s - loss: 1.5948e-04 - accuracy: 1.0000 - auc: 1 - ETA: 21s - loss: 1.5460e-04 - accuracy: 1.0000 - ETA: 20s - loss: 1.4903e-04 - accuracy: 1.0000 - auc: - ETA: 20s - loss: 1.4800e-04 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 1.5461e-04 - accuracy: 1.0000 - auc: 1. - ETA: 19s - loss: 1.5188e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 1 - ETA: 17s - loss: 1.3040e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 17s - loss: 1.3038e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 16s - loss: 1.2878e-04 - accuracy: 1.0000 - auc: 1 - ETA: 16s - loss: 1.2912e-04 - accuracy: 1.0000 -  - ETA: 15s - loss: 1.2500e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 15s - loss: 1.2357e-04 - accuracy: 1. - ETA: 14s - loss: 0.0011 - accuracy: 0.9998 - auc: 1. - ETA: 14s - loss: 0.0011 - accuracy: 0.9998 -  - ETA: 13s - loss: 0.0011 - ETA: 11s - loss: 9.7916e-04 - accuracy: 0.9998 - auc: 1 - ETA: 11s - loss: 9.6812e-04 - accuracy: 0.9998 - au - ETA: 10s - loss: 9.4375e-04  - ETA: 9s - loss: 8.9534e-04 - accura - ETA: 8s - loss: 8.6767e-04 - accuracy: 0.9998 - a - ETA: 8s - loss: 8.5874e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 8s - loss: 8.5651e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 8s - loss: 8.5428e-04 - accuracy: 0. - ETA: 7s - loss: 8.3454e-04 - accuracy: 0.99 - ETA: 6s - loss: 8.1932e-04 - accuracy: 0.9998 - ETA: 6s - loss: 8.0655e-04 - accuracy: 0.9998 - auc:  - ETA: 6s - loss: 8.0 - ETA: 5s - loss: 7.6789e-04 - accuracy: 0.9999 - ETA: 4s - loss: 7.7683e-04 - accuracy: 0.99 - ETA: 4s - loss: 7.6382e-04 - accuracy: 0.9999 - auc:  - ETA: 3s - loss: 7.5942e-0 - ETA: 0s - loss: 6.9056e-04 - accura\n",
      "Epoch 108/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.1918e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3563 - val_accuracy: 0.4157 - val_auc: 0.6405 - loss: 7.9653e-06 - accuracy: 1.000 - ETA: 29s - ETA: 26s - loss: 2.2595 - ETA: 4s - loss: 1.225 - ETA: 3s - loss: 1.2395e-04 - accuracy: 1.0000 - - ETA: 3s - loss: 1.2339e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 1.228 - ETA: \n",
      "Epoch 109/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.5538e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3367 - val_accuracy: 0.4195 - val_auc: 0.6398- loss: 6.3901e-05 - accuracy: 1.0000 - au - ETA: 28s - loss: 5.0279e-05 -  - ETA: 26s - loss: 4.3116e-05 - accuracy: - ETA: 25s - loss: 6.1758e-05 - accuracy: 1.0000 - auc: 1. - ETA: 25s - loss: 5.9565e-05 - accuracy: 1.0000 - - ETA: 24s - loss: 6.5505e-05 - accuracy: 1.0000 -  - ETA: 23s - loss: 6.2128e-05 - accuracy: 1.0000 - auc: 1. - ETA: 23s - loss: 6.0120e-05 - accuracy: 1 - ETA: 22s - loss: 5.6951e-05 - accuracy: 1.0000  - ETA: 21s - loss: 5.3646e-05 - accuracy: 1.0000 - auc: - ETA: 20s - loss: 5.3467e-05 - accur - ETA: 15s - loss: 8.0670e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 15s - loss: 8.0665e-05 - accuracy: 1.0000  - ETA: 14s - loss: 7.9249e-05 - accuracy: 1. - ETA - ETA: 9s - loss: 1.1071e-04 - accuracy: 1.0000 - auc: 1 - ETA: 9s - loss: 1.1023e-04 - ac - ETA: 8s - loss: 1.0804e-04 - accuracy: 1.0000 - a - - ETA - ETA: 2s - loss: 1.5647e-04 - accuracy: 1.0000 - auc: 1.00 - - ETA: 0s - loss: 1.5833e-04 - accu\n",
      "Epoch 110/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 2.5552e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4189 - val_accuracy: 0.4218 - val_auc: 0.6415: 4.1686e-05 - accuracy: 1.0000 - a - ETA: 27s - loss: 2.9512e-04 - accuracy: 1 - ETA: 25s - loss: 2.2985e-04 - accuracy: 1.0 - ETA: 24s - loss: 2.1686e-04 - accuracy: 1.0 - ETA: 19s - loss: 1.5051e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 1.4976e-04 - accur - ETA: 18s - loss: 1.3590e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 1.3403e-04 - accuracy: 1 - ETA: 17s - loss: 1.2525e-04 - accuracy: 1.0000 - auc: - ETA: 16s - loss: 1.2186e-04 - accuracy: 1.0000 - ETA: 15s - loss: 2.4608e-04 - accuracy: 0.9999 - ETA: 10s - loss: 1.9693e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 10s - loss: 1.9529e-04 - ac - ETA: 7s - loss: 3.1757e-04 - accuracy: 0.9998 - auc: 1. - ETA: 7s - loss: 3.1599e-04 - accuracy: 0.9998 - a - ETA: 6s - loss: 3.1220e-04 - accuracy - - ETA: 4s - loss: 2.8373e-04  - ETA: 1s - loss: 2.6389e-04 - accuracy:  - ETA: 0s - loss: 2.5889e-04 - accuracy: \n",
      "Epoch 111/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.6694e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3723 - val_accuracy: 0.4207 - val_auc: 0.6427 - ETA: 18s - loss: 1.7225e-04 - accur - ETA: 16s - loss: 1.8105e-04 - accuracy: 1.0000 - a - ETA: 15s - loss: 1.8117e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 15s - loss: 1.8047e- - ETA: 13s  - ETA: 9s - loss: 2.2027e-0 - ETA: 7s - loss: 2.0056e-04 -  - ETA: 6s - loss: 1.9 - ETA: 4s - loss: 1.8 - ETA: 3s - loss: 1.8015e-04 - accuracy: 1.0000 - auc - ETA: 3s - loss: 1.7908e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 1.7872e-04 - accuracy: 1.0000 - - ETA: 2s - loss: 1.7660e-04 - accuracy: 1.0000 - - ETA: 2s - loss: 1.7466e-04 - accuracy: 1. - ETA: 1s - loss: - ETA: 0s - loss: 1.6976e-04 - accuracy: \n",
      "Epoch 112/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.0686e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3072 - val_accuracy: 0.4149 - val_auc: 0.6415- loss: 1.9905e-04 - accuracy: 1.0000 - au - ETA: 29s - loss: 1.2606e-04 - accuracy: 1.0000 - au - ETA: 29s - loss: 9.6051e-05 - accurac - ETA: 27s - loss: 9.7135e-05 - accuracy:  - ETA: 22s - loss: 8.1962e-05 - accuracy:  - ETA: 21s - loss: 7.8147e-05 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 7.9291e-05 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 7.7703e-05 - accuracy: 1.0000 - auc - ETA: 20s - loss: 7.5693e-05 - accuracy - ETA: 18s - loss: 6.8168e-05 - accuracy: 1.00 - ETA: 17s - loss: 6.3714e-05 - ac - ETA: 15s - loss: 6.2555e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 15s - loss: 6.1941e-05 - accuracy: 1.0000 - auc - ETA: 15s - loss: 6.4917e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 14s - loss: 6.5011e-05 - accuracy: 1.0000 -  - ETA: 14s - loss: 6.3925e-05 - accuracy: 1.0000 - - ETA: 13s - loss: 6.2346e-05 - accurac - ETA: 11s - loss: 6.0106e-05 - accuracy: 1.0000 - auc: - ETA: 11s - loss: 5.9508e-05 - accuracy: 1.0 - ETA: 10s - loss: 5.7693e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 10s - loss: 6.0039e-05 - accuracy: 1.0000 - ETA: 9s - loss: 5.9338e-05 - accuracy:  - ETA: 9s - loss: 5.8111e-05 - ac - ETA: 4s - loss: 6.3192e-05 - accuracy: 1.0000 - - ETA: 3s - loss: 6.6044e-05 - accuracy: 1.0000 - auc:  - ETA: 3s - loss: 6.5754e-05 - accu - ETA: 2s - loss: 6.4268e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 6.4117e-05 - accuracy - ETA: \n",
      "Epoch 113/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.3081e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3256 - val_accuracy: 0.4011 - val_auc: 0.6282TA: 30s - loss: 2.4329e-05 - accuracy: 1.00 - ETA: 29s - loss: 7.0026e-05 - accuracy: 1.000 - ETA: 28s - loss: 5.7357e-0 - ETA: 26s - loss: 1.5154e-04 - accuracy: 1.0000 - au - ETA: 25s - loss: 1.3761e-04 - accuracy: 1.0000 - auc - ETA: 25s - loss: 1.3014e-04 - accuracy: 1.0000 - auc: 1 - ETA: 24s - lo - ETA: 21s - loss: 0.0018 - accuracy: 0.9998 - auc: 0 - ETA: 21s - loss: 0.0018 - accuracy: 0.9998 - auc: 0.99 - ETA: 20s - loss: 0.0017 - accuracy: 0.9998  - ETA: 20s - loss: 0.0016 - accuracy: 0.9998  - ETA: 19s - loss: 0.0015 - accurac - ETA: 18s - loss: 0.0014 - accuracy: 0.9999 - auc: 0.99 - ETA: 17s - loss: 0.0014 - accuracy: 0.9999 - auc: 0.9 - ETA: 17s - loss: 0.0014 - accuracy: 0.9999 - a - ETA: 17s - loss: 0.0013 - accuracy - ETA: 15s - loss: 0.0012 - accuracy: 0.99 - ETA: 14s - loss: 0.0011 - accuracy: 0.9999 - auc:  - ETA: 14s - loss: 0.0011 - accuracy: 0.9 - ETA: 13s - loss: 0.0010 - accuracy - ETA: 11s - los - ETA: 1s - loss: 6.592\n",
      "Epoch 114/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.5283e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.6648 - val_accuracy: 0.4157 - val_auc: 0.6233A: 29s - loss: 8.6057e-05 - accuracy: 1.0000 -  - ETA: 28s - loss: 6.5016e-05 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 6.0196e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 5.8658e-05 - accuracy: 1.0000 - auc - ETA: 27s - loss: 5.5459e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 27s - loss: 5.2800e-0 - ETA: 25s - loss: 6.2256e-05 - accuracy: - ETA: 24s - loss: 1.6181e-04 - accuracy: 1. - ETA: 22s - loss: 1.4482e-04 -  - ETA: 21s - loss: 1.2403e-04 - accuracy: 1.0000 - - ETA: 20s - loss: 1.2075e-04 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 1.1909e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - loss: 1.1849e-04 - accurac - ETA: 18s - loss: 1.0760e-04 - accuracy: 1.0000 - au - ETA: 18s - loss: 1.0386e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 17s - loss: 1.0948e-04 - accuracy: 1.0000 - ETA: 17s - loss: 1.0467e-04 - accuracy: 1.0000 - - ETA: 16s - loss: 1.0509e-04 - accuracy: 1.0000 -  - ETA: 15s - loss: 1.9897e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 15s - loss: 1.9821e-04 - accuracy: 0.9999 - auc: 1 - ETA: 15s - loss: 1.9397e-04 - accuracy: 0.9999 - auc - ETA: 14s - loss: 1.9351e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 14s - loss: 1.9172e-04 - ac - ETA: 12s - loss: 1.8252e-04 - accuracy: 0.9999 - - ETA: 12s - loss: 1.7708e-04 - accu - ETA: 10s - loss: 1.653 - ETA: 9s - loss: 1.5709e-04 - accuracy:  - ETA: 8s - loss: 1.5395e-04 - accuracy:  - ETA: 7s - loss: 1.5003e-04 - accuracy: 0.99 - ETA: 7s - loss: 1.4711e-04 - accuracy: 0.9999 - a - ETA: 6s - loss: 1.4555e-04 - accuracy:  - ETA:  - ETA: 2s - loss: 1.6443e-0 - ETA: 1s - loss: 1.5923e-04 - accuracy: 0.99 - ETA: 0s - loss: 1.5733e-04 \n",
      "Epoch 115/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.0965e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3417 - val_accuracy: 0.4027 - val_auc: 0.628088e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 27s - loss: 3.6117e-04 - accur - ETA: 25s - loss:  - ETA: 22s - loss: 2.2040e-04 - accuracy - ETA: 21s - loss: 2.4057e-04 - accuracy: 1.0000 - auc: - ETA: 21s - loss: 2.3176e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 21s - loss: 2.3045e-04 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 2.2381e-04 - accuracy: 1.0000 - ETA: 19s - loss: 2.0839e-04 - accuracy: 1.0000 - auc: - ETA: 19s - loss: 2.0254e-04 - accuracy: 1.0000 - au - ETA: 19s - loss: 1.9481e-04 - accuracy: 1.0000 - a - ETA: 18s - loss: 1.8740e-04 - accuracy: 1.0000 - auc: 1. - ETA: 18s - loss: 1.8432e-04 - accuracy: 1.0000 - auc - ETA: 17s - loss: 1.7848e-04 - accuracy: - ETA: 12s - loss: 1 - ETA: 5s - loss: 1.2488e-04 - accuracy - ETA: 4s - loss: 1.2177e-04 - accuracy: 1.0000 - - ETA: 4s - loss: 1.2021e-04 - accuracy: 1.0000 - auc: 1. - ETA: 4s - loss: 1.2000e-04 - accuracy: 1.0000 - auc - ETA: 4s - loss: 1.1914e-04 - accuracy: 1.00 - ETA: 3s - loss: 1.1722e-04 - accuracy: 1.0000 - auc: 1. - ETA: 3s - loss: 1.1703e-04 - accuracy: 1.0000 - ETA: 3s - loss: 1.1515e-04 - accu - ETA: 2s - loss: 1.1276e-04 - accuracy: 1.0000 - auc - ETA: 1s - loss: 1.1173e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 1.1151e - ETA: 0s - loss: 1.0965e-04 - accuracy: 1.0000 - - ETA: 0s - loss: 1.0972e-04 - accuracy: 1.0000 - auc: 1.\n",
      "Epoch 116/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.5472e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3215 - val_accuracy: 0.3966 - val_auc: 0.627822s - loss: 2.9908e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 22s - loss: 2.9777e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 22s - loss: 2 - ETA: 19s - loss: 2.6832e-04 - accuracy: 0.9998 - a - ETA: 18s - ETA: 15s - loss: 2.2993e- - - ETA: 7s - loss: 1.7912e-04 - ac - ETA: 6s - loss: 1.8545e-04 - accuracy: 0.9999 - ETA: 6s - los - ETA: 5s - loss: 1.7455e-04 - accuracy:  - ETA: 2s - loss: 1.6422e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 2s - loss: 1.6404e-04 -  - ETA: 1s - loss: 1.6022e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 1.5848e-04 - ac\n",
      "Epoch 117/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.3112e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3374 - val_accuracy: 0.4061 - val_auc: 0.6351 ETA: 26s - loss: 2.3684e-04 - accuracy: 1.0000 - auc - ETA: 26s - loss: 2.1171e-04 - accuracy: 1.0000 - auc: - ETA: 25s - loss: 1.9611e-04 - accuracy: 1.0000 - a - ETA: 25s - loss: 1.8544e-04 - accuracy: - ETA: 23s - loss: 1.6079e-04 - accuracy: 1.0000 - - ETA: 23s - loss: 1.5632e-04 - accuracy: 1.0000 -  - ETA: 22s - loss: 1.4609e-04 - accuracy: - ETA: 21s - loss: 1.3188e-04 - accuracy: 1.0000 -  - ETA: 20s - loss: 1.2528e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - los - ETA: 17s - loss: 1.1211e-04 - accuracy: 1.0000 -  - E - ETA: 13s - loss: 3.4673e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 13s - loss: 3.4451e-04 - accuracy: 0.999 - ETA: 12s - loss: 3.3034e-04 - acc - ETA: 10s - loss: 3.0522e-04 - - ETA: 2s - loss: 2.3918e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 2s - loss: 2.3867e-04 - accuracy: 0.9999 - auc - ETA: 2s - loss: 2.4586e-04 - accuracy: 0.99 - ETA: 0s - loss: 2.3209e-04 - accuracy: 0.9999 - auc: \n",
      "Epoch 118/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.3244e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.1445 - val_accuracy: 0.4080 - val_auc: 0.6380A: 26s - loss: 3.1813e-05 - accuracy: 1.0000 - auc: 1 - ETA: 25s - loss: 3.1195e-05 - accuracy: 1.000 - ETA: 25s - loss: 3.2877e-05 - accuracy: 1.00 - ETA: 24s - loss: 3.3729e-05 - accuracy: 1.0000 - auc:  - ETA: 23s - loss: 7.0090e-05 - accuracy: 1.0000 - auc: - ETA: 23s - loss: 6.8142e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 6.7933e-05 - accuracy - ETA: 21s - loss: 6.7632e-05 - accurac - ETA: 20s - loss: 6.1462e-05 - accuracy - ETA: 18s - loss: 7.7970e-05 - accuracy: 1 - ETA: 17s - loss: 7.4088e-05 - accurac - ETA: 16s - loss: 2.5496e-0 - ETA: 14s - loss: 2.3853e-04 - accuracy: 0.9999 - auc: 1. - ETA: 13s - loss: 2.3546e-04 - accuracy: 0.9999 - au - ETA: 13s - loss: 2.2848e-04 - accuracy: 0.9999 - auc: - ETA: 12s - loss: 2.2392e-04 - accuracy: 0.9999 - a - ETA: 12s - loss: 2.1660e-04 - accuracy: 0.9999 - auc: 1.000 - ETA:  - ETA: 5s - loss: 2.6\n",
      "Epoch 119/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.4291e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3424 - val_accuracy: 0.4146 - val_auc: 0.6334TA: 32s - loss: 1.299 - ETA: 28s - loss: 2.7041e-05 - accuracy: 1.0000 - auc:  - ETA: 27s - loss: 2.7769e-05 - accur - ETA: 26s - loss: 3.6436e-05 - a - ETA: 24s - loss: 3.5736e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 3.5426e-05 - accuracy - ETA: 23s - loss: 4.2257e-05 - accuracy: 1.0000 - a - ETA: 22s - loss: 4.2743e-05 - accuracy: 1.000 - ETA:  - ETA: 18s - loss: 4.0133e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 17s - loss: 3.9605e-05 - accuracy: 1.00 - ETA: 16s - loss: 3.9233e-05 - acc - ETA: 15s - loss: 4.9764e-05 - accuracy: 1.0000 - auc:  - ETA: 14s - loss: 4.8950e-05 - accuracy: 1 - ETA: 13s - loss: 4.8856e-05 -  - ETA: 11s - loss: 4.9 - ETA: 7s - ETA: 0s - loss: 8.4346e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 120/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.8344e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2885 - val_accuracy: 0.4073 - val_auc: 0.63508e-04 - ac - ETA: 22s - loss: 9.8285e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 9.8074e-05 - accuracy: 1.0000 - auc: 1. - ETA: 22s - loss: 9.5985e-05 - accuracy: 1.0000 - auc: 1. - ETA: 21s - loss: 1.0486e-04 - accuracy: 1.0 - ETA: 20s - loss: 1.0004e-0 - ETA: 18s - loss: 8.6846e-05 - accuracy: 1.0000 - auc: 1 - ETA: 18s - loss: 8.5255 - ETA: 16s - loss: 9.2308e-05 - accuracy: 1.0000 - au - ETA: 15s - loss: 9.1367e-05 - a - ETA: 13s - loss: 8.4619e-05 - accuracy: 1.0000 - auc: 1. - ETA: 13s - loss: 8.3672e-05 - accuracy: 1.000 - ETA: 12s - loss: 8.1655e-05 - accuracy: 1.0000 - auc: - ETA: 12s - loss: 8.1508e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 12s - loss: 8.1509e-05 - accuracy: 1.0000 -  - ETA: 11s - loss: 7.9142e-05 - accuracy: 1.0000 - auc - ETA: 10s - loss: 7.7585e-05 - accuracy: 1.0000 - auc - ETA: 4s - los - ETA: 0s - loss: 7.8945e-05 - accura\n",
      "Epoch 121/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.1156e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.2710 - val_accuracy: 0.4050 - val_auc: 0.634728s - loss: 1.5383e-05 - - ETA: 26s - loss: 3.6862e-05 - accuracy: 1.0000  - ETA: 25s - loss: 3.2535e-05 - accuracy: 1.00 - ETA: 24s - loss: 3.4887e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 3.4569e-05 - accuracy: 1.0000 - a - ETA: 23s - lo - ETA: 17s - loss: 1.6498e-04 - accur - ETA: 15s - loss: 1.5519e-04 - accuracy: 0.9999 - - ETA: 14s - loss: 1.4860e-04 - accuracy: 0.9999 - auc: 1 - ETA: 14s - loss: 1.4709e-04 - accuracy: 0.999 - ETA: 13s - loss: 1.4042e-04 - accuracy:  - ETA: 12s - loss: 1.3869e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 11s - loss: 1.5809e-04 - - ETA: 9s - loss: 1.4289e-04 - accuracy: 0.9999 - auc - ETA: 9s - loss: 1.4102e-04  - ETA: 8s - loss: 1.3707e-04 - accuracy: 0.9999 - ETA: 8s - loss: 1 - ETA: 6s - loss: 1.2965e-04 - accuracy - - ETA: 4s - loss: 1.2300e-04 - accuracy: 0.9999 - - ETA: 3s - loss: 1.2155e-0 - ETA: 2s - loss: 1.1855e-04 - accuracy: 0.9999 - ETA: 2s - loss: 1.1694e-04 - accuracy - ETA: 1s - loss: 1.146 - ETA: 0s - loss: 1.1219e-04 - accuracy: 0.9999 - auc\n",
      "Epoch 122/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.0554e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3043 - val_accuracy: 0.4084 - val_auc: 0.635230s - loss: 2.126 - ETA: 27s - loss: 1.55 - ETA: 25s - loss: 4.51 - ETA: 22s - loss: 5.3116e-05 - accuracy: 1.000 - E - ETA: 1s - loss: 1.0805e-04 - accuracy - ETA: 1s - loss: 1.0675e-04 - accuracy: 1.00 - ETA: 0s - loss: 1.0613e-04 - accuracy: 1.\n",
      "Epoch 123/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9108e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3598 - val_accuracy: 0.4077 - val_auc: 0.63428.5240e-05 - accuracy: 1.0000 - ETA: 28s - loss: 6.5784e-05 - accuracy: 1.0000 - auc:  - ETA: 27s - loss: 6.7578e-05 - accura - ETA: 26s - loss: 6.4612e-05 - accuracy: 1.0000 -  - ETA: 25s - ETA: 22s - loss: 4.5735e-05 - accuracy: 1 - ETA: 21s - loss: 4. - ETA: 18s - loss: 5.2385e-05 - accuracy: 1.0000 - - ETA: 17s - loss: 2.4647e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 17s - loss: 2.4341e-04 - ac - ETA: 15s - loss: 2.2150e-04 - accuracy: 0.999 - ETA: 14s - loss: 2.1208e-04 - accuracy: 0.9999 - auc - ETA - ETA: 10s - loss: 1.9984e-04 - accuracy: 0.9999 - au - ETA: 9s - loss: 1.9653e-04 - accuracy - ETA: 9s - loss: 1.9 - ETA: 7s - loss: 2.4740e-04 - accuracy: 0.9999 - a - ETA: 7s - loss: 2.4475e-04 - accuracy: 0.9999 - auc:  - ETA: 7s - loss: 2.4297e-04 - accuracy - ETA: 2s - loss: 2.0768e-04 - accuracy: 0.9999 - auc:  - ETA: 2s - loss: 2.0641e-04 - accuracy: 0.9999 - a - ETA: 0s - loss: 1.9352e-04 - accuracy: 0.99\n",
      "Epoch 124/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 9.5812e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4650 - val_accuracy: 0.4165 - val_auc: 0.632829s - loss: 2.4980e-05 - accuracy: 1.0000 -  - ETA: 20s - loss: 8.1015e-05 - accuracy: - ETA: 19s - loss: 8.1227e-05 - accuracy: 1.0000 - au - ETA: 19s - loss: 8.0906e-05 - accur - ETA: 17s - loss: 8.6217e-05 - accuracy: 1.0000 - auc: 1. - ETA: 17s - loss: 8.4945e-05 -  - ETA: 15s - loss: 8.1549e-05 - accuracy: 1.0000 - auc - ETA: 14s - loss: 7. - ETA: 12s - loss: 9.3399e-05 - accuracy: 1.0000 - auc - ETA: 11s - loss: 9.2106e-05 - ac - ETA: 9s - loss: 9.9127e-05 - accuracy: 1.0000 - auc - ETA: 9s - l - ETA: 6s - loss: - ETA: 4s - loss: 9 - ETA: 3s - loss: 9.6169e-05 - accuracy: 1.00 - ETA: 2s - loss: 9.7513e-05 - accuracy - ETA: 1s - loss: 9.6121e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 9.5931e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 9.573 - ETA: 0s - loss: 9.5678e-05 - accura\n",
      "Epoch 125/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.1578e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4951 - val_accuracy: 0.4146 - val_auc: 0.6312 - loss: 6.5106 - ETA: 24s - loss: 5.3802e-05 - accuracy: 1.0000 - auc: 1. - ETA: 24s - loss: 5.2622e-05 - ETA: 22s - loss - ETA: 18s - loss: 7.0530e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 18s - loss: 6.9920e-05 - accuracy: 1.0000 -  - ETA: 18s - loss: 1.1440e-04 - accuracy: 1.0000 - auc: - ETA: 17s -\n",
      "Epoch 126/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.7177e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3131 - val_accuracy: 0.4080 - val_auc: 0.6365loss: 2.9983e-05 - accuracy: 1.0000 - auc: 1. - ETA: 25s - loss: 2.8580e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 25s - loss: 2.7632e-05 - ac - ETA: 23s - loss: 2.8686e-05 - accuracy: 1.0000 - auc: 1 - ETA: 23s - loss: 2.8459e-05 - accuracy: 1.0000 - auc: - ETA: 22s - loss: 2.7929e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 2.7926e-05 - accu - ETA: 21s - loss: 3.6300e-05 - accuracy: 1.0000 - a - ETA: 20s - loss: 3.8980e-05 - acc - ETA: 19s - loss: 8.8085e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 8.7386e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 8.6262e-05 - accurac - ETA: 17s - loss: 8.7225e-05 - accuracy: 1.0000 - auc: 1. - ETA: 17s - loss: 8.6752e-05 - accuracy: 1.0000 - auc:  - ETA: 16s - loss: 8.4603e-05 - accuracy: - ETA: 15s - loss: 8.3771e-05 - accuracy: 1.0000 -  - ETA: 14s - loss: 8.4319e-05 - accuracy: 1.0000  - ETA: 13s - loss: 8.0500e-05 - accuracy: 1.0000 - auc:  - ETA: 13s - loss: 7.9218e-05 - ETA: 2s - loss: 8.2574e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 8.2436e-05 - accuracy: 1.0000 - a - ETA: 2s - loss: 8.1563e-05 - accuracy - ETA: 1s - loss:\n",
      "Epoch 127/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.6144e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4560 - val_accuracy: 0.3981 - val_auc: 0.6309l - ETA: 26s - loss: 1.0441e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 1.0355e-04 - accuracy: 1.0000 - au - ETA: 26s - ETA: 18s - loss: 3. - ETA: 4s - loss: 1.8568e-04 - accuracy: 0.9999 - - ETA: 4s - loss: 1.8285e-04 - accura - ETA: 3s - loss: 1.7788e-0 - ETA: 2s - loss: 1.7262e-04 - accuracy: 0.9999 - auc - ETA: 2s - loss: 1.7086e-04 - accuracy: 0.9999 - auc:  - E\n",
      "Epoch 128/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.2508e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4093 - val_accuracy: 0.4031 - val_auc: 0.631428s - loss: 1.6316e-04 - accur - ETA: 2 - ETA: 23s - loss: 1.0348e-04 - accuracy - ETA: 22s - loss: 8.9748e-05 - accuracy: - ETA: 21s - loss: 9.2835e-05 - accuracy: 1.0000 - auc:  - ETA: 20s - loss: 9.0311e-05 - accuracy:  - ETA: 15s - loss: 7.3215e-05 - accuracy: 1.0000 - auc: 1 - ETA: 15s - loss: 7.1896e-05 - accur - ETA: 13s - loss: 7.2933e-05 - a - ETA: 11s - loss: 6.9598e-05 - accuracy: 1.0000 - auc - ETA: 11s - loss: 6.7705e-05 - accuracy: 1.0000 - auc: 1 - ETA: 10s - loss: 6.6800e-05 - accuracy: 1.0000 - ETA: 10s - loss: 6.4713e-05 - accuracy: 1.0 - ETA: 9s - loss: 6.7410e-05 - accuracy:  - ETA - ETA: 7s - loss: 9.9121e-05 - accu - ETA: 6s - loss: 9.6638e-05 - accuracy: 1.0000 - auc:  - ETA: 4s - loss: 9.2571e - ETA: 2s - loss: 8.9487e-05 - accuracy: 1.0000 - auc - ETA: 2s - loss: 8.8760e-05 - accuracy: 1.0000 - - ETA: 2s - loss: 8.7726e-05 - accura - ETA: 1s - loss: 8.5773e-05 - ac - ETA: 0s - loss: 8.3748e-05 - accuracy: 1.00 - ETA: 0s - loss: 8.2835e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 8.2545e-05 - accuracy: 1.0000 - auc: \n",
      "Epoch 129/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.0386e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5518 - val_accuracy: 0.4115 - val_auc: 0.6265: 1.0000 - auc: 1.000 - ETA: 28s - loss: 9.9995e-06 - - ETA: 26s - loss: 2.9560e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 3.2778e-05 - accuracy: 1.0000 - au - ETA: 25s - loss: 3.2073e-05 - accuracy: 1.0000 - auc: - ETA: 25s - loss: 3.4544e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 25s - loss: 3.6558e-05\n",
      "Epoch 130/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.4673e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5514 - val_accuracy: 0.4169 - val_auc: 0.6360 30s - loss: 6.7615e-06 - accuracy: 1.0000 - auc: 1. - ETA: 30s - loss: 6.9690e-06 - accurac - ETA: 28s - loss: 7.2356e-04 - accuracy: 0.9991 - auc: 1.000 - ETA: 29s - loss: 7.0418e-04 - acc - ETA: 27s - loss: 3.9693e-04 - accuracy: 0.9995 - auc - ETA: 26s - loss: 3.5761e-04 - accuracy - ETA: 25s - loss: 2.7717e-04 - - ETA: 23s - loss: 2.1368e-04 - accuracy: 0 - ETA: 22s - loss: 1.9061e-04 - accuracy: 0.9998 - - ETA: 21s - loss: 1.7642e-04 - accuracy: 0.9998 - auc: 1 - ETA: 20s - loss: 1.6999e-04 - accuracy:  - ETA: 19s - loss: 1.5190e-04 - accuracy: 0.9998 - auc: 1. - ETA: 19s - loss: 1.4892e-04 -  - ETA: 17s - loss: 1.4538e-04 - accuracy: 0.9999 - auc:  - ETA: 16s - loss: 1.4561e-04 - accuracy: 0.9999 - auc:  - ETA: 16s - loss: 1.4229e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 16s - loss: 1.4077e-04 - accuracy: 0.9999 - - ETA: 15s - loss: 1.3619e-04 - accuracy: 0.9999 - ETA: 14s - loss: 1.2918e-04 - accuracy: 0.9999 -  - ETA: 13s - loss: 1.3433e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 13s - loss: 1.3342e-04 - accuracy: 0. - ETA: 12s - loss: 1.2663e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 12s - loss: 1.258 - ETA: 10s - loss: 1.1469e-04 - accuracy: 0.9999 - auc: - ETA: 9s - los - - ETA: 0s - loss: 3.4823e-04 - accuracy: 0.9999 - auc: \n",
      "Epoch 131/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.3860e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3154 - val_accuracy: 0.4134 - val_auc: 0.63876s - loss: 1.6325e-04 - accuracy: 1 - ETA: 25s - loss: 1.3438e-04 - accuracy: 1.00 - ETA: 23s - loss: 1.1795e-04 - accuracy: 1.0000 - auc: - ETA: 23s - loss: 1.1261e-04 - accuracy: - ETA: 22s - loss: 9.8736e-05 - accuracy: 1.0000 - auc: 1. - ETA: 22s - loss: 9.6385e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 9.5150e-05 - accuracy: 1.0000 -  - ETA: 21s - loss: 9.2821e-05 - accuracy: 1.0000 - - ETA: 20s - loss: 8.6886e-05 - ac - ETA: 18s - loss: 8.0632e-05 - accuracy: 1.0000 - - ETA: 17s - loss: 7.6578e-05 - accuracy: 1.0000 - auc: 1. - ETA: 17s - loss: 7.5740e-05 - accuracy: 1.0000  - ETA: 16s - loss: 7.8987e-05 - accuracy: 1.0000 - a - ETA: 15s - loss: 7.7024e-05 - accuracy: 1.0000 - auc:  - ETA: 15s - loss: 7.5335e-05 - accuracy: 1.0000  - ETA: 14s - loss: 7.2392e-05 - accuracy - ETA: 13s - loss: 7.0530e-05 - accuracy: 1.0000 -  - ETA: 1s - loss: 8.1731e-05 - accura - ETA: 0s - loss: 8.0006e-05 - accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.0901e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2881 - val_accuracy: 0.4119 - val_auc: 0.6385oss: 3.9767e-05 - accuracy: 1.0 - ETA: 28s - loss: 3.5881e-05 - accuracy: 1.0000 - auc:  - ETA: 28s - loss: 3.1502e-05 - accuracy: 1.0000 - auc:  - ETA: 28s - loss: 4.0537e-05 -  - ETA: 26s - loss: 3.0128e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 2.9827e-05 - accura - ETA: 24s - loss: 1.4277e-04 - accuracy: 1.0000 - auc:  -  - ETA: 16s - loss: 1.2998e-04 - accuracy: - ETA: 14s - loss: 1 - ETA: 12s - loss: - ETA: 9s - loss: 1.1557e-04 - accuracy: 1.0000 - a - ETA: 9s - loss: 1.1439e-04 - accuracy: 1. - ETA: 8s - loss: 1.1137e-04 - accuracy: 1.0000 - - ETA: 8s - loss: 1.0978e-04 - accuracy: 1.0000 - a - ETA: 8s - loss: 1.0908e - ETA: 7s - loss: 1.2682e-04 - accuracy: 1.0000 - ETA: 6s - loss: 1.2461e-04 - accuracy: 1.0000 - ETA: 6s - loss: 1.2268e-04 - accuracy:  - ETA: 5s - ETA: 3s - loss: 1.1822e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 1.1904e-04 - accuracy: 1.0000 - - ETA: 3s - loss: 1.1842e-04 - accu - ETA: 2s - loss: 1.1600e-04  - ETA: 1s - loss: 1.1223e-04 - accuracy: 1.0000 - auc - ETA: 1s - loss: 1.1219e-04 - accura - ETA: 0s - loss: 1.0983e-04 - accuracy: 1.0000 - auc - ETA: 0s - loss: 1.0926e-04 - accuracy: 1.0000 - auc: 1.\n",
      "Epoch 133/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.2047e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3034 - val_accuracy: 0.4119 - val_auc: 0.6386e-05 - accuracy: 1.0000 - - ETA: 21 - ETA: 17s - loss: 7.9306e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 17s - loss: 7.8399e-05 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 7.9318e-05 - accuracy: 1.0000 - au - ETA: 16s - l - ETA: 13s - loss: 6.9251e-05 - accuracy: 1.00 - ETA: 12s - loss: 6.5929e-05 - accuracy: 1.0000 - ETA: 11s - loss: 6 - ETA: 7s - loss: 5.7466e-05 - accuracy:  - E - ETA: 1s - loss: 5.2100e-05 - accuracy: 1.0000 - auc - ETA: 1s - loss: 5.2134e-05 - accuracy - ETA: 0s - loss: 5.1847e-05 - accuracy: 1.0000 - a - ETA: 0s - loss: 5.2278e-05 - accuracy: 1.0000 - a\n",
      "Epoch 134/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.3261e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7204 - val_accuracy: 0.4119 - val_auc: 0.6292: 28s - loss: 1.6606e-05 - accuracy: 1.0000 - au - ETA: 28s - loss: 1.7544e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 27s - loss: 1.6927e-05 - accuracy: 1.0000  - ETA: 27s - loss: 1.9160e-05 -  - ETA: 25s - loss: 3.3280e-05 - accuracy: 1.0000 - auc: 1 - ETA: 24s - loss: 3.1800e-05 - accuracy: 1.0 - ETA: 23s - loss: 2.9617e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 23s - loss: 3.0499e-05 - accuracy: 1.0000 - au - ETA: 23s - loss: 2.9002e-05 - accuracy: 1.0000 - a - ETA: 22s - loss: 3.1388e-05 - accuracy:  - ETA: 17s - loss: 3.4598e-05 - accuracy: 1.0000 - auc - ETA: 16s \n",
      "Epoch 135/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.9094e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4826 - val_accuracy: 0.4172 - val_auc: 0.6365TA: 30s - loss: 6.6821e-06 - a - ETA: 28s - loss: 2.1456e-05  - ETA: 26s - loss: 3.6080e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 26s - loss: 3.5258e-05 -  - ET - ETA: 20s - loss: 6.8317e-05 - accuracy: 1.0000 - - ETA: 19s - loss: 8.3012e-05 - accuracy: 1.0000 - auc: 1. - ETA: 19s - loss: 8.1488e-05 - accuracy: 1.0000 - auc: 1. - ETA: 19s - loss: 8.4778e-05 -  - ETA: 17s - loss: 7.5290e-05 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 7.3787e-05 - accuracy: 1.0000 - - ETA: 16s - loss: 7.2393e-05 - acc - ETA: 14s - loss: 6.6786e-05 - accuracy: 1.0000 - - ETA: 13s - loss: 6.4276e-05 - accuracy: 1. - ETA: 12s - loss: 6.3035e-05 - accur - ETA: 10s - loss: 6.4012e-05 - accuracy - ETA: 9s - loss: 6.4063e-05 - accuracy:  - ETA: 5s - loss: 6.0254e-05 - accu - ETA: 4s - loss: 5.9022e-05 - accuracy - ETA: 3s - loss: 6.3363e-05 - accuracy: 1.0000 - a - ETA: 3s - loss: 6.2580e-05 - accu - ETA: 2s - loss: 6.1783e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 6.1654e-0 - ETA: 1s - loss: 6.0191e-05 - accuracy:  - ETA: 0s - loss: 5.9053e-05 - accuracy:  - ETA: 0s - loss: 5.9234e-05 - accuracy: 1.0000 - auc: 1.\n",
      "Epoch 136/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.8083e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7197 - val_accuracy: 0.4138 - val_auc: 0.6346A: 30s - l - ETA: 27s - loss: 1.5353e-05 - accuracy: 1.00 - ETA: 26s - loss: 1.7090e-05 - accuracy: - ETA: 25s - loss: 1.6616e-05 - accuracy: 1.0000 - auc: - ETA: 20s - loss: 3.983 - ETA: 18s - loss: 3 - ETA: 15s - loss: 2.8970e-04 - accuracy: 0.99 - ETA: 14s - loss: 2.7498e-04 - accu - ETA: 12s - loss: 2.5400e-04 - accuracy: 0.99 - ETA: 11s - loss: 2.4196e-04 - accura - ETA: 5s - loss: 2 - ETA: 0s - loss: 2.8353e-04 - accuracy: 0.9999\n",
      "Epoch 137/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.8961e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6572 - val_accuracy: 0.4161 - val_auc: 0.63416053e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 5.3 - ETA: 25s - loss: 3.8323e-05 - accuracy - ETA: 24s - loss: 3.3854e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 3.3567e-05 - accuracy: 1.0000 - auc: 1 - ETA: 24s - loss: 3.2350e-05 - accur - ETA: 22s - loss: 3.90 - ETA: 20s - loss: 3.8159e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 3.8722e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 3.8553e-05  - ETA: 17s - loss: 3.4438e-05 -  - ETA: 15s - loss: 3.3293e- - ETA:  - ETA: 4s - loss: 4.8110e-05 - accu - ETA: 3s - loss: 4.8422e-05 - accuracy: 1.00 - ETA: 0s - loss: 4.9600e-05 - ac\n",
      "Epoch 138/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.7365e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3262 - val_accuracy: 0.4215 - val_auc: 0.6388oss: 9.5362e-06 - accuracy: 1.0000 - auc - ETA: 29s - - ETA: 17s - loss: 4.0724e-05 - accuracy: 1. - ETA: 16s - loss: 4.0866e-05 - accuracy: 1. - ETA: 15s - loss: 3.9814e-05 -  - ETA: 5s - loss: 6.7180e-05 - accuracy: 1.0000 - auc:  - ETA: 5s - loss: 6.6786e-05 - accuracy: 1.0000 - a - ETA: 4s - loss: 6.6151e-05 - accuracy: 1.0000 - ETA: 4s - loss: 1.9755e-04 - accuracy: 0.9999 - auc: 1. - ETA: 4s - loss: 1.9671e-0 - ETA: 3s - loss: 1.898 - ETA: 2s - loss: 1.8518e-04 - accuracy: 0. - ETA: 1s - loss: 1.8199e-0 - ETA: 0s - loss: 1.7680e-04 - accuracy: 0.9999 - auc:  - ETA: 0s - loss: 1.7578e-04 - accuracy: 0.99\n",
      "Epoch 139/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.2281e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3570 - val_accuracy: 0.4142 - val_auc: 0.6406A: 31s - loss: 2.0334e-05 - accuracy: 1.00 - ETA: 29s - loss: 6.5259e-05 -  - ETA: 27s - loss: 6.3202e-05 - accuracy:  - ETA: 26s - loss: 5.7989e-05 - accuracy: 1.0000  - ETA: 25s - loss: 6.9654e-05 - accuracy: - ETA: 24s - loss: 2.5304e-04 - accuracy: 1 - ETA: 23s - loss: 2.2941e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 2.2782e-04 - accuracy: 1.0000 - - ETA: 22s - loss: 2.1008e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 2.0865e-04 - accuracy: 1.0000 - ETA: 21s - loss: 1.9169e-04 - accuracy:  - ETA: 20s - loss: 1.7516e-04 - accuracy: 1. - ETA: 19s - loss: 1.6115e-04 - accurac - ETA: 17s - - ETA: 14s - loss: 1.2679e-04 - accuracy: - ETA: 13s - loss: 1.1974e-04 - accuracy: 1.0000 - auc:  - ETA: 12s - loss: 1.1757e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 12s - loss: 1 - ETA: 9s - loss: 1.0429e-04 - accur - ETA: 9s - loss: 1.0174e-04 - accuracy: 1.0000 - auc:  - ETA: 9s - loss: 1.0095e-04 - accuracy - ETA: 8s - loss: 9.7996e-05 - accuracy: 1.0000 - a - ETA: 7s - loss: 9.6976e - ETA: 6s - loss: 9.3677e-05 - accu - ETA: 5s - loss: 9.0779e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 5s - - ETA: 4s - loss: 9.1289e-05 - accuracy:  - ETA: 3s - loss: 8.9505e-05  - ETA: 0s - loss: 8.3709e-05 - accuracy: 1.\n",
      "Epoch 140/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 1.3663e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.3659 - val_accuracy: 0.4073 - val_auc: 0.638621s - loss: 2.7877e-04 - accuracy: - ETA: 19s - loss: 2.4792e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 2.5774e-04 - accuracy: 1.0000 - a - ETA: 18s - loss: 2.4557e-04 - accuracy: 1.0000 - - ETA: 18s - loss: 2.3154e-0 - ETA: 16s - loss: 2.1845e-04 - accuracy: 1.0000 - auc: 1 - ETA: 15s - loss: 2.2069e-04 - accuracy: 1.0000  - ETA: 15s - loss: 2.1347e-04 - accuracy: 1.0000 - - ETA: 14s - loss: 2.0462e-04 - accuracy: 1.0000 - a - ETA: 13s - loss: 1.9785e-04 - accuracy: 1.0000 - auc - ETA: 13s - loss: 1.9281e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 12s - loss: 1.9585e-04 - accuracy: - ETA: 11s - loss: 1.8320e-04 - accuracy: 1.00 - ETA: 10s - loss: 1.7950e-04 - accuracy: 1.0000 - auc - ETA: 9s - loss: 1.7568e-0 - ETA: 8s - loss: 1.6694e-0 - ETA: 7s - loss: 1.6171e-04 - accuracy: 1. - ETA: 7s - loss: 1.6453e-04 - accura - ETA: 6s - loss: 1.6028e-0 - ETA: 5s - loss: 1.5561e-04 - ac - ETA: 4s - loss: 1 - ETA: 3s - loss: 1.5015e-04 - accuracy: 1.0000 - ETA: 2s - loss: 1.4801e-04 - accuracy - ETA: 1s - loss: 1.4472e - ETA: 0s - loss: 1.3938e-04 - accuracy:  - ETA: 0s - loss: 1.3724e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 1.3697e-04 - accuracy: 1.0000 - auc: 1.\n",
      "Epoch 141/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.2984e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5970 - val_accuracy: 0.4157 - val_auc: 0.6370 30s - loss: 2.0593e-05 - accuracy: 1.0000 - auc: 1 - ETA: 30s - loss: 1.582 - ETA: 27s - loss: 1.4265e-05 - accuracy: 1.0000 - - ETA: 26s - loss: 4.1962e-04 - accuracy: 0.9995 - au - ETA: 26s - loss: 3.7937e-04 - accuracy: 0.9996 - au - ETA: 25s - loss: 3.4115e-0 - ETA: 23s - loss: 2.4196e-04 - accura - ETA: 21s - loss: 2.032 - ETA: 19s - loss: 1.6438e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 19s - loss: 1.6481e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 19s - loss: 1.6397e-04 - accuracy - ETA: 18s - loss: 1.5101e-04 - accuracy: 0.9999 - ETA: 17s - loss: 1.45 - ETA: 14s - loss: 1.4683e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 14s - loss: 1.4635e-04 - accuracy: 0.9999 -  - ETA: 13s - loss: 1.4258e-04 - accuracy: 0.9999 - - ETA: 13s - loss: 1.3963e-04 -  - ETA: 11s - loss: 1.2826e-0 - ETA: 9s - loss: 1.2322e-04 - accuracy:  - ETA: 8s - loss: 1.1985e-04 - accuracy: 0.9999 - ETA: 8s - los - ETA: 4s - loss: 1.0588e-04 - accu - ETA: 4s - loss: 1.4311e-04 - accuracy: 0.9999 - auc - ETA: 3s - loss: 1.4242e-04 - accuracy: 0.9999 - ETA: 3s - loss: 1.4063e-04 - accuracy: 0.9999 - auc - ETA: 3s - l - ETA: 1s - loss: 1.3351e-0 - ETA: 0s - loss: 1.2953e-04 - accuracy: \n",
      "Epoch 142/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.4139e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5922 - val_accuracy: 0.4218 - val_auc: 0.6386.3435e-04 - accuracy: 1.0000 - au - ETA: 28s - loss: 1.9389e-04 - accuracy: 1.0000 - a - ETA: 27s - loss: 1.6102e-04 - accuracy - ETA: 26s - loss: 1.1869e-04 - accuracy: 1.0000 - auc: 1.000 - - ETA: 22s - loss: 7.5076e-05 - accur - ETA: 20s - loss: 6.7584e-05 - accuracy: 1.0000 - auc: - ETA: 20s - loss: 6.5621e-05 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 6.3732e-05 - accuracy: 1.0000 - auc: - ETA: 19s - loss: 0.0011 - accuracy: 0.9998 - auc - ETA: 19s - loss: 0.0011 - accuracy: 0.9998 - - ETA: 18s - loss: 0.0010 - accuracy: 0. - ETA: 17s - loss: 9.2 - ETA: 14s - loss: 7.8851e-04 - accuracy: 0.9999  - ETA: 13s - loss: 7.5029e-04 - accuracy:  - ETA: 12s - loss: 6. - ETA: 10s - loss: 6.2714e-04 - accuracy: 0.9999 - a - ETA: 9s - loss: 6.1 - ETA: 8s - ETA: 6s - loss: 5.4457e-0 - ETA - ETA: 1s - loss: 4.6840e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 1s - loss: 4.6750e-04 - accu - ETA: 1s - loss: 4.5553e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 4.5106e-04 - accuracy - ETA: 0s - loss: 4.4167e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 143/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.9105e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5071 - val_accuracy: 0.4123 - val_auc: 0.6243 21s - loss: 8. - ETA: 19s - loss: 7.6662e-05  - ETA: 17s - loss: 7.9439e-05 - accuracy: 1.0000 - ETA: 16s - loss: 7.5246e-05 - accuracy: 1.0000 -  - ETA: 15s - loss: 7.2967e-05 - accuracy: 1.0000 - au - ETA: - ETA: 6s - loss: 9.3939e-05 - \n",
      "Epoch 144/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.0439e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3847 - val_accuracy: 0.4004 - val_auc: 0.6331TA: 30s - loss: 4.4656e-05 - accuracy: 1.0000 - auc: 1. - ETA: 30s - loss: 3.0504e-05 - accuracy:   - ETA: 25s - loss: 2.2920e-04 - accuracy: 1.0000 - ETA: - ETA: 20s - loss: 4.5446e-04 - accuracy: 0.9998  - ETA: 19s - loss: 4.2145e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 19s - loss: 4.1921e-04 - accuracy: 0.99 - ETA: 18s - loss: 3.9375e-04 - accuracy - ETA: 17s - loss: 3.5866e-04 - accuracy: 0.9999 - - ETA: 16s - loss: 3.4094e-04 - accuracy: 0.9999 - auc: 1. - ETA: 16s - loss: 3.3539e-04 -  - ETA: 14s - loss: 3.0448e-04 - accuracy: 0.9999 - auc: 1 - ETA: 14s - loss: 2.9906e-04 - accuracy: 0.9999 - auc: 1. - ETA: 14s - loss: 2.9701e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 14s - loss: 2.9597e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 14s - loss: 2.9493e-04 - accuracy: 0.9999 - auc - ETA: 13s - loss: 2.8966e-04 - accuracy: 0.9999 - auc: - ETA: 13s - loss: 2.8311e-04 - accuracy: 0 - ETA: 12s - loss: 2.6876e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 11s - loss: 2.6628e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 11s - loss: 2.6556e- - ETA: 7s - los - ETA: 4s - loss: 2.0078e-04 - accuracy: 0.9999 - a\n",
      "Epoch 145/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 1.9847e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4619 - val_accuracy: 0.4084 - val_auc: 0.636430s - loss: 1.0845e-04 - accuracy: 1.0000 - au - ET - ETA: 25s - loss: 6.6991e-04 - a - ETA: 23s - loss: 5.0369e-04 - accuracy: 0.9997 - auc: 1.000 - E - ETA: 19s - loss: 3.5746e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 19s - loss: 3 - ETA: 16s - loss: 3.2226e-04 - accuracy: 0.9999 - auc: 1. - ETA: 16s - loss: 3.1801e-04 - accuracy: 0. - ETA: 15s - loss: 2.9755e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 15s - loss: 2.9642e-04 - accuracy: 0.9999 - - ETA: 14s - loss: 2.8480e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 14s - loss: 2.8377e-04 - accuracy: 0.9999 - auc:  - ETA: 14s - loss: 2.8698e-04 - accuracy: 0.9999 - auc:  - ETA: 13s - ETA: 8s - loss: 2.5306e-04 - accuracy: 0. - ETA: 7s - loss: 2.4693e-04 - accuracy: 0.9999 - auc: 1. - ETA: 7s - loss: 2.4\n",
      "Epoch 146/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.7536e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7466 - val_accuracy: 0.4115 - val_auc: 0.6306TA: 28s - loss: 1.1597e-04 - accuracy: 1.0000  - ETA: 28s - loss: 9.9713e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 28s - loss: 9.7641e-05 - accuracy: 1.00 - ETA: 27s - loss: 8.0558e-05 - accuracy: 1. - ETA: 26s - loss: 6.7209e-05 - accuracy: 1.0 - ETA: 25s - loss: 6.0534e-05 - accuracy: 1.0000 - auc: - ETA: 24s - loss: 6.1611e-05 - accuracy: - ETA: 23s - loss: 5.5031e-05 - accuracy: 1.0000 - auc: - ETA: 22s - loss: 5.2642e-05 - accuracy: 1.0000 - auc: 1 - ETA: 22s - loss: 5.1841e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 22s - loss: 5.1371e-05 - accuracy: 1.0000 - a - ETA: 21s - loss: 4.8444e-05 - accuracy: 1.0000 - a - ETA: 21s - loss: 4.7 - ETA: 18s - loss: 4.2536e-05 - accuracy: 1.0000 - auc:  - ETA: 18s - loss: 4.1382e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 4.1020e-05 - accuracy: 1.0 - ETA: 17s - loss: 3.8834e-05 - accuracy: 1.0000  - ETA: 16s - loss: 3.8904e-05 - accu - ETA: 14s - loss:  - ETA: 12s - loss: 3.6573e-05 - accuracy: 1.0000 - ETA: 11s - loss: 3 - ETA: 9s - loss: 3.3997e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 9s - loss: 3.4046e-05 - accura - ETA: 8s - loss: 3.3469e-05  - ETA: 7s - loss: 3.4446e-05 - accura - ETA: 6s - loss: 3.3708e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 3.3641e-05 - accuracy: 1.0000 - - ETA: 6s - loss: - ETA: 5s - loss: 3.3736e - ETA: 0s - loss: 3.7560e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 147/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.2491e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4816 - val_accuracy: 0.4126 - val_auc: 0.63662912e - ETA: 24s - loss: 1.6107e-04 - accuracy: 1.0000 -  - ETA: 23s - loss: 1.4 - ETA: 21s - loss: 1.2061e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 21s - loss: 1.1856e-04 - accura - ETA: 15s - loss: 1.7457e-04 - ac - ETA: 13s - loss: 1.6317e-04 - accuracy: 1.0000 - auc - ETA: 13s - loss: 1.5908e-04 - accu - ETA: 11s - loss: 1.7781e-04 - accuracy: 1.0000 - auc: 1 - ETA: 11s - loss: 1.7530e-04 - accuracy: 1.0000 - auc - ETA: 10s - loss: 1.73 - ETA: 7s - loss: 1.5552e-04 - accuracy: 1.0000 - - E - ETA: 2s - loss: 1.3573e-04 - \n",
      "Epoch 148/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.7340e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4360 - val_accuracy: 0.4084 - val_auc: 0.6349- loss: 4.2512e-05 - accuracy: 1.0000 - auc: 1 - ETA: 27s - loss: 9.2392e-05 - accuracy: 1.0000 - auc: 1. - ETA: 27s - l - ETA: 24s - loss: 6.3227e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 24s - loss: 6.4424e-05 - accuracy: 1.0000 - auc: 1 - ETA: 23s - loss: 6.2400e-05 - accuracy: 1.0000 - auc: 1 - ETA: 23s - loss: 6.3850e-05 - accuracy: 1.0000 - ETA: 22s - loss: 5.7784e-05 - accura - ETA: 21s - loss: 5.989 - ETA: 18s - los - ETA: 15s - loss: 6.7 - ETA: 13s - loss: 6.0764e-05  - ETA: 8s - loss: 5.5779e-05 - accuracy:  - ETA: 7s - loss: 5.4487e-05 - accura - ETA: 7s - loss: 5.3149e-05 - accuracy - ETA: 6s - loss: 5.1968e-05 - accuracy: 1.0000 - - ETA: 6s - loss: 5.1314e-05 - ac - ETA: 5s - loss: 5.8176e-05 - accuracy: 1.0000 - auc - ETA: 5s - loss: 5.7736e-05 - accuracy: 1.0000 - auc: 1. - ETA: 4s - loss: 5.7479e-05 - accuracy: 1.0000 - auc:  - ETA:  - ETA: 3s - loss: 5 - ETA: 1s\n",
      "Epoch 149/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.0246e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4172 - val_accuracy: 0.4103 - val_auc: 0.6354.0000 - auc: 1.00 - ETA: 27s - lo - ETA: 25s - loss: 5.2757e-05 - accuracy: 1.0000 - auc: 1 - ETA: 24s - ETA: 21s - loss: 8.1456e-05 - accuracy: 1.0000 - auc: - ETA: 21s - loss: 7.8235e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - loss: 7.7369e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - loss: 7.6487e-05 - accuracy - ETA: 19s - loss: 7.0750e-05 - accuracy - ETA: 18s - loss: 6.7948e-05 - accu - ETA: 16s - loss: 6.2094e-05 - accuracy: 1.00 - ETA: 15s - loss: 5.8480e-05 - accuracy: 1.0000 - auc: 1 - ETA: 15s - loss: 5.827 - ETA: 12s - loss: 5.9856e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 12s - loss: 5.9348e-05 - accurac - ETA: 10s - loss: 6.3590e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 7.7105e-05 - accuracy: 1 - ETA: 9s - loss: 7.4409e-05 - accuracy: 1.0000 - a - ETA: 9s - loss: 1.2823e-04 - accuracy: 1. - ETA: 8s - loss: 1.2525e-04 - accuracy: 1.0000 - a - ETA: 8s - loss: 1.2369e-04 - accuracy: 1.0000 - - ETA: 8s - loss: 1.2158e-04 - accuracy: 1.00 - ETA: 7s - loss: 1.1886e-04 - accuracy - ETA: 6s - loss: 1.1 - ETA: 5s - loss: 1.1340e-04 - accuracy: 1.0000 - ETA: 5s - loss: 1.1182e-04 -  -\n",
      "Epoch 150/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.4343e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3860 - val_accuracy: 0.4092 - val_auc: 0.6373ss: 1.4211e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 20s - loss: 1.3961e-04 - accura - ETA: 19s - loss: 1.2172e-0 - ETA: 17s - loss: 1.0828e-0 - ETA: 15s - loss: 9.5270e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 15s - loss: 9.4562e-05 - accuracy: 1.0000 - auc: 1. - ETA: 10s - loss: 1.8416e-04 - accuracy: 0.9999 - auc - ETA: 10s - loss: 1.8086e-04 - acc - ETA: 9s - loss: 1.7390e-0 - ETA: 8s - loss: 1.8320e-04 - accuracy - ETA: 7s - loss: 1.7830e-04 - accuracy:  - ETA: 6s - loss: 1.7342e-04 - accuracy:  - ETA: 6s - loss: 1.6993e-04 - accuracy:  - ETA: 5s - loss: 1.6600e-04 - accuracy: 0.9999 - auc - ETA: 5s - loss: 1.6466e-04 - accuracy - ETA: 4s - loss: 1.6046e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 4s - loss: 1.6011e-0 - ETA: 3s - loss: 1.5516e-04 - accuracy: 0.99 - ETA: 2s - loss: 1.5278e-04 - accuracy: 0.9999 - ETA: 2s - loss: 1.5073e-04 - accuracy - ETA: 1s - loss: 1.4694e-04 - accura - ETA: 0s - loss: 1.4707e-04 - accuracy: 0.9999 - ETA: 0s - loss: 1.4515e-04 - accuracy: 0.9999\n",
      "Epoch 151/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.0519e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4097 - val_accuracy: 0.4092 - val_auc: 0.6349oss: 1.0502e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 29s - loss: 9.8608e-06 - accuracy: 1.0000 -  - ETA: 28s - loss: 5.7392e-05 - accuracy: 1.0000 - - ETA: 28s - loss: 4.511 - ETA: 21s - loss: 3.2410e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 21s - loss: 3.2026e-05 - accur - ETA: 19s - loss: 3.1632e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 3.1488e-05 - accuracy: 1.0000 - - ETA: 19s - loss: 4.7034e-05 - accuracy: 1.0000 - auc: - ETA: 18s - loss: 4.6208e-05 - accuracy: 1.0000 - auc: 1 - ETA: 18s - loss: 4.5333e-05 - accuracy: - ETA: 17s - loss: 4.2381e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 4.2094e-05 - accuracy: 1.0000 - - ETA: 16s - loss: 4.0914e-05 - accuracy: 1.0000 - auc: 1. - ETA: 15s - loss: 4.0589e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: - ETA: 12s - loss: 7.7436e-05 -  - ETA: 10s - loss: 7.2979e-05 - accuracy: 1.0000 - - E - ETA: 7s - loss: 7.0812e-05 - accuracy: 1.0000 - - ETA - ETA: 5s - loss: 6.6118e-05 - accuracy: 1.00 - ETA: 5s - loss: 6.4965e-05 - accuracy: 1.0000 - auc - ETA: 4s - los - ETA: 3s - loss: 6.2298e-05 - accuracy: 1.0000 - - ETA: 3s - loss: 6.1606e-05 - accuracy: 1.0000 - - ETA: 2s - loss: 6.1436e - ETA: 1s - loss: 6.2187e-05 - accuracy: 1.0000 - a - ETA: 1s - loss: 6.2334e-05 - ac - ETA: 0s - loss: 6.1230e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 6.1117e-05 - accuracy: 1.0000 -\n",
      "Epoch 152/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 1.1000e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4851 - val_accuracy: 0.4061 - val_auc: 0.6305A: 30s - loss: 4.2772e-05 - accuracy: 1.0000 - auc:  - ETA: 25s - loss: 2.6280e-05 - accuracy: 1. - ETA: 24s - loss: 2.3195e-05 - accuracy: 1.0000 - auc: 1. - ETA: 24s - loss: 2.2466e-05 - acc - ETA: 22s - loss: 1.75 - ETA: 19s - loss: 1.4347e-04 - accuracy: 1.0000 - a - ETA: 19s - loss: 2.3524e-04 - accuracy: 1.0000  - ETA: 18s - loss: 2.2130e-04 - accuracy: 1.000 - ETA: 17s - loss: 2.0770e-04 - accuracy: 1.0000 - auc:  - ETA: 17s - loss: 2.0259e-04 - accuracy: 1.0000 - auc: 1 - ETA: 16s - loss: 1.9786e-04 - accuracy: 1.0000 -  - ETA: 15s - loss: 1.888 - ETA: 13s - loss: 1.6566e-04 - accuracy: 1.000 - ETA - ETA: 7s - loss: 1.3149e-04 - accu - ETA: 6s - loss: 1.2890e-04 - accu - ETA: 5s - loss: 1.2711e-04  - ETA: 4s - loss: 1.2291e-04 -  - ETA: 3s - loss: 1.2236e-04 - accu - ETA: 2s - loss: 1.1942e-04 - accuracy: 1.0000 - ETA: 2s - loss: 1.1 - ETA: 1s - loss: 1.1352e-04 - accuracy: 1.0000 - - ETA: 0s - loss: 1.1225e-04 - \n",
      "Epoch 153/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.0135e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5118 - val_accuracy: 0.4073 - val_auc: 0.631429s - loss: 2.2668e-05 - accurac - ETA: 28s - loss: 2.6991e-05 - accuracy: 1.0000 - auc:  - ETA: 27s - loss: 2.5296e-05 - accuracy: 1.0000 - ETA: 27s - loss: 2. - ETA: 24s - loss: 2.1063e-05 - accuracy: 1.0000  - ETA: 23s - loss: 3.4279e-05 - accuracy: - ETA: 22s - loss: 3.2756e-05 - accuracy: 1.0000 - auc: 1 - ETA: 21s - loss: 3.2132e-05 - accuracy: 1.0000 -  - ETA: 21s - loss: 3.3 - ETA: 18s - loss: 2.9749e-05 - accuracy: 1.0000 - auc: 1.00 - ETA:  - ETA: 14s - loss: 2.8338e-05 - accuracy: 1.0000 -  - ETA: 14s - loss: 2.7604e-05 - acc - ETA: 12s - loss: 3.892 - ETA: 3s - l - ETA: 2s - loss: 3.8614e-05 - accuracy: 1.0000 - - ETA: 1s - loss: 3.8524e-05 - accuracy: 1.0000 - a - ETA: 1s - loss: 4.0552e-05 - accuracy - ETA: 0s - loss: 4.0754e-05 - accura\n",
      "Epoch 154/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.4592e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5570 - val_accuracy: 0.4126 - val_auc: 0.6326s: 6.2389e-06 - accuracy:  - ETA: 28s - loss: 7.6105e-06 - accuracy: 1.0000 - auc:  - ETA: 27s - loss: 1.2909e - ETA: 25s - loss: 1.4819e-05 - accurac - ETA: 23s - loss: 1.4581e-05 - accuracy: 1 - ETA: 22s - loss: 1.6896e-05 - accuracy: 1.0000 - auc: 1 - ETA: 22s - loss: 1.6384e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 1.6288e-05 - accuracy: 1. - ETA: 21s - loss: 2.2770e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - loss: 2.2766e-05 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 2.2601e-05 - accuracy: 1.000 - ETA: 19s - loss: 2.1304e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 2.1192e-05 - accuracy: 1.0000 - auc: 1. - ETA: 19s - loss: 2.1566e-05 - accuracy: 1.0000 - auc: 1 - ETA: 19s - loss: 2.1059e-05 - accuracy: 1.0 - ETA: 18s - loss: 2.7044e-05 - accuracy: - ETA: 16s - loss: 2.6338e-05 - accuracy: 1.00 - ETA: 15s - loss: 2.5665e-05 - accuracy: 1.0 - ETA: 14s - loss: 2.5630e-05 - a - ETA: 12s - loss: 2.3988e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 12s - loss: 4.5908e-05 - accuracy - ETA: 11s - loss: 4.3814e-05 - accuracy: 1.0000 - auc:  - ETA: 10s - l - ETA: 8s - loss: 6.1706e-05 - accuracy: 1.0000 - a - ETA: 8s - loss: 6.1135e-05 - accuracy: 1.0000 - - ETA: 8s - loss: 6.063 - ETA: 6s - loss: 5.9756e-05 -  - ETA: 5s - loss: 6.0876e-05 - accuracy: 1.0000 - a - ETA: 5s - loss: 6.0220e-05 - accuracy: 1.0000 - auc - ETA: 5s - loss: 5.9748e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 5.8039e-05 -  - ETA: 1s - loss: 5.8209e-05  - ETA: 0s - loss: 5.7040e-05 \n",
      "Epoch 155/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.0171e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4555 - val_accuracy: 0.4057 - val_auc: 0.6327ss: 2.8772e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 29s - loss: 2.7892e-05 - accuracy: 1.0000 - a - ETA: 29s - loss: 3.6428e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 28s - loss: 3.5428e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 4.9982e-05 - accuracy: 1.0000 - - ETA: 27s - loss: 3.8850e-05 - accuracy: 1.0000 -  - ETA: 27s - loss: 4.6291e-05 - accuracy: 1 - ETA: 26s - loss: 3.7590e-05 - accuracy: 1.0000 - - ETA: 25s - loss: 3.4826e-05 - accuracy: 1.000 - ETA: 24s - loss: 3.2199e-05 - accuracy: 1.0000 - - ETA: 23s - - ETA: 20s - loss: 5.5417e-05 - accuracy: 1.0000 - ETA: 19s - loss: 5.6416e-05 - accuracy: 1.0000 - auc: 1. - ETA: 19s - loss: 5.5034e-05 - accuracy: 1.0000 - auc - ETA: 18s - loss: 5.5614e-05 - accuracy: 1.0000 - auc: 1 - ETA: 18s - - ETA: 15s - loss: 8.7875e-05 - accuracy: 1.0 - - ETA: 7s - l - ETA: 6s - loss: 6.4639e-05 - accuracy: 1.0000 - auc: 1. - ETA: 6s - loss: 6.4354e-0 - ETA - ETA: 1s - loss: 5.7636e-05 - accu - ETA: 0s - loss: 6.1528e-05 - accuracy: 1.0000 - a - ETA: 0s - loss: 6.0968e-05 - accuracy: 1.00\n",
      "Epoch 156/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.8330e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.2376 - val_accuracy: 0.4103 - val_auc: 0.6371: 30s - loss: 1.4797e-05 - a - ETA: 28s - loss: 1.2141e-05 - accuracy: 1.0000 - auc:  - ETA: 28s - loss: 1.7700e-05 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 2.8463e-05 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 3.2682e - ETA: 24s - loss: 2.5868e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 2.5635e-05 - accuracy: 1.0000 - ETA: 23s - loss: 2.3624e-05 - accuracy: 1.0000 - auc: - ETA: 23s - loss: 2.5723e-05 - accuracy: 1.0000  - ETA: 22s - loss: 2.5530e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 2.5506e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 2.5195e-05 - accuracy: 1.0000 - ETA: 21s - loss: 2.3384e-05 - accuracy: 1.0000 - auc:  - ETA: 21s - loss: 2.2631e-05 - accuracy: 1.0000 - au - ETA: 20s - loss: 2.5310e-05 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 2.4920e-05 - accuracy: 1.00 - ETA: 19s - loss: 2.3220e-05 - accuracy: 1.00 - ETA: 18s - loss: 2.3907e-05 - accuracy: 1.0000 -  - ETA: 17s - loss: 2.3330e-05 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 2.2987e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 17s - loss: 2.2941e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 17s - los - ETA: 14s - loss: 2.3418e-05 - accuracy: 1.0000 - auc - ETA: 9s - loss: 3.0479e-04 - ac - ETA: 8s - loss: 2.9255e-04 - accuracy: 0.9998 - auc:  - ETA: 8s - loss: 2.9028e-04 - accuracy: 0.9998 - ETA: 8s - loss: 2.8463e-04 - accuracy: 0.9998 - auc - ETA: 7s - loss: 2.8187e-04 - accuracy: 0.99 - ETA:  - ETA:  - ETA: 3s - loss: 3.6334e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 3s - loss: 3.6255e-04 - accuracy: 0.99 - ETA: 3s - loss: 4.1715e-04 - accuracy: 0.9997 - auc: 1.00 - ETA: 3s - loss: 4.1630e-04 - accuracy: 0.99 - ETA: 2s - loss: 4.1122e-04 - ac - ETA: 1s\n",
      "Epoch 157/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.4023e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.2570 - val_accuracy: 0.4146 - val_auc: 0.6390 - loss: 1.6081e-04 - accuracy: 1.0000 - auc: 1. - ETA: 28s - loss: 1.4816e-04 - accuracy: 1.0000 - auc: 1.0 - ETA:  - ETA: 24s - loss: 8.6819e-05 - accuracy: - ETA: 23s - loss: 1 - ETA: 20s - loss: 1.1627e-04 - accuracy: 1.0000 - auc: 1 - ETA: 19s - loss: 1.1342e-04 - - ETA: 18s - loss: 1.0008e-04 - accura - ETA: 16s - loss: 9.1232e-05 - accuracy: 1.0000 - auc - ETA: 15s - loss - ETA: 13s - loss: 8.6080e-05 - a - ETA: 11s - loss: 8.2790e-05 - accuracy: 1.0000 -  - ETA: 10s - loss: 8.0595e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 10s - loss: 8.0140e-05 - accuracy: 1.0000 - a - ETA: 9s - loss: 7.8597e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 9s - loss: 7.8376e-05 - accuracy: 1.00 - ETA: 9s - loss: 7.6750e-05 - accura - ETA: 8s - loss: 7.4831e-05 - accuracy: 1.0000 - a - ETA: 8s - loss: 7.4002e-05 - accuracy: 1. - ETA: 7s - loss: 7.2441e-05 - accuracy:  - ETA: 7s - loss: 7.1009e - ETA: 5s - loss: 6.8464e-05 - accu - ETA: 4s - loss: 6.6890e-05 - accuracy: 1.0000 - auc: 1. - ETA: 4s - loss: 6.6701e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 4s - loss: 6.6571e-05 - accuracy:  - ETA: 4s - loss: 6.8300e-05 - accuracy: 1.0000 - - ETA: 3s - ETA: 1s - loss: 6.4489e-05 - accuracy: 1.0000 - auc: 1. - ETA: 1s - loss: 6.4241e - ETA: 0s - loss: 6.4790e-05 - accuracy: 1.00\n",
      "Epoch 158/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 9.6525e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5328 - val_accuracy: 0.4188 - val_auc: 0.63177340e-05 - accurac - ETA: 11s - loss: 4.7461e-05 - accuracy: 1.0000 - auc: 1. - ETA: 10s - loss: 4.6972e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 8s - loss: 4.4800e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 8s - loss: 4.4758e-05 - accura - ETA: 7s - loss: 4 - ETA: 6s - loss: 4.3384e-05  - ETA: 5s - loss: 7.0334e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 5s - loss: 7.0079e-05 - accuracy: 1.0000 - - ETA: 4s - loss: - ETA: \n",
      "Epoch 159/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.1964e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5737 - val_accuracy: 0.4207 - val_auc: 0.6369- accuracy: 1.0000 - auc:  - ETA: 27s - loss: 1.6776e-05 - accuracy: 1.00 - ETA: 27s - loss: 1.7 - ETA: 24s - loss: 1.745 - ETA: 22s - loss: 2.5718e-05 - accuracy: 1. - ETA: 20s - loss: 2.9980e-05 - accuracy: 1.0000 - au - ETA: 20s - loss: 2.8787e-05 - accur - ETA: 18s - loss: 2.7744e-05 - accuracy: 1.0000 - auc: 1. - ETA: 18s - loss: 2.8192e-05 - accuracy: 1.0000 - auc: - ETA: 18s - loss: 2.7398e-05 - accuracy - ETA: 16s - loss: 2.7801e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 2.7643e-05 - accuracy: 1.0000 - auc:  - ETA: 16s - loss: 2.9365e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 2.9978e-05 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 2.9567e-05 - accuracy: 1.0000 - auc: 1 - ETA: 15s - loss: 2.9276 - ETA: 13s - loss: 2.6943e-05 - accuracy:  - ETA: 11s - loss: 2.9163e-05 - accurac - ETA: 10s - loss: 3.1151e-0 - ETA: 9s - loss: 2.9911e-04 - accuracy: 0.9998 - a - ETA: 4s - loss: 2.5305e-04 - ac - ETA: 1s - loss: 2.3096e-04 - accuracy: 0.99 - ETA: 1s - loss: 2.2714e-04 - accuracy: 0.9999 - ETA: 0s - loss: 2.2429e-04 - accura\n",
      "Epoch 160/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 7.6349e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6139 - val_accuracy: 0.4199 - val_auc: 0.6346loss: 2.0373e-04 - accuracy: 1.0000 - auc: 1. - ETA: 29s - loss: 2.0089e-04 - accuracy: 1. - ETA: 28s - loss: 1.6799e-04 - ac - ETA: 26s - loss: 1.1487e-04 - accuracy: 1.0000 - auc: - ETA: 26s - lo - ETA: 23s - loss: 7.8875e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 7.8326e-05 - accuracy: 1.0000 - au - ETA: 22s - loss: 7.3386e-05 - accuracy: 1.0000 - ETA: 21s - loss: 6.8835e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 21s - loss: 6.8768e-05 - accuracy: 1.0000 - ETA: 20s - loss: 6.4955e-05 - accuracy: 1.0000  - ETA: 19s - loss: 7.0661e-05 - accuracy: 1.0000 - ETA: 19s - loss: 6.6839e-05 - accuracy: 1.0000 - auc: - ETA: 18s - loss: 6.4641e-05 - accuracy: 1.0000 - auc: 1. - ETA: 18s - loss: 6.3553e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 6.6243e-05 - accuracy: 1.0 - ETA: 16s - loss: 6.8845e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 16s - loss: 6.8665e-05 - accuracy: 1.0000 - auc: - ETA: 16s - loss: 6.7338e-05 - accuracy: 1.0000 - auc: - ETA: 16s - loss: 6.6388e- - ETA: 13s - loss: 6.3453e-05 - accuracy: 1.0000 - a - ETA: 13s - loss: 6.7061e-05 - accurac - ETA: 11s - loss: 6.4486e-05 - accuracy: 1.0 - ETA: 10s - loss: 8.5344e-05 - accuracy: 1.0000 - auc: 1. - ETA: 10s - loss: 8.4410e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 10s - loss: 8.4184e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 8.3538e-05 - accuracy: 1 - ETA: 9s - loss: 8.1104e-05 -  - ETA: 8s - loss: 8.1529e-05 - accuracy: 1.0000 - a - ETA: 8s - loss: 8.1031e-05 - accuracy: 1.00 - ETA: 7s - loss: 8.0643e-05 - accura - ETA: 6s - loss: 8.1145e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 8.0973e-05 - accuracy: 1.00 - ETA: 6s - loss: 7.9 - ETA: 4s - loss: 7.9 - ETA: 3s - loss: 8.1019e-05 - accuracy: 1.00 - ETA: 3s - loss: 8.1354e-05 - ac - ETA: 2s - loss: 7.9688e-05 - accuracy: 1.0000 - a - ETA: 2s - loss: 7.8901e-05 - accuracy: 1.0000 - - ETA: 1s - loss: 7.9504e-05 - accuracy: 1.0000 - auc - ETA: 1s - loss: 7.8994e-05 - accuracy: 1.0000 - auc:  - ETA: 1s - loss: 7.8670e-05 - accuracy: 1.0000 - auc: 1. - ETA: 1s - loss: 7.8371e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 7.8246e-05 - accuracy:  - ETA: 0s - loss: 7.7183e-05 - accuracy: 1.0000 -\n",
      "Epoch 161/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 7.4755e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5432 - val_accuracy: 0.4165 - val_auc: 0.6358: 28s - loss: 3.5316e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 5.6100e-05 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 5.3870e-05 - accuracy: 1. - ETA: 26s - loss: 4.3284e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 26s - loss: 4.2346e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 26s - loss: 4.1426e-05 - accuracy: 1.0000 - au - ETA: 25s - loss: 6.2594e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 25s - loss: 6.1984e-05 - accu - ETA: 24s - loss: 5.2136e-05 - accuracy: 1.0000 - auc: 1 - ETA: 23s - loss: 5.0775e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 23s - loss: 4.9893e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 23s - loss: 4.9283e-05 - accuracy: 1.0000 - auc: 1 - ETA: 23s - loss: 4.7735e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 23s - loss: 4.7246e-05 - accuracy: 1.0000 - - ETA: 22s - loss: 4.5975e-05 - accuracy: 1.0000 -  - ETA: 21s - loss: 4.3393e-05 - accuracy: 1.0000  - ETA: 20s - loss: 4.0938e-05 - accuracy - ETA: 19s - loss: 3.8774e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 19s - loss: 8.5094e-05 - accuracy: 1.0000 - auc: 1 - ETA: 18s - loss: 8.3360e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 18s - loss: 8.3033e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 18s - loss: 8.6233e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 18s - loss: 8.5804e-05 - accura - ETA: 16s - loss: 8.2612e-05 - accuracy: 1. - ETA: 15 - ETA: 11s - loss: 8.4246e-05 - accuracy: 1.0000 - auc: 1. - ETA: 11s - loss: 8.3496e-05 - accuracy: - ETA: 8s - loss: 8.5782e-05 - accuracy: 1.0000 - a - ETA: 7s - loss: 8.4987e-05 - accuracy: 1.0000 - - ETA: 7s - loss: 8.4 - ETA: 6s - loss: 8.1271e-05 - accuracy: 1.0000 - auc - ETA: 6s - loss: 8.0506e-05 - accuracy: 1.0000 - auc - ETA: 5s - loss: 7.9873e-05 - accura - E - ETA: 3s - loss: 7.5377e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 7.5219e-05 - accuracy: 1.00 - ETA: 2s - loss: 7.5677e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 7.5247e - ETA: 1s - loss: 7.2562e-05 - accuracy: 1.0000 - auc - ETA: 0s - loss: 7.2049e-05 - accu\n",
      "Epoch 162/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 2.5454e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.3857 - val_accuracy: 0.4077 - val_auc: 0.6380 loss: 1.8779e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 29s - loss: 6.8911e-04 - accura - ETA: 24s - loss: 7.0694e-04 - accuracy: 0 - ETA: 23s - loss: 6.0631e-04 - accuracy: 0.9998 - auc: -  - ETA: 19s - loss: 4.1353e-04 - accuracy: 0.9998 - ETA: 18s - loss: 3.8709e-04 - accuracy: - ETA: 16s - loss: 3.5737e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 16s - loss: 3.5309e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 16s - loss: 3.4902e-04 - accuracy:  - ETA: 15s - loss: 3.2822e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 15s - loss: 3.2728e-04 - a - ETA: 13s - loss: 3.8015e-04 - accuracy: 0.9998 - auc - ETA: 12s - loss: 3.6957e-0 - ETA: 8s - loss: 3.0857e-04  - ETA: 7s - loss: 2.9650e-04 - accuracy: 0.9998 - auc: 1. - ETA: 5s - ETA: 3s - loss: 2\n",
      "Epoch 163/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 9.7639e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.4746 - val_accuracy: 0.4119 - val_auc: 0.6338 25s - loss: 3.7075e-05 - accuracy: 1.0000 - ETA: 25s - l - ETA: 21s - loss: 3.0800e-05 - accuracy: 1.0000  - ETA: 21s - loss: 3.0822e-05 - accuracy: 1.0000 - ETA: 20s - loss: 3.1627e-05 - accuracy: 1.000 - ETA: 19s - loss: 3.5303e-05 - accuracy: 1 - ETA: 18s - loss: 3.8348e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 17s - loss: 3.8228e-05 - accuracy: 1. - ETA: 16s - loss: 4.6674e-05 - accuracy: 1.0000 - auc:  - ETA: 16s - loss: 5.0614e-05 - accuracy: 1.0000 - auc - ETA: 15s - loss: 4.9249e-05 - accuracy: 1.00 - ETA: 14s - loss: 4.6991e-0 - ETA: 12s - loss: 4.4410e-05 - ac - ETA: 10s - loss: 4.8390e-05 - accuracy: 1.0000 - auc:  - ETA: 10s - loss: 4.7702e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 4.7320e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 10s - ETA: 6s - loss: 7.8384e-05 - accuracy: 1.0000 - - ETA: 6s - loss: 7.7470e-05 - accu - ETA: 5s - loss: 7.5 - ETA: 4s - loss: 7.3119e-05 - accuracy: 1.0000 - auc - ETA: 3s - loss: 7.2672e-05 - accura - ETA: 3s - loss: 1.0579e-04 - accuracy: 1. - ETA: 2s - loss: 1.042 - ETA: 1s - loss: 1.0\n",
      "Epoch 164/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.7257e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5211 - val_accuracy: 0.4138 - val_auc: 0.6394s - loss: 2.1823e-04 - accuracy: 1.0000 - - ETA: 30s - loss: 1.1704e-04 -  - ETA: 27s - loss: 5.8789e-05 - accuracy: 1.0000 - auc:  - ETA: 27s - loss: 5.4225e-05 - accuracy: 1.0000 -  - ETA: 26s - loss: 4.8711e-05 - accuracy: 1. - ETA: 25s - loss: 4.1753e-05 - accuracy: 1.0000 -  - ETA: 24s - loss: 3.8195e-05 - a - ETA: 23s - loss: 3.4844e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 3.7251e-05 - accuracy: 1.0000 - auc: 1. - ETA: 22s - loss: 3.6307e-05 - accuracy: 1.0000 - auc:  - ETA: 22 - ETA: 19s - loss: 3.0473e-05 - accuracy: 1.0000 - - ETA: 18s - loss: 2.9380e-05 - accuracy: 1.0000 - auc: 1. - ETA: 18s - loss: 2.8912e-05 - accuracy: 1.0000 - auc: 1. - ETA: 17s - loss: 2.8484e-05 - accuracy: 1.0000 - auc - ETA: 17s - loss: 2.9263e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 17s - loss: 2.9219e-05 - acc - ETA: 15s - loss: 2.6998e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 15s - loss: 2.6839e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 15s - loss: 2.6562 - ETA: 12s - lo - ETA: 9s - loss: 3.8853e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 9s - loss: 3.8635e-04 - accura - ETA: 9s - - ETA: 5s - loss: 3.2379e-04 - accura - ETA: 4s - loss: 3.1438e-04 - accura - ETA: 3s - loss: 3.0671e-04 - accuracy: 0.9999 - auc:  - ETA:  - ETA: 2s - loss: 2.8832e-04 - accuracy: 0.9999 - auc: 1. - ETA: 1s - loss: 2.8724e-04 - accuracy: 0. - ETA: 1s - loss: 2.8426e-04 - accuracy: 0.9999 - auc: 1. - ETA: 1s - loss: 2.8315e-04 - accuracy:  - ETA: 0s - loss: 2.7784e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 2.7729e-04 - accuracy: \n",
      "Epoch 165/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.5376e-04 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 5.4668 - val_accuracy: 0.4046 - val_auc: 0.62694 - auc: 1.000 - ETA: 24s - loss: 0.0011 - accuracy: 0.999 - ETA: 23s - loss: 9.7860e-04 - accuracy: 0.9995 - auc: 1.00 - ETA: 23s - loss: 9.6350e-04 - accuracy: 0.9995  - ETA: 22s - loss: 8.9519e-04 - accuracy: 0.9996 - auc: 1. - ETA: 22s - loss: 8.7131e-04 - accuracy: 0.9996 - auc: 1.000 - ETA: 22s - loss: 8.6566e-04 - accuracy: 0.9996 - auc: 1.00 - ETA: 22s - loss: 8.5424e-04 - accuracy: 0.9996 - auc:  - ETA: 21s - loss: 8.2226e-04 - accuracy:  - ETA: 20s - loss: 7.3003e-04 - accuracy: 0.9997 - - ETA: 19s - loss: 6.8553e-04 - accuracy: 0.9997 - au - ETA: 19s - loss: 6.6700e-04 -  - ETA: 17s - loss: 5.8072e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 17s - loss: 5.7826e-04 - accuracy: 0.9997 - ETA: 16s - loss: 5.5309e-04 - accuracy: 0.9997 - auc: - ETA: 15s  - ETA: 12s - loss: 4.5327e-04 - accuracy: 0.9998 - au - ETA: 12s - loss: 4.3980e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 11s - loss: 4.3711e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 11s - loss: 4.3327e-04 - accuracy: 0.9998 - auc: 1 - ETA: 11s - ETA - ETA: 7s - los - ETA: 3s - loss: 3.920 - ETA: 2s - loss: 3.781 - ETA: 1s - loss: 3.6444e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 1s - loss: 3.6370e-04 - accuracy: 0.9998 - - ETA: 1s - loss: 3.6520e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 1s - loss: 3.6448e-04 - accuracy: 0.9998 - ETA: 0s - loss: 3.5960e-04 - accuracy: 0.9998 - a - ETA: 0s - loss: 3.5730e-04 - accuracy: 0.9998 -\n",
      "Epoch 166/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9459e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7227 - val_accuracy: 0.4034 - val_auc: 0.6302TA: 30s - loss: 2.1399e-05 - accuracy: 1.0 - ETA: 29s - loss: 6.4 - ETA: 22s - loss: 5. - ETA: 20s - loss: 4.4575e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 19s - lo - ETA: - ETA: 13s - loss: 2.9814e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 13s - loss: 2.9628e-04 - accuracy: 0.9999 - auc: - ETA: 12s - loss: 2.8976e-04 - accuracy - ETA: 11s - loss: 2.7524e-04 - accuracy: 0.9999 - auc: - ETA: 11s - loss: 2.7073e-04 - accuracy: 0.9999 - auc: 1 - ETA: 10s - loss: 2.6668e-04 - accuracy: 0.9999 - auc: 1. - ETA: 10s - loss: 2.6392e-04 - accuracy: 0.9999 - a - ETA: 9s - l - ETA: 8s - loss: 2.4106e-04 - accuracy: 0.9999 - ETA: 8s - loss: 2.3682e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 7s - loss: 2.3621e-04 - accura - ETA: 7s - loss: 2.3018e-04 - accuracy: 0.9999 - - ETA: 6s - loss: 2.2958e-04 - accura - ETA: 6s - loss: 2.2369e-04 - accuracy: 0. - ETA: 5s - loss: 2.189 - ETA: 2s - loss: 1.9757e-04 - accuracy: 0.9999 - auc:  - ETA: 1s - loss: 1.9638e-04 - accuracy: 0.9999 - - ETA: 1s - loss: 1.9401e-04 - accu - ETA: 0s - loss: 1.9753e-04 - accuracy: 0.\n",
      "Epoch 167/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.5543e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7461 - val_accuracy: 0.4011 - val_auc: 0.6310loss: 3.5318e-05 - accuracy: 1.00 - ETA: 25s - loss: 3.7049e-05 - accuracy: 1 - ETA: 24s - loss: 3. - ETA: 21s - loss: 3.5210e-05 - accuracy: 1.0000 -  - ETA: 20s - loss: 1.5382e-04 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 1.5003e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 2 - ETA: 16s - loss: 1.20 - ETA: 14s - loss: 1.1081e-04 - accuracy: 1.0000 - auc: 1 - ETA: 13s - loss: 1.0936e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 13s - loss: 1.0895e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 13s - loss: 1.0826e-04 - accuracy: 1.0000 - auc:  - ETA: 13s - loss: 1.0646e-04 - accuracy: 1.0 - ETA: 12s - loss: 1.0098e-04 - accura - ETA: 8s - loss: 8.8706e-05 - accuracy:  - ETA: 7s - loss: 8.6864e-05 - accuracy: 1. - ETA: 5s - loss: 8.3393e-05 - accuracy: 1.0000 - ETA: 4s - loss: - ETA: 3s - loss: 8.0850e-05 - ac - ETA: 2s - loss: 7.8547e-05 - accuracy: 1.0000 - auc - ETA: 1s - loss: 7.7778e-05 - accura - ETA: 1s - loss: 7.5924e-05 - accuracy: 1.0000 - a - ETA: 0s - loss: 7.6679e-05 - accuracy: 1.0000 - - ETA: 0s - loss: 7.6067e-05 - accuracy: 1.0000 - a\n",
      "Epoch 168/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.7810e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8847 - val_accuracy: 0.4050 - val_auc: 0.6285ETA: 26s - loss: 2.8399e-05 - accuracy: 1. - ETA: 24s - loss: 2.8672e-05 - accuracy: 1 - ETA:  - ETA: 19s - loss: 2.7136e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: - ETA: 16s - loss: 3.4424e-05 - accuracy: 1.0000  - ETA: 16s - loss: 3.4500e-05 - accuracy: 1.00 - ETA: 15s - loss: 3.8600e-05 - accuracy: 1.0 - ETA: 14s - loss: 3.8697e-05 - accuracy: 1.0000 - auc - ETA: 13s - loss: 3.7966e-05 - accuracy: 1.0000 - auc:  - ETA: 13s - loss: 3.7271e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 13s - loss: 3.7148e-05 - accuracy: 1.0000 - auc - - ETA: 9s - - ETA: 7s - loss: 9.1397e-05 - accuracy: 1.0000 - auc: 1. - ETA: 7s - - ETA: 3s - loss: 8.3259e-05 - accuracy: 1.00 - ETA: 3s - loss: - ETA: 1s - loss: 8.1554e-05 - accuracy - ETA: 1s - loss: 8.0015e-05 - accuracy: 1.0000 - auc - ETA: 0s - loss: 7.9506e-05 - accuracy: 1.0000 - - ETA: 0s - loss: 7.8599e-05 - accuracy: 1.00\n",
      "Epoch 169/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.3731e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6676 - val_accuracy: 0.4061 - val_auc: 0.6332: 30s - loss: 4.8119e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 30s - loss: 4.5860e-05 - accuracy: 1.0000 - ETA: 29s - loss: 2.9070e-05 - accuracy: - ETA: 28s - loss: 2.5858e-05 - accuracy: 1.0000 - ETA: - ETA: 23s - loss: 3.6108e-05 - accuracy: 1.0000 -  - ETA: 23s - loss: 3.3706e - ETA: 20s - loss: 2.8051e-05 - ETA: 18s - loss: 2.6744e-05 - accur - ETA: 16s - loss: 2.6534e-05 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 2.6144e-05 - accuracy: 1.000 - ETA: 15s - loss: 4.1001e-05 - accur - ETA: 13s - loss: 3.8902e-05 - accuracy: 1.0000 - auc: 1. - ETA: 13s - loss: 3.8393e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 13s - loss: 3.9756e-05 - accuracy: 1.000 - ETA: 9s - loss: 1.0042e-04 -  - ETA: 8s - loss: 9.8445e-05 - accuracy:  - ETA: 7s - loss: 9.6352e-05 - accuracy: 1. - ETA: 6s - - ETA: 5s - loss: 9.1573e-05 - accuracy: 1.0000 - a - ETA: 5s - loss: 9.0707e-05  - ETA: 3s - loss: 9.4460e-05  - ETA: 2s - loss: 9.0992e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 9.0717e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 9.0161e-05 - accuracy: 1.0000 - auc - ETA: 2s - loss: 8.9484e-05 - accuracy: 1. - ETA: 1s - loss: 8.7852e-05 - ac - ETA: 0s - loss: 8.5289e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 8.5122e-05 - accuracy: \n",
      "Epoch 170/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 1.3669e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5763 - val_accuracy: 0.4042 - val_auc: 0.6327loss: 0.0015 - accuracy: 1.0000 - auc: 1 - ETA: 30s - loss: 0.0012 - accuracy: 1.0000 - a - ETA: 29s - loss: 7.4467e-04 - accuracy: 1.0000 - auc: 1 - ETA: 29s - loss: 7.0544e-04 - accuracy: 1.0000 - auc: 1. - ETA: 29s - loss: 6.2729e-04 - accuracy: 1.0000 -  - ETA: 28s - loss: 4.8682e-04 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 4.4121e-04 - accuracy: 1.0000 - au - ETA: 27s - loss: 3.7064e-04 - accuracy: 1 - ETA: 26s - loss: 2.9973e-04 - accuracy: 1.0000 - auc: - ETA: 26s - loss: 2.7873e-04 - accuracy: 1.0000 - auc:  - ETA: 25s - loss: 2.6211e-04 - accuracy: 1.0000 - auc: 1. - ETA: 25s - loss: 2.5166e-04 - accura - ETA: 24s - loss: 2.0421e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 23s - loss: 2.0069e-04 - accuracy: 1.0000 - a - ETA: 23s - loss: 1.8653e-04 - accuracy: 1.000 - ETA: 22s - loss: 1.7590e-04 - accuracy: 1.0000 - auc: 1. - ETA: 22s - loss: 1.7149e-04 - accuracy: 1.0000 - auc - ETA: 21s - loss: 1.6357e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 1.6068e-04 - accuracy: 1.0000 -  - ETA: 20s - loss: 1.5040e-04 - accuracy: 1.0000 - au - ETA: 20s - l - ETA: 17s - loss: 1.1550e-04 - accuracy: 1.0000 - auc: 1 - ETA: 16s - loss: 1.1308e-04 - accuracy: 1.0000 - a - ETA: 16s - loss: 1.0930e-04 - accuracy: 1.0000 - auc - ETA: 15s - loss: 1.0657e-04 - accuracy: 1.00 - ETA: 14s - loss: 1.0688e-04 - accuracy: 1.0000 - auc: 1 - ETA: 14s - loss: 1.0506e-04 - accuracy: 1.0 - ETA: 13s - loss: 1.4321e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 12s - loss: 1.4216e-04 - accuracy: 1.0000 - auc: 1 - ETA: 12s - loss: 1.4007e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 12s - loss: 2.1160e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 12s - loss: 2.1032e-04 - accuracy: 0.9999  - ETA: 11s - loss: 2.0364e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 11s - loss: 2.0304e-04 - accuracy: 0.9999 - - ETA: 10s - loss: 1.9579e-04 - accuracy: 0 - ETA: 5s - loss: 1 - ETA: 4s - loss: 1.5458e-04 - accuracy: 0.9999 - auc - ETA: 4s - loss: 1.5330e-04 - accuracy: 0.9999 - a - ETA: 3s - loss: 1.5172e-0 - ETA: 2s - loss: 1.4591e-04 - accuracy: 0.9999 - auc:  - ETA: 2s - loss: 1.4511e-04 - accuracy: 0.9999 - auc:  - ETA: 2s - loss: 1.4431e-04 - accuracy: 0.9999 - auc - ETA: 1s - loss: 1.4485e-04 - accuracy: 0.9999 - ETA: 1s - loss: 1.4298e-04 - accu - ETA: 0s - loss: 1.3944e-04 - accuracy\n",
      "Epoch 171/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.0689e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5201 - val_accuracy: 0.4084 - val_auc: 0.6365oss: 2.1684e-05 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 2.6789e-05 - accuracy: 1.0 - ETA: 27s - loss:  - ETA: 24s - loss: 3.5503e-04 - accuracy: 0.9997 - au - ETA: 24s - loss: 3.2807e-04 - - ETA: 21s - loss: 2.5587e-04 - accuracy: 0.99 - ETA: 20s - loss: 2.3387e-04 - accuracy: 0.9998 - auc:  - ETA: 20s - loss: 2.2816e-04 - accuracy: 0.999 - ETA: 19s - loss: 2.1249e-04 - accuracy: 0.9998 - auc: - ETA: 19s - loss: 2.1057e-04 - accuracy: - ETA: 17s - loss: 1.9279e-04 - accuracy: 0. - - ETA: 5s - loss: 1.2270e-04 - accuracy: 0.9999 - auc:  - ETA: 4s - loss: 1.2188e-04 - accuracy: 0. - ETA: 4s - loss: 1.2142e-04 - accuracy: 0.9999 - - ETA: 4s - loss: 1.1996e-04 - accuracy: 0.9999 - auc - ETA: 3s - loss: 1.1899e-04 - accuracy: 0.99 - ETA: 3s - loss: 1.1710e-04 - accuracy:  - ETA: 2s - loss: 1.154 - ETA: 1s - loss: 1.1165e-04 - accura - ETA: 0s - loss: 1.0920e-04 - accu\n",
      "Epoch 172/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.8544e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8823 - val_accuracy: 0.4115 - val_auc: 0.6274 - accuracy - ETA: 27s - loss: 1.9441e-05 - accuracy: 1 - ETA: 25s - loss: 1.7966e-05 - accuracy: 1.0000 - auc: 1. - ETA: 25s - loss: 1.7320e-05 - accuracy: 1.0000 - auc: - ETA: 25s - loss: 2.0414e-05 - accuracy: 1.0000 - auc: - ETA: 24s - loss: 2.0025e-05  - ETA: 22s - loss: 5.982 - ETA: 20s - loss: 4.9455e-05 - a - ETA: 18s - loss: 4.7164e-05 - accuracy: 1.0000 - auc - ETA: 17s - loss: 4.5727e-05 - accuracy: 1.0000 - auc: - ETA: 17s - loss: 4.5192e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 17s - loss: 4.4648e-05 - accuracy: 1.0000 -  - ETA: 16s - loss: 4.7073e-05 -  - ETA: 14s - loss: 4.3454e-05 - accuracy: 1.0000 -  - ETA: 13s - loss: 4.1890e-05 - accuracy: 1.0000 - auc - ETA: 13s - loss: 4.3890e-05 - accur - ETA: 11s - loss: 4.1047e-05 - accuracy: 1.000 - ETA: 10s - loss: 3.9407e-05 - ETA: 9s - loss: 3 - ETA: 7s - loss: 3.7435e-05 - accuracy:  - ETA: 7s - loss: 6.0058e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 7s - loss: 5.9909e-05 - accuracy: 1.0000 - auc: 1. - ETA: 7s - loss: 5.9645e-05 - accuracy:  - ETA: 6s - loss: 5.8612e-05 - accuracy: 1.0000 - - ETA: 6s - loss: 5.8143e - ETA: 4s - loss: 5.6162e-05 - accuracy: 1.0000 - auc: 1.00 - - ETA: 2s - loss: 5.6493e-05 - accuracy: 1.0000 - ETA: 2s - loss: 5.5730e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 5.5440e-05 - accuracy: 1.0000 - auc - ETA: 1s - loss: 5.5018e-05 - accuracy: 1.0000 - a - ETA: 1s - loss: 5.4506e-05 - accuracy: 1.0000 - - ETA: 1s - loss: 5.3908e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 5.4518e-05 - accuracy: 1. - ETA: 0s - loss: 5.3768e-05 - accuracy: \n",
      "Epoch 173/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 64ms/step - loss: 6.7917e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7877 - val_accuracy: 0.4172 - val_auc: 0.6298A: 29s - loss: 4.5218e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 29s - loss: 4.4355e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 28s - loss: 4.1902e-05 - accuracy: 1.0000 - ETA: 28s - loss: 3.2731e-04 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 2.9491e-04 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 2.6539e-04 - accuracy: 1.0000 - auc: 1 - ETA: 26s - loss: 2.5142e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 2.4865e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 26s - loss: 2.4298e-04 - accuracy: 1.0000 - auc - ETA: 26s - loss: 2.2311e-04 - accuracy: 1.0 - ETA: 25s - loss: 1.9120e-04 - accuracy: 1.0000 - auc: 1 - ETA: 24s - loss: 1.8328e-04 - accuracy: 1.0000 - ETA: 23s - loss: 1.6900e-04 - accuracy: 1.0000 -  - ETA: 23s - loss: 1.5660e-04 - accur - ETA: 21s - loss: 1.3914e-04 - ac - ETA: 19s - loss: 1.2008e-04 - accuracy: 1.0000 -  - ETA: 18s - loss: 1.1615e-04 - accuracy - ETA: 17s - loss: 1.0599e-04 - accuracy: 1.0000 - au - ETA: 16s - loss: 1.0181e-04 - accuracy:  - ETA: 15s - loss: 9.6595e-05 - accuracy: 1.0000 - auc: - ETA: 15s - loss: 9.4400e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 15s - loss: 9.3400e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 14s - loss: 9.2765e-05 - accura - ETA: 13s - loss: 9.5291e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 13s - loss: 9.4975e-05 - accura - ETA: 11s - loss: 8.8861e-05 - accuracy: 1.0000 - a - ETA: 11s - loss: 8.6786e-05 - accuracy: 1 - ETA: 9s - loss: 8.2682e-05 - accuracy: 1.0000 - auc: 1 - ETA: 9s - loss: 8.2104e-05 - accuracy: 1.0000 - ETA: 9s - loss: 8.0700e-05  - ETA: 8s - loss: 7.7171e-05 - accuracy:  - ETA: 7s - loss: 7 - ETA: 1s - loss: 6.7198e-05 - accuracy: 1.0000 - auc: 1. - ETA: 1s - loss: 6.6926e-05  - ETA: 0s - loss: 6.6593e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 6.6473e-05 - accuracy\n",
      "Epoch 174/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 1.0136e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5419 - val_accuracy: 0.4134 - val_auc: 0.6373racy: 1.0000 -  - ETA: 28s - loss: 1.1767e-04 - - ETA: 25s - loss: 8.6914 - ETA: 23s - loss: 8.2057e-05 - accuracy: 1.0000 - auc: 1 - ETA: 23s - loss: 9.1658e-05 - accu - ETA: 21s - loss: 1.0656e-04 - ETA: 19s - loss: 9.1587e-05 - accuracy: 1.0000 - ETA: 18s - loss: 8.5697e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 18s - loss: 8.5294e-05 - accuracy: 1.0000 -  - ETA: 17s - loss: 8.0474e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 17s - loss: 7.9815e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 17s - loss: 7.9186e-05 - accuracy: 1.0000 - auc - ETA: 17s - loss: 7.7137e-05 - accuracy: 1.0000 - au - ETA: 16s - loss: 7.4551e-05 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 7.5331e-05 - accuracy: 1.0000 - ETA: 15s - loss: 7.15 - ETA: 13s - loss: 7.3909e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 13s - loss: 7.3520e-05 - accuracy: 1.0000 - auc: - ETA: 12s - loss: 7.2701e-05 - accuracy: 1.0000 - - ETA: 11s - loss: 6.9738e-05 - accur - ETA: 10s - loss: 6.70 - ETA: 8s - loss: 7.4294e-05 - accuracy: 1.00 - ETA - ETA: 6s - loss: 8.1038e-05 - accuracy:  - ETA: 6s - loss: 7.9 - ETA: 4s - loss: 9.4811e-05 - accuracy: 1. - ETA: 4s - loss: 9.3097e-05 - accuracy: 1.0000 - a - ETA: 3s - loss: 9.2162e-05 - accuracy: 1.00 - ETA: 3s - loss: 9.0907e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 9.0712e-05 - accuracy: 1.0000 - a - ETA: 3s - loss: - ETA: 1s - loss: 8.6853e-05 - accuracy:  - ETA: 1s - loss: 8.5199e-05 - accuracy: 1.0000 - - ETA: 0s - loss: 8.5342e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 8.5196e-05 - accuracy: 1. - ETA: 0s - loss: 9.9377e-05 - accuracy: 1.0000 - auc: 1.\n",
      "Epoch 175/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 1.0780e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5596 - val_accuracy: 0.4096 - val_auc: 0.6350 - loss: 6.6505e-06 - accuracy: 1.0000 - auc: 1.00 - ETA: 30s - loss: 6.1872e-06 - accuracy: 1.0000 - auc: 1.0 - ETA: 30s - loss: 5 - ETA: 28s - loss: 1.0562e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 27s - loss: 1.0337 - ETA: 25s - loss: 1.0497e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 25s - loss: 1.0292e-05 - accurac - ETA: 23s - loss: 9.6641e-06 - accuracy:  - ETA - ETA: 10s - l - ETA: 8s - loss: 1.3574e-04 -  - ETA: 7s - loss: 1.3097e-04 - accura - ETA: 7s - loss: 1.2738e - ETA: 1s - l - ETA: 0s - loss: 1.0807e-04 - accuracy: 0.9999 - auc: 1.\n",
      "Epoch 176/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.1637e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5883 - val_accuracy: 0.4126 - val_auc: 0.6350:  - ETA: 22s - loss: 6.0369e-05 -  - ETA: 20s - loss: 7.8837e-05 - accuracy: 1.0000 -  - ETA: 19s - loss: 7.5210e-05 - accuracy - ETA: 13s - loss: 6.5096e-05 - accuracy: 1.0000 - auc: 1. - ETA: 7s - loss: 1.0235e-04  - ETA: 6s - loss: 9.8123e-05 - accu - ETA: 5s - loss: 9.5540e-05 - accuracy: 1. - ETA: 2s - loss: 8.7747e-05 - accuracy: 1.0000 - a - ETA: 2s - loss: 8.6860e-05 -  - ETA: 1s - loss: 8.4566e-05 - accu - ETA: 0s - loss: 8.2296e-05 - accuracy: 1.\n",
      "Epoch 177/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.5255e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5540 - val_accuracy: 0.4100 - val_auc: 0.6363: - ETA: 11s - loss: 6.4814e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 11s - loss: 6.4237e-05 - accu - ETA: 0s - loss: 5.5292e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 178/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 2.8277e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.4903 - val_accuracy: 0.4138 - val_auc: 0.6405s - loss: 2.9501e-04 - accuracy: 0 - ETA: 21s - loss: 7.4861e-04 - accuracy: 0.9996 - a - ETA: 20s - loss: 7.1089e-04 - accuracy: 0.9996 - auc: 1.00 - ETA: 20s - loss: 7.0281e-04 - accuracy: 0.9996 - auc: 1 - ETA: 20s - loss: 6.8607e-04 -  - ETA: 18s - loss: 5.9823e-04 - accuracy: 0.9997 - auc: - ETA: 18s - loss: 5.8035e-04 - accuracy: 0.9997 - auc: 1.00 - ETA: 18s - loss: 5.7510e-04 - accuracy: 0.9997 - auc: - ETA: 17s - loss: 5.5737e-04 - accuracy: 0.9997 - auc: 1 - ETA: 17s - loss: 5.4562e-04 - accuracy: 0.9997 - a - ETA: 16s - loss: 5.2 - ETA: 14s - loss: 4.8263e-04 - accuracy: - ETA: 13s - loss: 4.5613e-04 - - ETA: 11s - loss: 4.1765e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 10s - loss: 4.1413e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 1 - ETA: 4s - loss: 3.2506e-04 - accuracy:  - ETA: 1s - loss: 2.9767e-04 - ac - ETA: 1s - loss: 2.8925e-04 - accuracy: 0.9999 - auc:  - ETA: 0s - loss: 2.8756e-04 - ac\n",
      "Epoch 179/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.4702e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5652 - val_accuracy: 0.4142 - val_auc: 0.6387TA: 29s - loss: 2.1431e-05 - accuracy: 1.000 - ETA: 28s - loss: 1.6901e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 1.7055e-05 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 2.0760e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 27s - loss: 2.0624e-05 - accuracy: 1.0000 - - ETA: 27s - loss: 2.2842e-05 - accuracy: 1.0000 - auc: - ETA: 26s - loss: 2.2814e-05 - accuracy: 1.0000 - auc: 1. - ETA: 26s - loss: 2.1914e-05 - ETA: 24s - loss: 2.4523e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 2.4340e-05 - accuracy: 1.0000 - auc:  - ETA: 23s - loss: 2.3594e-05 - accuracy: 1 - ETA: 22s - loss: 2.2604e-05 - accuracy: 1.0000 - ETA: 21s - loss: 2.1313e-05 - accuracy: 1.0000 - - ETA: 21s - loss: 2.0402e-05 - accuracy: 1.0 - ETA: 19s - loss: 1.8761e-05 - accuracy: 1.0000 - auc:  - ETA: 19s - loss: 1.8644e-05 - accuracy: 1.0000 - auc: 1.000 -  - ETA: 15s - loss: 2.0795e-05 - acc - ETA: 7s - loss: 3.1609e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 7s - loss: 3.1642e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 7s - loss: 3.2884e-05 - accura - ETA: 6s - loss: 3.2319e-05 - accura - ETA - ETA: 3s - loss: 3.2744e-05 - accuracy: 1. - ETA: 3s - loss: 3.2573e-05 - accuracy - ETA: 2s - loss: 3.2213e-05 - accuracy - ETA:  - ETA: 0s - loss: 3.4948e-05 - accuracy: 1.0000 - a\n",
      "Epoch 180/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.3634e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5177 - val_accuracy: 0.4088 - val_auc: 0.6354505e-05 - accuracy: 1.0 - ETA: 22s - loss: 7.3949e-05 - - ETA: 19s - loss: 7.2062e-05 - accuracy: 1.0000 - - ETA: 19s - loss: 8.363 - ETA: 16s - loss: 8.0098e-05 - accuracy: 1.0000  - ETA: 16s - loss: 7.6250e-05 - accuracy: 1.0000 - au - ETA: 15s - loss: 2.4051e-04 - accuracy: 1.0000 - auc:  - ETA: 15s - loss: 2.3538e-04 - accuracy: 1.0000  - ETA: 14s - loss: 2.2480e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 14s - loss: 2.2267e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 2.2194e-04 - accuracy: 1.0000 - a - ETA: 13s - loss: 2.1443e-04 - accuracy: 1.0000 - auc: 1 - ETA: 13s - loss: 2.1030e-04 - accuracy: 1 - ETA: 12s - loss: 1.9810e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 12s - loss: 1.9748e-04 - accuracy: 1.0000 - auc:  - ETA:  - ETA: 9s - loss: 1.8021e-04 - ac - ETA: 8s - loss: 1.7443e-04 - accura - ETA: 7s - loss: 1.7066e-04 -  - ETA: 6s - loss: 1.6466e-0 - ETA: 5s - loss: 1.5820e-04 -  - ETA: 4s - loss: 1.5 - ETA: 2s - - ETA: 1s - loss: 1.4150e-04 - accuracy: 1.0000 - auc: 1. - ETA: 1s - loss: 1.4069e-04 - accura - ETA: 0s - loss: 1.3797e-04 - accuracy: 1.0000 -\n",
      "Epoch 181/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.4593e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7669 - val_accuracy: 0.4199 - val_auc: 0.62700000  - ETA: 23s - loss: 8.3048e-05 - accuracy: 1. - ETA: 22s - loss: 7.2465e-05 - accuracy: 1.0000 - ETA: 21s - loss: 6.6888e-05 - accuracy: 1.0000 - ETA: 16s - loss: 7.0780e-05 - accuracy: 1.0000 - a - ETA: 15s - loss: 6.9750e-05 - accura - ETA: 14s - loss: 6.6342e-05 - accuracy: 1 - ETA: 12s - lo - ETA: 9s\n",
      "Epoch 182/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 5.5799e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5847 - val_accuracy: 0.4069 - val_auc: 0.6339 24s - loss: 2.2595e-05 - accuracy: 1.0000 - auc:  - ETA: 23s - loss: 2.1543e-05 - accuracy: 1.0000 - ETA: 22s - - ETA: 19s - loss: 4.3122e-05 - accuracy: 1.0000 - au - ETA: 18s - loss: 4.2650e-05  - ET - ETA: 13s - loss: 4.7973e-05 - accuracy: 1.0000 - auc - ETA: 12s - loss: 4.6541e-05 - accuracy: 1.00 - ETA: 11s - loss: 4.7139e-05 - accu - ETA: 7s - loss: 6.4092e-05  - ETA: 6s - loss: 6.2100e-05 - accuracy: 1.0000 - a - ETA: 6s - loss: 6.1380e-05 - accuracy:  - ETA - ETA: 4s - loss: 5.9559e - ETA: 2s - loss: 5.8686e-05 - accuracy: \n",
      "Epoch 183/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.6735e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8138 - val_accuracy: 0.4172 - val_auc: 0.6271oss: 2.0781e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 23s - loss: 2.0519e-05 - accuracy: 1.0000 - a - ETA: 22s - loss: 1.8971e-05 - accuracy: 1.0000 - auc - ETA: 22s - loss: 1.8037e-05 - accuracy: 1.0000 - au - ETA: 21s - loss: 1.7977e-05 - - ETA: 19s  - ETA: 16s - loss: 1.8936e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 1.9058e-05 - accuracy: 1.0000 - a - ETA: 15s - loss: 1.8607e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 15s - loss: 1.8562e-05 - accuracy: 1 - ETA: 14s - loss: 1.8147e-05 - accuracy: - ETA: 12s - loss: 1.8958e-05 - accuracy: 1.0000 - auc: 1 - ETA: 12s - loss: 1.9786e-05 - accuracy: 1.0 - ETA: 11s - loss: 2.8002e-05 - accuracy: 1.0000 - a - ETA: 10s - l - ETA: 0s - loss: 4.7835e-05 - accu\n",
      "Epoch 184/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 9.7093e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8292 - val_accuracy: 0.4176 - val_auc: 0.6314s - loss: 5.9308e-06 - accuracy: 1.0000 - auc: 1 - ETA: 30s - loss: 3.0251e-05 - accuracy: 1.0000 - auc: - ETA: 29s - loss: 2.1377e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 1.9974e-05 - acc - ETA: 27s - loss: 1.3835e-05 - accuracy:  - ETA: 26s - loss: 3.6076e-05 - - ETA: 16s - loss: 6.7016e-05 - accura - ETA: 14s - loss: 6.2600e-05 - accuracy: 1.0000 - auc: 1.000 - - ETA: 10s  - ETA: 6s - loss: 5.6 - ETA: 5s - loss: 5.4510e-05 - accuracy: 1.0000 - auc: 1. - ETA: 5s - loss: 5.4463e-05 - accuracy: 1.0000 - auc - ETA: 4s - loss: 5.4342e-0 - ETA: 1s - loss: 1.0123e - ETA: 0s - loss: 9.8371e-05 - accuracy: 1.00\n",
      "Epoch 185/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.3876e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6139 - val_accuracy: 0.4103 - val_auc: 0.6357-05 - accuracy: 1. - ETA: 4s - loss: 5.6763e-05 - accuracy: 1.00 - ETA: 4s - loss: 5.5690e-05 - accuracy:  - ETA: 3s - loss: 5.9052e-05  - ETA: 2s - - ETA: 0s - loss: 5.5001e-05 - accu\n",
      "Epoch 186/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.5915e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7543 - val_accuracy: 0.4180 - val_auc: 0.6325 1.2162e-05 - accuracy: 1 - ETA: 22s - loss: 1.2429e-05 - accuracy: 1.0 - ETA: 21s - loss: 2.1349e-05 - accuracy: 1.0000 - auc: 1 - ETA: 21s - loss: 2.0900e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 2.0597e-05 - accuracy: 1.0000 - a - ETA: 20s - loss: 2.0450e-05 - accuracy: 1 - ETA: 19s - loss: 2.0973 - ETA: 16s - loss: 5.5994e-05 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 5.5908e-05 - accuracy: 1.0000 - auc: 1 - ETA: 16s - loss: 5.5959e-05 - accuracy: 1.0000 - auc - ETA: 15s - loss: 5.4428e-05 - accuracy: 1.0000  - ETA: 15s - loss: 5.4021e-05 - accuracy: 1.000 - ETA: 14s - loss: 5.2085e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 9s - loss: 4.8353e-05 - accuracy - ETA: 9s - loss: 4.7433e-05 - accuracy: 1. - ETA: 8s - loss: 4.8269e-05 - accuracy: 1.0000 - - ETA: 2s - loss: 4.5607e-05 - accu - ETA: 1s - loss: 4.4618e-05 - accuracy: 1.0000 - a - ETA: 1s - los\n",
      "Epoch 187/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.8252e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7827 - val_accuracy: 0.4142 - val_auc: 0.6335s: 6.7334e-06 - accuracy: 1.0000 - auc: 1.000 - ETA: 28s - loss: 6.6420e-06 - accuracy: 1.00 - ETA: 27s - loss: 8.6068e-06 - accuracy: 1.0000 - a - ETA: 26s - loss: 7.9816e-06 - accuracy - ETA: 25s - loss: 1.0510e-05 - accuracy: 1.0000 - auc: 1. - ETA: 25s - loss: 1.0410e-05 - accu - ETA: 23s - loss: 9.3663e-06 - accuracy: 1.0000 - auc: 1.00 - ETA: 23s - loss: 9.2851e-06 - accuracy: 1.0000 - auc: 1. - ETA: 23s - loss: 9.0475e-06 - accuracy: 1.0000 - auc: 1.00 - ETA: 22s - loss: 8.9355e-06 - accuracy: 1.0000 - auc: - ETA: 22s - loss: 1.1789e-04 - accura - ETA: 20s - loss: 1.0114e-04 - accuracy: 1.0000 - - ETA: 20s - loss: 1.0530e-04 - accuracy: 1. - ETA: 19s - loss: 9.7772e-05 - accuracy: - ETA: 17s - loss: 9.222 - ETA: 15s - loss: 8.0048e-05 - accuracy: 1. - ETA: 10s - loss: 6.3986e-05 - accuracy: 1 - ETA: 9s - loss: 6.2609e-05 - accuracy: 1.0000 - - ETA: 8s - los - ETA: 7s - loss: 6.0218e-05 - accuracy: 1.0000 - auc: 1. - ETA: 7s - loss: 5.9919e-05 - ac - ETA:  - ETA: 4s - loss: 6.4111e-05 - accuracy - ETA: 3s - loss: 6.2977e-05 - accuracy:  - ETA: 3s - loss: 6.2\n",
      "Epoch 188/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.0361e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6762 - val_accuracy: 0.4119 - val_auc: 0.6342- ETA: 20s - loss: 1.1725e-04 - accuracy: 1.0000 - auc: 1.000 -  - ETA: 17s - loss: 1.2497e-04 - accura - ETA:  - ETA: 6s - loss: 1.2116e-04 - accuracy: 1. - ETA: 6s - l - ETA: 4s - los - ETA - ETA: 1s - loss: 1.0527e-04 - accuracy: 1.0000 - - ETA: 1s - loss: 1.0616e-04 - accura - ETA: 0s - loss: 1.0487e-04 - accuracy: 1.0000 -\n",
      "Epoch 189/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 34s 66ms/step - loss: 3.9770e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7183 - val_accuracy: 0.4119 - val_auc: 0.63493.6129e-05 - ETA: 28s - loss: 2.3264e-05 - accuracy: 1.0000 - auc: - ETA: 27s - loss: 2.2957e-05 - accurac - ETA: 26s - loss: 2.5980e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 25s - loss: 2.5543e-05 - accurac - ETA: 24s - loss: 2.3788e-05 - accuracy: 1.0000 - auc: 1 - ETA: 24s - loss: 2.3503e-05 - accuracy: 1.0000 - - ETA: 23s  - ETA: 1 - ETA: 13s - loss: 4. - ETA: 10s - loss: 4.8087e-05 - accu - ETA: 9s - loss: 4.6027e-05 -  - ETA: 8s - loss: 4.5335e-05 -  - ETA: 7s - loss: 4.3920e-05 - accuracy: 1.0000 - a - E - ETA: 5s - loss: 4.4793e-05 -  - ETA: 4s - loss: 4.3560e-05 - accuracy: 1. - ETA: 3s - loss: 4.2819e-05 - accura - ETA: 3s - loss: 4.2113e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 4.1870e-05 - accu - ETA: 2s - loss: 4.1667e-05 - accu - ETA: 1s - loss: 4.0585e-05 - accuracy: 1.00 - ETA: 0s - loss: 4.0370e-05 - accuracy: 1.00 - ETA: 0s - loss: 3.9969e-05 - accuracy: 1.0000 - auc\n",
      "Epoch 190/250\n",
      "518/518 [==============================] - 34s 66ms/step - loss: 1.7506e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.6460 - val_accuracy: 0.4138 - val_auc: 0.6359accuracy: 1.000 - ETA: 26s - loss: 2.1536e-05 - - ETA: 24s - loss: 2.1087e-05 -  - ETA: 22s - loss: 3.4327e-05 - accuracy: 1.0000 - auc: - ETA: 22s - loss: 3.3373e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 21s - loss: 3.3034e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 21s - loss: 3.2850e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 21s - loss: 3.5712e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 21s - loss: 3.5138e-05 - accuracy: 1.0000 - a - ETA: 20s - loss: 3.7182e-05 - accuracy: 1 - ETA: 19s - loss: 3.7814e-05 - accur - ETA: 13s - loss: 2.4626e-04 - accurac - ETA: 12s - loss: 2.2964e-04 - accuracy: 0.9999 - auc: - ETA: 12s - loss: 2. - ETA: 9s - los - ETA: 8s - loss: 1.9629e-04 - accuracy: 0. - ETA: 7s - loss: 1.9257e-04 - accuracy: 0.9999 - ETA: 7s - loss: 1.9279e-04 - accuracy: 0.9999 - auc - ETA: 6s - loss: 1.9176e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 6s - ETA: 5s - loss: 1.8071e - ETA: 3s - loss: 1.7339e-04 - accuracy: 0.99 - ETA: 3s - loss: 1.7071e-04 - accuracy - ETA: 2s - loss: 1.8807e-04 - accuracy: 0.9999 - auc:  - ETA: 2s - los - ETA: 0s - loss: 1.7903e-04 - accuracy: 0.99 - ETA: 0s - loss: 1.7643e-04 - accuracy: 0.9999 - auc - ETA: 0s - loss: 1.7517e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 191/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 7.2618e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8203 - val_accuracy: 0.4172 - val_auc: 0.63579s - loss: 4.4845e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 3.6702e-05 - accuracy: 1.0000 -  - ETA: 28s - loss: 2.7204e-05 - accuracy: 1.0000 - ETA: 27s - loss: 2.3673e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 27s - loss: 2.2835e-05 - accuracy: 1.0000 -  - ETA: 26s - loss: 2.1377e-05 - accuracy: 1.0000 - auc: 1 - ETA: 26s - loss: 2.0399e-05 - accuracy: 1.0000 - auc: 1 - ETA: 26s - loss: 1.9435e-05 - accuracy: 1.0000 - auc - ETA: 25s - loss: 2.3326e-05 - accuracy: 1.0000 -  - ETA: 25s - loss: 1.8155e-04  - ETA: 23s - loss: 1.5253e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 1.5217e-04 - accuracy: 1.0000 - auc: 1. - ETA: 23s - loss: 1.4769e-04 - accuracy: 1.0000 -  - ETA: 22s - loss: 1.3695e-04 - accuracy: 1.0000 - auc: 1. - ETA: 22s - loss: 1.3356e-04 - accuracy: 1.0000 - auc: 1. - ETA: 21s - loss: 1.3016e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 21s - loss: 1.2934e-04 - accuracy: 1.0000 - a - ETA: 21s - loss: 1.2317e-04 - accuracy: 1.0000 - auc: 1 - ETA: 21s - loss: 1.2006e - ETA: 18s - loss: 1.2455e-04 - accuracy:  - ETA: 17s - loss: 1.2670e-04 - accuracy: 1.0000 - auc: 1.0 - ETA: 17s - loss: 1.2510e-04 - accuracy: 1.0000  - ETA: 16s - loss: 1.1830e-04 - accuracy: 1.0000 - auc:  - ETA: 16s - loss: 1.1583e-04 - accuracy: 1.0000  - ETA: 15s - loss: 1.0993e-04 - accuracy: 1.0000 - - ETA: 14s - loss: 1.0540e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 1.0505e-04 - accuracy: 1.00 - ETA: 13s - loss: - ETA: 10s - loss: 8.8555e-05 - accuracy: 1.0000 - ETA: 9s - loss: 8.6643e-05 - accuracy - ETA: 7s - loss: 8.4193e-05 - accuracy: 1.00 - ETA: 6s - ETA: 4s - loss: 7.9850e-05 - ac - ETA: 3s - loss: 7.799 - ETA: 2s - loss: 7.5066e-05 - accuracy: 1.0000 - auc: 1. - ETA: 2s - loss: 7.4684e-05 - accura - ETA: 1s - los - ETA: 0s - loss: 7.3132e-05 - accuracy: 1.0000 -\n",
      "Epoch 192/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.0948e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.0199 - val_accuracy: 0.4195 - val_auc: 0.6341racy: 1.00 - ETA: 27s - loss: 1.3334e-04 - accuracy: 1.0000 - ETA: 27s - loss: 1.1166e-04 - accuracy: 1.0000 - a - ETA: 26s - loss: 9.9372e-05 - accuracy: 1.0000 - auc: 1 - ETA: 26s - loss: 9.4307e-05 - accuracy: 1.0000 - auc: 1 - ETA: 25s - loss: 8.9587e-05 - accuracy: 1.00 - ETA: 24s - loss: 1.2743e-04 - ac - ETA: 22s - loss: 1.0464e-04 - accura - ETA: 20s - loss: 1.0178e-04 - accuracy: 1 - ETA: 19s - loss: 9.3991e-05 - accuracy: 1.0000 - auc: - ETA: 19s - loss: 9 - ETA: 16s - loss: 1.0044e-04 - accuracy: 1. - ETA: 15s - loss: 1.0910e-04 - accuracy:  - ETA: 14s - loss: 1.0419e-04 - accuracy: 1.0000 - ETA: 13s - loss: 9.9592e-05 - accur - ETA: 11s - loss: 1.0020e-04 - accuracy: 1. - ETA: 10s - loss: 9.4715e-05 - - ETA: 9s - loss: 9.0639e-05 - accuracy: 1.0000 - auc:  - ETA - ETA: 6s - loss: 9.8163e-05 - accuracy: 1. - ETA: 6s - loss: 9.6661e-05 - accuracy: 1.0000\n",
      "Epoch 193/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 2.6720e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7503 - val_accuracy: 0.4111 - val_auc: 0.6354: 30s - loss: 7.6898e-05 - accur - ETA: 28s - loss: 1.9164e-05 - accuracy: 1.0000 - au - ETA: 28s - loss: 2.2866e-05 - - ETA: 26s - loss: 3. - ETA: 23s - loss: 2.7992e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 2.7789e-05 - accuracy: 1.0000 - auc: 1.000 - ET - ETA: 15s - loss: 2.4960e-05 - accuracy: 1.0000 - ETA: 14s - loss: 2.3948e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 2.3867e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 14s - loss: 2.3780e-05 - accuracy: 1.0000 - a - ETA: 13s - loss: 2.3939e-05  - ETA: 11s - loss: 2.4833e-05 - accuracy: 1.0000 -  - ETA: 10s - l - ETA: 8s - loss: 2.3982e-05 - accuracy: 1.00 - ETA: 8s - loss: 2.3575e-05 - accuracy: 1.0000 - a - ETA: 8s - loss: 2.3414e-05 - accuracy: 1.00 - ETA: 7s - loss: 2.3034e-05 - accuracy: 1.0000 - auc: 1. - ETA: 7s - loss: 2.2921e-05 - accuracy: 1.0000 - auc:  - ETA: 5s - loss: 2.4681e-05 - accuracy: 1.0000 - a - ETA: 4s - loss: 2.7874e-05 - accuracy: 1.0000 - a - ETA: 4s - loss: 2.8450e-05 - accuracy: 1.0000 - ETA: 1s - loss: 2.7993e-05 - accuracy: 1.0000 - auc: 1.00 - E - ETA: 0s - loss: 2.6738e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 194/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.8382e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.1048 - val_accuracy: 0.4157 - val_auc: 0.6304- ETA: 17s - loss: 2.9047e-05 - accuracy: 1.00 - ETA: 16s - loss: 3.7024e-05 - accuracy: 1.0000 - auc - ETA: 16s - loss: 3.651 - ETA: 1s - loss: 2.8135e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 1s - loss: 2.8102e - ETA: 0s - loss: 2.8915e-05 - accuracy: 1.0000 - auc: 1. - ETA: 0s - loss: 2.8808e-05 - accuracy\n",
      "Epoch 195/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 8.8275e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.9772 - val_accuracy: 0.4149 - val_auc: 0.6288oss: 2.8852e-05 - accuracy: 1.000 - ETA: 30s - loss: 1.7605e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 1.6578e-05 - accuracy: 1.0000 - auc: - ETA: 29s - loss: 1.5069e-05 - accuracy: 1.0000 -  - ETA: 28s - loss: 1.9331e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 1.8618e-04 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 1.716 - ETA: 25s - loss: 1.0812e-04 - accuracy: 1.0000 - auc: 1 - ETA: 25s - loss: 1.0303e-04 - accuracy: 1.0000 - au - ETA: 25s - loss: 9.5283e-05 - accuracy: 1.0 - ETA: 24s - loss: 9.1858e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 9.1156e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 9.0498e-05 - accuracy: 1.0000 - - ETA: 23s - loss: 8.2910e-05 - accuracy: 1.0000 - auc:  - ETA: 22s - loss: 8.0068e-05 - accuracy: 1 - ETA: 21s - loss: 7.3390e-05 - accuracy: 1.0000 - a - ETA: 20s - loss: 8.1184e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - loss: 8.0754e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - loss: 7.9989e-05 - accura - ETA: 19s - loss: 8 - ETA: 12s - loss: 6.2134e-05 - accuracy: 1.0000 - - ETA: 11s - loss: 6.0781e-05 - accuracy: 1.0000 - auc: 1. - ETA: 11s - loss: 6.0067e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 11s - loss: 5.9672e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 11s - loss: 5.9496e-05 - accuracy: 1. - ETA: 10s - loss: 5.8593e-05 - accura - ETA: 9s - loss: 9.3947e-05 - accuracy - ETA: 8s - loss: 9.4378e-05 - accuracy: 1. - ETA: 8s - loss: 9.2269e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 8s - loss: 9.2048e-05 - accuracy:  - ETA: 7s - loss: 9.0111e-05 - accura - ETA: 6s - loss: 8.7697e-05 - accuracy: 1.0000 - auc:  - ETA: 6s - loss: 8.7076e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 8.6871e-05 - accuracy: 1.0000 - auc: 1. - ETA: 6s - loss: 8.6458e-05 - ac - ETA: 5s - loss: 8.4493e-05 - accu - ETA: 4s - loss: 8.2809e-05 - accuracy: 1. - ETA: 3s - loss: 8.1042e-05 - accuracy: 1. - ETA: 3s - loss: 8.0076e-05 - accuracy: 1.00 - ETA: 2s - loss: 7.8534e-05 - accu - ETA: 1s - loss: 7.6827e-05 - accuracy: 1.0000 - - ETA: 1s - loss: 9.2328e-05 - accuracy: 1.0000 - ETA: 1s - loss: 9.1057e-05 - accuracy: 1.0000 - auc:  - ETA: 0s - loss: 9.0523e-05 - ac\n",
      "Epoch 196/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.0569e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7444 - val_accuracy: 0.4119 - val_auc: 0.6312 - ETA: 26s - loss: 1.6846e-05 - - ETA: 24s - loss: 2.9871e-05 - accuracy: 1.0000 - a - ETA: 19s - loss: 4.7660e-05 - accuracy:  - ETA: 18s - loss: 2.0242e-04 - accuracy - ETA: 17s - loss: 1.8318e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 16s - loss: 1.8241e-04 - accuracy - ETA: 15s - loss: 1.7754e-04 - accuracy: 0.9999 - auc - ETA: 15s - loss: 1.7229e-04 - accuracy: 0.9999  - ETA: 14s - loss: 1.6504e-04 - accuracy: 0.9999  - ETA: 13s - loss: 1.6232e-04 - accuracy: 0.9999 - auc:  - ETA: 13s - loss: 1.5920e-04 - - ETA: 10s - loss: 1.4703e-04 - accuracy: 0.9999 - ETA: 9s - loss: 1.4326e-04 - accuracy: 0.9999 -  - ETA: 9s - loss: 1.4088e-04 - accuracy - ETA: 8s - loss: 1.3618e-04 - ac - ETA: 7s - los - ETA: 6s - loss: 1.2489e-0 - ETA: 3s - loss: 1.1203e - ETA: 2s - loss: 1.0921e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 2s - loss: 1.089 - ETA: 0s - loss: 1.0511e-04 - accuracy:  - ETA: 0s - loss: 1.0654e-04 - accuracy: 0.9999 - a\n",
      "Epoch 197/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.6654e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7225 - val_accuracy: 0.4092 - val_auc: 0.6335s - loss: 1.0021e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 28s  - ETA: 24s - loss: 5.4353e-05 - accuracy: - ETA: 23s - loss: 6.2020e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 6.1538e-05 - accuracy: 1.0000 -  - ETA: 22s - loss: 1.033 - ETA: 20s - loss: - ETA: 17s - loss: 8.6123e-05 - accuracy: 1.000 - ETA: 16s - loss: 7.9677e-05 - accuracy: 1.0000  - ETA: 15s - loss: 8.0527e-05 -  - ETA: 13s - loss: 7.3451e-05 - ac - ETA: 12s - loss: 2.4864e-04 - accuracy:  - ETA: 10s - loss: 2.3309e-04 - accuracy: 0.9999 - au - ETA: 10s - loss:  - ETA: 8s - loss: 2.1902e-04 - accuracy: 0.9999 - auc - ETA: 8s - loss: 2.1672e-04 - accuracy: 0.9999 - auc:  - E - ETA: 6s - loss: 2.0495e-04 - accuracy - ETA: 3s - loss: 1.8603e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 3s - l - ETA: 2s - loss: 1.7 - ETA: 0s - loss: 1.7050e-04 - accuracy: 0.9999 - ETA: 0s - loss: 1.6825e-04 - accuracy: 0.9999 -\n",
      "Epoch 198/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.3823e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.5813 - val_accuracy: 0.4130 - val_auc: 0.63800 - - ETA: 27s - loss: 1.0498e-04 - ac - ETA: 21s - loss: 4.3643e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 21s - loss: 4.3376e-04 - accuracy: - ETA: 20s - loss: 3.9847e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 20s - loss: 3.9223e-04 - accura - ETA: 18s - loss: 3.4744e-04 - accuracy: 0 - ETA: 17s - loss: 3.2035e-04 - accuracy:  - ETA: 16s - loss: 2.9744e-04 - accuracy: 0 - ETA: 15s - loss: 3.0336e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 14s - loss: 3.0115e-04 - accuracy: 0.9999 - auc: 1.0 - ETA: 14s - loss: 2.9789e-04 - accuracy: 0.99 - ETA: 13s - loss: 4.0615e-04 - accuracy: 0 - ETA: 12s - loss: 3.8221e-04 - accuracy: 0.9998 -  - ETA: 11s - loss: 3.6731e-04 - accuracy: 0.9998 - auc: 1 - ETA: 11s - loss: 3.6224e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 11s - loss: 3.6008e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 11s - loss: 3.5912e-04 - accuracy: 0.9998  - ETA: 10s - loss: 3.4592e-04 - accuracy: 0.9998 - auc: 1 - ETA: 10s - loss: 3.4114e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 10s - loss: 3.3923e-04 - accuracy: 0.9998 - auc: 1. - ETA: 9s - loss: 3.3636e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 9s - loss: 3.3762e-04 - accuracy: 0.99 - ETA: 9s - loss: 3 - ETA: 8s - loss: 3.1333e-04 - accuracy: 0.9998 - ETA: 7s - loss: 3.0784e-04 - accura - ETA: 6s - loss: 3.0008e-04  - ETA: 5s - loss: 2.8884e-04 - accuracy: 0.99 - ETA: 5s - loss: 2.8372e-04 - accuracy: 0.9999 - auc:  - ETA - ETA: 3s - loss: 2.6428e-04 - accuracy: 0.99 - ETA: 2s - loss: 2.6036e-04 - accuracy: 0.9999 - auc: 1. - ETA: 2s - loss: 2.5927e-0 - ETA: 1s - loss: 2.4995e-04 - accuracy: 0.9999 - auc:  - ETA: 1s - loss: 2.4844e-04 - accuracy - ETA: 0s - loss: 2.4272e-04 - accuracy: \n",
      "Epoch 199/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 4.8936e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5935 - val_accuracy: 0.4126 - val_auc: 0.6371s - loss: 1.8189e-05 - accuracy: 1.0000 - - ETA: 29s - loss: 1.9172e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 29s - loss: 1.9355e-04 - accuracy: 1.0000  - ETA: 28s - loss: 1.4046e-04 - accuracy: 1.0000 - - ETA: 27s - loss: 1.1076e-04 - accuracy: 1 - ETA: 26s - loss: 9.2491e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 9.1294e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 26s - loss: 8.7966e-05 - accur - ETA: 24s - loss: 1.4283e-04 - accuracy: 1.0000 - a - ETA: 24s - loss: 1.3119e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 24s - loss: 1.3010e-04 - accuracy: 1.0000 - auc: - ETA: 23s - loss: 1.2293e-04 - accuracy:  - ETA: 22s - loss: 1.0643e-04 - accuracy: 1.0000 - au - ETA: 21s - loss: 1.0155e-04 - accurac - ETA: 20s - loss: 9.0984e-05 - accuracy: 1.0000 - auc: 1. - ETA: 19s - l - ETA: 16s - loss: 7.6406e-05 - accuracy: 1.00 - ETA: 15s - loss: 7.2911e-05 - accuracy: 1.0000 - auc: 1. - ETA: 15s - loss: 7.4288e-05 - accuracy: 1.0000 - auc: 1. - ETA: 15s - loss: 7.3290e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 15s - loss: 7.3067e-05 - accuracy: 1.0000 - auc:  - ETA: 14s - loss: 7.1504e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 14s - loss: 7.1018e-05 - - ETA: 12s - loss: 7.1838e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 12s - loss: 7.1162e-05 - accuracy - ETA: 10s - loss: 6.7408e-05  - ETA: 9s - loss: 6.384 - ETA: 8s - los - ETA: 6s - loss: 5.8696e-05 - accuracy: 1. - ETA: 6s - loss: 5.7 - ETA: 4s - loss: 5.6809e-05 - accuracy: 1.0000 - - ETA: 4s - loss: 5.6113e-05 - accuracy: 1.0000 - ETA: 4s - loss: 5.5260e-05 - accuracy: 1.0000 - ETA: 3s - loss: 5.4459e-05 - accu - ETA: 3s - loss: 5.3103e-05 - accuracy: 1.0000 - - ETA: 2s - loss: 5 - ETA: 1s - loss: 5.0765e-05 - accuracy: 1.00 - ETA: 0s - loss: 4.9967e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 4.9938e-05 - accura\n",
      "Epoch 200/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.9680e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6985 - val_accuracy: 0.4222 - val_auc: 0.6349- loss: 4.9420e-06 - accurac - ETA: 28s - loss: 9.1003e-06 - accuracy: 1.0000 - auc: 1. - ETA: 28s - loss: 1.0578e-05 - accuracy: 1.0000 - ETA: 27s - loss: 1.5177e-05 - accuracy: 1.0000 - auc: 1. - ETA: 27s - loss: 1.5075e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 27s - loss: 1.4863e-05 - accuracy: 1.0000 - au - ETA: 26s - loss: 1.5251e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 26s - loss: 1.5035e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 1.4984e-05 - accuracy: 1.0000  - ETA: 25s - loss: 2.1692e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 25s - loss: 2.1469e-05 - - ETA: 23s - loss: 3.0767e-05 - accuracy: 1.0000 - a - ETA: 22s - loss: 2.9153e-05 - accuracy: 1.0000 - auc:  - ETA: 22s - loss: 2.8266e-05 - ac - ETA: 20s - loss: 2.5052e-05 - accuracy: 1.0000 - auc:  - ETA: 20s - loss: 2.5068e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 2.4938e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 19s - loss: 2.4551e-05 - accuracy: 1.0000  - ETA: 18s - loss: 2.3157e-05 - accuracy: 1.0000 - auc - ETA: 18s - loss: 2.2 - ETA: 15s - loss: 2.2715e-05 - accurac - ETA: 14s - loss: 2.8402e-05 - accuracy: 1.0000 - - ETA: 13s - loss: 2.7928 - ETA: 10s - loss: 2.6182e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 1 - ETA: 6s - loss: 2.7 - ETA: 5s - loss: 2.7004e-05 - accura - ETA: 4s - loss: 2.6373e-05 - accuracy: 1.00 - ETA: 4s - loss: 7.3174e-05 - accuracy: 1.0000 - ETA: 3s - loss: 7.2085e-05 - accuracy: 1.0000 - auc:  - ETA: 3s - loss: 7.3142e-05 - accu - ETA: 2s - loss: 7.3347e-05 - accuracy: 1.0000 - auc - ETA: 2s - loss: 7.4917e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 7.4449e-05 - accuracy: 1.0000 - auc: 1. - ETA: 2s - l - ETA: 0s - loss: 7.1386e-05 - accuracy: 1.00 - ETA: 0s - loss: 7.0361e-05 - accuracy: 1.0000 -\n",
      "Epoch 201/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 6.6480e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7206 - val_accuracy: 0.4084 - val_auc: 0.6349 - accura - ETA: 27s - loss: 5.3754e-05 - accuracy: 1.0000 - auc:  - ETA: 26s - loss: 5.1583e-05 -  - ETA: 24s - loss: 1.7693e-04 - accuracy: 1.0000 - auc:  - ETA: 24s - loss: 1.6809e-04 - accuracy: 1.0000 - auc: 1. - ETA: 23s - loss: 1.6270e-04 - acc - ETA: 22s - loss: 1.3 - ETA: 19s - loss: 1.0697e-04 - accuracy: 1.0000 - - ETA: 19s - loss: 1.0113e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 18s - loss: 1.0064e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 18s - loss: 9.9815e-05 - accuracy: 1.0000 - - ETA: 18s - loss: 9.4283e-05 - accuracy: 1.0000 - auc: - ETA: 17s - loss: 9.3054e-05 - accuracy: 1.0000 - ETA: 16s - loss: 8.8255e-05 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 8.7007e-05 - accuracy: 1.0000 - a - ETA: 15s - loss: 8.3629e-05 - accuracy: 1.0000 - - ETA: 15s - loss: 7.9793e-05 - accuracy:  - ETA: 13s - loss:  - ETA: 10s - loss: 9.2860e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 10s - loss: 9.2324e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 9.1537e-05 - a - ETA: 9s - loss: 8.8368e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 9s - loss: 8.8155e-05 - accuracy - ETA: 8s - loss: 8.5143e-05 - accuracy - ETA: 7s - l - ETA: 4s - loss: 7 - ETA: 2s - loss: 7.1990e-05 - accuracy: 1.0000 - auc:  - ETA: 2s - loss: 7.1713e-05 - accuracy: 1.0000 - auc - ETA: 0s - loss: 6.7565e-05 - accuracy: 1.0000 - auc: 1. - ETA: 0s - loss: 6.7507e-05 - accuracy: 1.\n",
      "Epoch 202/250\n",
      "518/518 [==============================] - 32s 62ms/step - loss: 4.7870e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.9320 - val_accuracy: 0.4176 - val_auc: 0.6308cy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 5.1054e-05 - ac -\n",
      "Epoch 203/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.8205e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.9590 - val_accuracy: 0.4211 - val_auc: 0.6305: 2.6328e-05  - ETA: 27s - loss: 2.3932 - ETA: 25s - loss: 1.9456e-05 - accuracy: 1.0000 - a - ETA: 24s - loss: 1.7883e-05 - accuracy: 1.0000 - auc:  - ETA: 24s - loss: 1.9137e-05 - ac - ETA: 22s - loss: 2.0068e-05 - accuracy: 1.0000 - auc: - ETA: 21s - loss: 1.9167e-05 - a - ETA: 19s - loss: 1.9060e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 1.8872e-05 - accuracy - ETA: 17s - loss: 2.5249e-05 - a - ETA: 16s - loss: 2.4462e-05 - accuracy: 1.00 - ETA: 15s - loss: 2.6763e-05 - acc - ETA: 13s - loss: 4.4027e-04 - accuracy: 0.9999 - auc: 1 - ETA: 12s - loss: 4.3313 - ETA: 10s - loss: 3.8087e-04 - a - ETA: 9s - loss: 3.6332e-04 - accuracy: 0.9999 - auc: 1. - ETA: 9s - loss: 3.6133e-04 - accuracy: 0.9999 - ETA: 8s - loss: 3.5416e-04 - accuracy: 0.9999 - auc:  - ETA: 8s - loss: 3.5137e-04 - accuracy: 0.9999 - a - ETA: 8s - loss: 3.4683e - ETA: 7s - loss: 3.3455e-04  - ETA: 6s - loss: 3.2284e-04 - accuracy: 0.99 - ETA: 5s - loss: 3.168 - ETA: 2s - loss: 2.8313e-04 - ac - ETA: 1s - loss: 2.9380e-04 - accuracy: 0.9999 - auc - ETA: 1s - loss: 2.9153e-0\n",
      "Epoch 204/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 8.3915e-05 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7410 - val_accuracy: 0.4142 - val_auc: 0.6385 ETA: 25s - loss: 1.4283e-05 - accuracy: 1.0000 -  - ETA: 24s - loss: 1.3499e-05 - accuracy: 1.0000 - auc: - ETA: 24s - loss: 1.4332e-05 -  - ETA: 22s - loss: 1.3580e-05 - accuracy: 1.0000 - auc - ETA: 22s - loss: 1.5188e-05 - accuracy: 1.00 - ETA: 21s - loss: 1.5483e-05 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 1.5159e-05 - accuracy: 1.0000 - ETA: 20s - ETA: 16s - loss: 1.8079e-05 -  - ETA: 15s - loss: 1.7995e-05 - accu - ETA: 13s - loss: 1.8711e- - ETA: 11s - loss: 1.8189e-05 - accuracy: - ETA: 9s  - ETA: 8s - loss: 1.8346e-05  - ETA: 7s - loss: 1.9100e-05 - accuracy: 1.0000 - auc: 1. - ETA: 7s - loss: 1.9016e-05 - accuracy: 1.0000 - auc:  - ETA: 6s - loss: 1.8892e-05  - ETA: 5s - loss: 1.9201e-05 - accu - ETA: 5s - loss: 1.8778e-05 - accuracy: 1.0000 - auc - ETA: 2s - loss: 1.8288e-05 - accuracy: 1.0000 - - ETA: 2s - l - ETA: 1s - loss: 8.5238e-05 - accuracy: 0.9999 - ETA: 0s - loss: 8.5303e-05 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 8.5137e-05 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 8.5013e-05 - accuracy: 0.99\n",
      "Epoch 205/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 1.3678e-04 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8120 - val_accuracy: 0.4203 - val_auc: 0.6352-05 - accuracy: 1.0000 - auc: 1. - ETA: 28s - loss: 1.5801e-05 - accuracy: 1 - ETA: 27s - loss: 1.4881e- - ETA: 25s - loss: 2.2162e-04 - accuracy: 1.000 - ETA: 24s - loss: 1.9389e-04 - accuracy: 1.0000 - au - ETA: 23s - loss: 2.0740e-04 - accuracy: 1.0000  - ETA: 23s - loss: 1.8941e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 1.8812e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 22s - loss: 1.8554e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 22s - loss: 1.8304e-04 - accuracy: 1.0000 - auc:  - ETA: 22s - loss: 1.7593e-04 - accuracy: 1.0000 -  - ETA: 21s - loss: 1.6820e-04 - - ETA: 19s - loss: 1.4513e-0 - ETA: 17s - loss: 1.2481e-04 - accuracy: 1.0000 - auc - ETA: 17s - loss: 1.2902e-04 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 1.2700e-04 - ac - ETA: 14s - loss: 1.4998e-04 - accuracy: 1.0000 - auc:  - ETA: 14s - loss: 1.4695e-04 - accuracy: 1.0000 - ETA: 13s - loss: 1.4003e-04 - accuracy: 1.0 - ETA: 12s - loss: - ETA: 7s - - ETA: 6s - loss: 1.5770e-04 - accuracy: 1.0000 - auc: 1.00 - ETA: 5s - loss: 1.5738e-04 - accuracy: 1.0000 - - ETA: 5s - loss: 1.5519e-04  - ETA: 0s - loss: 1.3886e-04 - accuracy: 1.0000 - a - ETA: 0s - loss: 1.3762e-04 - accuracy: 1.0000 - auc\n",
      "Epoch 206/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.7667e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6381 - val_accuracy: 0.4100 - val_auc: 0.6397s - loss: 4.2738e-05 - accuracy: 1.0000 -  - ETA: 29s - loss: 2.4666e-05 - accuracy: 1.0000 - auc:  - ETA: 29s - loss: 2.0326e-05 - accuracy: 1 - ETA: 28s - l - ETA: 25s - ETA: 21s - loss: 2.7244e-05 - accuracy: 1 - ETA: 20s - loss: 3.9925e-05 - accuracy: 1.0 - ETA: 19s - loss:  - ETA: 16s - loss: 3.1796e-05 - accuracy: 1.0000  - ETA: 15s - loss: 3.1784e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 15s - loss: 3.1547e-05 - accuracy: 1.0000 - - ETA: 14s - loss: 3.0473e-05 - accuracy: 1 - ETA: 13s - loss: 2.8923e-05 - accuracy:  - ETA: 12s - loss: 2.7960e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 12s - loss: 2.7884e-05 - accuracy: 1. - ETA: 10s - loss: 2.7805e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 2.7586e-05 - accuracy: 1.0000 - auc: 1 - ETA: 8s - loss: 2.6404e-05 - accuracy: 1.00 - ETA: 7s - loss: 2.5857e-05 - accuracy: 1.0000 - auc - ETA: 7s - loss: - ETA: 5s - loss: 2.451 - ETA:  - ETA: 1s - loss: 2.8061e-0\n",
      "Epoch 207/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.7037e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6776 - val_accuracy: 0.4130 - val_auc: 0.63882e-05 - accuracy: 1.0000 -  - ETA: 28s - loss: 1.3549e-05 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 1.2284e-05 - accuracy - ETA: 27s - loss: 1.2687e-05 - accuracy: 1.0000 - auc:  - ETA: 26s - loss: 1.2114e-05 - accuracy - ETA: 25s - loss: 1.1458e- - ETA: 23s - loss: 1.5169e- - ETA: 21s - loss: 1.4230e-05 - accuracy: - ETA: 11s - loss: 1.7886e-05 - accuracy: 1.0000  - ETA: 10s - loss: 1.7603e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 10s - loss: 1.7536e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 10s - loss: 1.7441e-05 - accuracy: 1.0000 - ETA: 9s - loss: 1.7921e-05 - accuracy: 1. - ETA: 9s - loss: 1.7664e-05 - accuracy: 1.0000 - auc: 1. - ETA: 9s - loss: 1.7 - ETA: 7s - loss: 1.8220e-05 - accuracy: 1.0000 - a - ETA: 7s - loss: 1.8116e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 7s - loss: 1.8152e-05 - accuracy - ETA: 6s - loss: 1.7803e-05 - accuracy: 1.0000 - a - ETA: 6s - loss: 1.7712e-05 - accuracy: 1.0000 - a - ETA: 6s - loss: 1.7522e-05 - accu - ETA: 5s - loss: 1.7060e-05 - accuracy: 1.0000 - a - ETA: 5s - loss: 1.6963e-05 - accu - ETA: 4s - loss: 1.6518e-05 - accuracy: 1.0000 - auc - ETA: 3s - loss: 1 - ETA:  - ETA: 0s - loss: 1.6652e-05 - accuracy\n",
      "Epoch 208/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 4.5940e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6666 - val_accuracy: 0.4153 - val_auc: 0.6373ss: 1.1683e-05 - accuracy: 1.0000 - auc: 1 - ETA: 30s - loss: 1.3369e-05 - accuracy: 1.0000 - au - ETA: 29s - l - ETA: 26s - loss: 1.3281e-04 - accuracy: 1 - ETA: 25s - loss: 1.0873e-04 - accuracy: 1.0000 -  - ETA: 24s - loss: 9.9142e-05 - accuracy: 1.0000 - auc: - ETA: 24s - loss: 9.4203e-05 - accuracy: 1.0000 - auc: - ETA: 23s - loss: 8.9302e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 8.8621e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - - ETA: 20s - loss: 7.7 - ETA: 17s - loss: 6.4428e-05 - accuracy: 1.000 - ETA: 17s - loss: 6.2015e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 16s - loss: 6.3271e-05 - accuracy: 1.000 - ETA: 16s - loss: 6.0554e-05 - accuracy: 1.0000 - auc: - ETA: 11s - loss: 5.5469e-05 - accurac - ETA: 10s - loss: 5.8336e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 10s - loss: 5.9279e-05 - accuracy: 1.0000 - auc: 1. - ETA: 9s - loss: 5.8927e-05 - accuracy: 1.0000 - a - ETA: 9s - loss: 5.8290e-05 - accuracy: 1.0000 - ETA: 9s - ETA: 1s - loss: 4.7130e-05 - accura - ETA: 0s - loss: 4.6045e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 4.6000e-05 - accuracy: 1.0000 - a\n",
      "Epoch 209/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 2.5016e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7434 - val_accuracy: 0.4111 - val_auc: 0.636730s - loss: 4.5006e-06 - accuracy: 1.0000 - ETA: 29s - loss: 2.1208e-05 - accuracy: 1.0000 - auc: 1 - ETA: 29s - loss: 1.8757e-05 - accuracy: 1.0000 - ETA: 28s - loss: 1.9831e-05 - accuracy: 1.0000 - auc: 1. - ETA: 28s - loss: 1.9091e-05 - accura - ETA: 26s - loss: 0.0014 - accuracy: 0.9996 - auc: 1. - ETA: 26s - loss: 0.0013 - accuracy: 0.9996 - auc: 1.0 - ETA: 26s - loss: 0.001 - ETA: 24s - loss: 8.9514e-04 - accuracy: 0.99 - ETA: 22s - loss: 7.8166e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 22s - loss: 7.5969e-04 - accuracy: 0.9998 - auc: 1.000 - ETA: 22s - loss: 7.5438e-04 - accuracy: 0.9998 -  - ETA: 21s - loss: 6.9636e-04 - - ETA: 20s - loss: 5.8291e-04 - accura - ETA: 18s - loss: 5.1796e-04 - accuracy: 0.9999 - auc: 1. - ETA: 18s - loss: 5.0839e-04 - accuracy: 0.9999 - auc: 1.000 - ETA: 18s - loss: 5.0605e-04 - accuracy:  - ETA: 17s - loss: 4.6417e-04 - accuracy: 0.9999 - ETA: 12s - loss: 3.5074e-04 - accuracy: 0.9999 - auc: 1. - ETA: 12s - loss: 3.4707e-04 - accuracy:  - ETA: 10s - loss: 3.2717e - ETA: 9s - loss: 3.0542e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 9s - loss: 3.0461e-04 -  - ETA: 8s - loss: - ETA: 6s - loss: 2.7605e-04 - accu - ETA: 1s\n",
      "Epoch 210/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 5.0918e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7365 - val_accuracy: 0.4119 - val_auc: 0.633005 - accuracy: 1.0000 - auc: 1.000 - ETA: 26s - loss: 2.8435e-05 - accuracy: 1.0000 - auc: 1 - ETA: 26s - loss: 2.6787e-05 - accuracy: 1.0000 - auc: 1. - ETA: 26s - loss: 2.5548e-05 - accuracy: 1.000 - ETA: 25s - loss - ETA: 22s - loss: 2.5295e-05 - accuracy: 1.0000 - auc: 1. - ETA: 22s - loss: 2.5056e-05 - accuracy: 1.0000 -  - ETA: 21s - loss: 2.8807e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 2.8315e-05 - accuracy: 1.0000 - auc - ETA: 20s - loss: 2.7308e-05 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 2.6607e-05 - accuracy: 1.00 - ETA: 19s - loss: 2.5487e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s - loss: 2.5865e-05 - accuracy: 1.0000 - auc: 1. - ETA: 19s - loss: 2.5509e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 19s -  - ETA: 12s - loss: 5.361 - ETA: 9s - loss: 4.9625e-05 - accuracy: 1.0000 - auc - ETA: 9s - loss: 4.9068e-05 - accuracy: 1.0000 - a - ETA: 9s - loss: 4.8463e-05 - accuracy: 1.00 - ETA: 8s - loss: 4.7461e-05 - accu - ETA: 7s - loss: 4.6081e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 7s - loss: 4.5964e-05 - accuracy:  - ETA: 7s - loss: 4.5040e-05 - accura - ETA: 6s - loss: 4.5270e-0 - ETA: 5s - loss: 5.046\n",
      "Epoch 211/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 2.7518e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7077 - val_accuracy: 0.4061 - val_auc: 0.6294 - accuracy: 1. - ETA: 28s - loss: 2.3765e-05 - accuracy: 1.000 - ETA: 27s - loss: 3.0584e-05 - accuracy: 1.0000 - auc: 1  - ETA: 24s - loss: 2.1272e-05 - accuracy: 1.0000 - auc: 1 - ETA: 23s - loss: 2.0605e-05 - accuracy: 1.0 - ETA: 22s - loss: 7.6648e-04 - accuracy: 0.9996 - auc: 1.0 - ETA: 21s - loss: 7.5287e-04 - accuracy: 0.9996 - - ETA: 16s - loss: 5 - ETA: 7s - loss: 3.342 - ETA: 6s - loss: 3.2532e-04 -  - ETA: 1s - loss: 2.7200e-04 - accuracy: 0. - ETA: 0s - loss: 2.7956e-04 - accuracy: 0.99 - ETA: 0s - loss: 2.7536e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 212/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.0417e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6805 - val_accuracy: 0.4077 - val_auc: 0.63110s - loss: 2.6731e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 2.3755e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 30s - loss: 2.2895e-05 - accuracy: - ETA: 28s - loss: 1.5832e-04 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 1.4576e-04 - accurac - ETA: 26s - loss: 1.0030e-04 - accuracy: 1. - ETA: 25s - loss: 8.0773e-05 - accuracy: 1.0000 - auc: 1.000 - ETA:  - ETA: 21s - loss: 5.3124e-05 - accuracy: 1.0000 - auc: 1. - ETA: 21s - loss: 5.2353e-05 - accuracy: 1.0000 - ETA: 20s - loss: 4.8321e-05 - accuracy: 1.0000 - auc: 1. - ETA: 20s - loss: 4.7338e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 20s - loss: 4.7254e-05 - accur - ETA: 19s - loss: 4.1787e-05 - accuracy: 1.000 - ETA: 18s - loss: 3.9655e - ETA: 15s - loss: 4.9625e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 15s - loss: 4.9466e-05 - accuracy: 1. - ETA: 14s - loss: 5.0447e-05 - accuracy: 1.0000  - ETA: 13s - loss: 4.8133e-05 - accuracy: 1.0000 - auc: - ETA: 13s - loss: 4.7047e-05 - accuracy: 1.0000 - auc: 1. - ETA: 13s - loss: 4.6454e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 13s - loss: 4.6313e-05 - accuracy: 1.0000 - auc: 1 - ETA: 12s - loss: 4.5615e-05 - accuracy: 1.0000 - - ETA: 0s - loss: 3.8909e-05 - accuracy: 1.00 - ETA: 0s - loss: 4.0043e-05 - accuracy: 1.0000 -\n",
      "Epoch 213/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.7833e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7141 - val_accuracy: 0.4065 - val_auc: 0.6308.  - ETA: 22s - loss: 3.5658e-04 - acc - ETA: 20s - loss: 3.0278e-04 - accuracy: - ETA: 19s - loss: 2.8124e-04 - accuracy: 0.9998  - ETA: 18s - loss: 2.6 - ETA: 15s - loss: 2.2175e-04 - a - ETA: 14s - loss: 2.8670e-04 - accuracy: - ETA: 12s - loss: 2.6741e-04 - accuracy: 0.9998  - ETA: 12s - loss: 2.5601e-04 - accu - ETA: 10s - loss: 2.3663e-0 - ETA: 9s - loss: 2.2596e-04 - accuracy: 0.9998 - auc:  - ETA: 8s - - ETA: 7s - loss: 2.2779e-04  - ETA: 6s - l - ETA:  - ETA: 3s - loss: 1.9608e-04 - accuracy: 0.9999 - a - ETA: 2s - los - ETA: 1s - loss: 1.8507e-04 - accuracy: 0.9999 - ETA: 0s - loss: 1.8287e-04 - ac\n",
      "Epoch 214/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 3.2528e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6824 - val_accuracy: 0.4069 - val_auc: 0.6331A: 19s - loss: 7.2356e-05 - accuracy: 1.0000 - a - ETA: 18s - loss: 6 - ETA: 16s - loss: 5.8179e-05 - accuracy: 1.0000 -  - ETA: 15s - loss: 5.6614e-05 - accuracy: 1.0000 -  - ETA: 14s - loss: 5.4474e-05 - accuracy: 1.0000 - auc: 1. - ETA: 14s - loss: 5.3754e-05 - accuracy: 1.0000 - auc - ETA: 13s  - ETA: 4s - loss: - ETA: 2s - loss: 3.4869e-05 - accuracy: 1.0000 - ETA: 2s - loss: 3.4452e-05 - accuracy: 1. - ETA: 1s - loss: 3.4055e - ETA: 0s - loss: 3.2993e-05 - accuracy: 1.0000 - auc: 1. - ETA: 0s - loss: 3.2874e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 0s - loss: 3.2859e-05 - accuracy: 1.0000 - a\n",
      "Epoch 215/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.9132e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.9592 - val_accuracy: 0.4134 - val_auc: 0.6257- ETA: 21s - loss: 4.4982e-05 - accuracy: 1.0000  - ETA: 20s - loss: 4.54 - ETA: 17s - l - ETA: 14s - loss: 3.4723e-05 - accuracy: 1.0000 - auc: 1. - ETA: 14s - loss: 3.4226e- - ETA: 12s - loss: 3.1125e-05 - acc - ETA - ETA: 4s - loss: 3.8772e-05 - accuracy: 1.0000 - auc: 1. - ETA: 4s - loss: 3.8603e-0 - ETA: 3s - loss: 4.281\n",
      "Epoch 216/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 1.4082e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7795 - val_accuracy: 0.4073 - val_auc: 0.62902.8380e-04 - accuracy: 0.9998  - ETA: 19s - loss: 2.6892e-04 - accuracy: 0.9 - ETA: 18s - loss: 2.5090e-04 - - ETA: 2s - loss: 1.4047e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 2s - loss: 1.4019e-04 - accu - ETA: 2s - loss: 1.3725e - ETA: 0s - loss: 1.4312e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 0s - loss: 1.4284e-04 - accuracy: 0.9999 - - ETA: 0s - loss: 1.4281e-04 - accuracy: 0.99\n",
      "Epoch 217/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 2.6639e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.7460 - val_accuracy: 0.4061 - val_auc: 0.6302ccurac - ETA: 27s - loss: 1.2173e-05 -  - ETA: 25s - loss: 1.3006e-05 - accuracy: 1.00 - ETA: 24s - loss: 2.2014e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 24s - loss: 2.1525e-05 - acc - ETA: 22s - loss: 1 - ETA: 19s - loss: 1.9201e-05 - accuracy: 1.0000 - - ETA: 18s - loss: 1.8195e-05 - accuracy: 1.0000 - a - ETA: 14s - loss: 1.9993e-05 - accuracy: 1.0000 -  - ETA: 13s - loss: 1.9628e-05 - ac - ETA: 11s - loss: 2.1039e-05 - accuracy: 1.0000 - auc: - ETA: 10s - loss: 3.9960e-04 - accurac - ETA: 9s - loss: 3.7734e-04 - accuracy:  - ETA: 5s - loss: 3.153 - ETA: 4s - loss: 3.003 - ETA: 2s - loss: 2.8876e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 2s - loss: 2.8820e-04 - accuracy: 0.9999 - a - ETA: 2s - loss: 2.8527e-04 - accuracy: 0.9999 - a -\n",
      "Epoch 218/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 1.1027e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.6329 - val_accuracy: 0.4054 - val_auc: 0.6302 30s - loss: 2.0298e-05 - accuracy: 1.0000 - auc - ETA: 29s - loss: 1.3438e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 29s - loss: 1.2778e-05 - accuracy: 1.0000 - auc: 1. - ETA: 29s - loss: 1.7630e-05 - accuracy: 1.000 - ETA: 28s - loss: 2.0495e-05 - accuracy: 1.0000 - ETA: 27s - loss: 2.9235e-05 - accuracy: 1.0000 - auc: 1. - ETA: 27s - loss: 4.4010e-04 - acc - ETA: 25s - loss: 2.8817e-04 - ac - ETA: 23s - loss: 2.1608e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 23 - ETA: 15s - loss: 1.2421e-04 - accuracy: 0.9999 - auc - ETA: 15s - loss: 1.2052e-04 - acc - ETA: 13s - loss: 1.0972e-04 - - ETA: 11s - loss: 1.0078e-04 - accurac - ETA: 9s - loss: 9.4461e-05 - accuracy: 0.9999 - au - ETA: 9s - loss: 9.3158e-05 - accuracy: 0.9999 - auc: 1. - ETA: 9s - loss: 9.2663e-05 - accuracy:  - ETA: 8s - - ETA: 7s - l - ETA: 5s - loss: 1.3156e - ETA: 2s - loss: 1.1756e-04 - ac - ETA: 1s - loss:\n",
      "Epoch 219/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.1832e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6987 - val_accuracy: 0.4057 - val_auc: 0.6291 - loss: 1.5224e-05 - accuracy: 1.0000 - auc:  - ETA: 29s - loss: 1.1361e-05 - accuracy:  - ETA: 28s - loss: 1.3151e-05 - accuracy: 1 - ETA: 27s - loss: 2.6418e-05 - accuracy: 1.0000 - a - ETA: 26s - loss: 2.3341e-05 - accuracy: 1.0000  - ETA: 25s - loss: 3.7498e-05 - accuracy: 1.0000  - ETA: 24s - loss: 3.3735e-05 - ETA: 18s - loss: 2. - ETA: 15s - l - ETA: 12s - loss: 2.1750e-05 - accura - ETA: 11s - loss: 2.1648e-05 - accuracy: 1.0000 - auc: 1. - ETA: 11s - loss: 2.1687e-05 - accuracy: 1.0000 - auc:  - ETA: 10s - loss: 2.1334e-05 - ETA: 9s - loss: 2.075 - ETA: 6s - loss: 2.2880e-0 - ETA: 5s - loss: 2.3470e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 5s - loss: 2.3417e - ETA: 3s - loss: 2.3211e-05 - accuracy - ETA: 3s - loss: 2.3184e-05 - accuracy: 1.0000 - a - ETA: 2s - loss: 2.2951e-05 - accu - ETA: 1s - loss: 2.2429e-05 - accuracy: 1.00 - ETA: 1s - loss: 2.2460e - ETA: 0s - loss: 2.1850e-05 - accuracy: 1.0000 - auc: 1.\n",
      "Epoch 220/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 8.4067e-05 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.6740 - val_accuracy: 0.4054 - val_auc: 0.62941s - loss: 4.9709e-05 - accuracy: 1.0000 - auc:  - ETA: 21s - loss: 4.8138e-05 - accurac - ETA: 19s - loss: 4.6890e-05 - accuracy: 1.0000 -  - ETA: 18s - loss: 4.4856e-05 - accuracy: - ETA: 17s - loss: 4.4 - ETA: 10s - loss: 4.4110e-05 - accuracy: 1.0000 -  - ETA: 10s - loss: 4.3089e-0 - ETA: 8s - loss: 4.3492e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 8s - loss: 4.3389e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 8s - loss: 4.3272e-05 - accuracy - ETA: 8s - loss: 1.0891e - ETA: 6s - loss: 1.0374e-04 - accuracy: 0.99 - ETA: 6s - loss: 1.0158e-04 - accuracy: 0.9999 - ETA: 3s - loss: 9.3629e-05 - accuracy: 0.9999 - a - ETA: 3s - loss: 9.2714e-05 - accuracy: 0.9999 - auc: 1.00 - - ETA: 1s - loss: 8.7889e-05 - accuracy: 0.99 - ETA: 1s - loss: 8.6643e-05 - accura - ETA: 0s - loss: 8.4941e-05 - accuracy: 0.9999 - - ETA: 0s - loss: 8.4006e-05 - accuracy: 0.9999 - auc: 1.00\n",
      "Epoch 221/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 3.4664e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.0163 - val_accuracy: 0.4057 - val_auc: 0.62125 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - loss: 4.6979e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 28s - loss: 4.5685e-05 - accuracy: 1.0000 - auc: 1. - ETA: 28s - loss: 4.0749e-05 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 3.7838e-05 - accuracy: 1.0000 - - ETA: 23s - loss: 7.0256e-05 - accuracy: - ETA: 21s - loss: 6.1687e-05 - accuracy: 1.0000 - auc: 1. - ETA: 21s - loss: 5.9786e-05 - accuracy: 1.0000 - auc:  - ETA: 21s - loss: 5.7499e-05 - accuracy: 1 - ETA: 19s - loss: 5.6517e-05 - accu\n",
      "Epoch 222/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.9420e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6989 - val_accuracy: 0.4057 - val_auc: 0.6263TA: 30s - loss: 2.4848e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 30s - loss: 1.7708e-05 - accuracy: 1.0000 - auc:  - ETA: 30s - loss: 3.1229e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 30s - loss: 2.8331e-05 - accurac - ETA: 29s - loss: 2.3911e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 2.2770e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 29s - loss: 2.152 - E - ETA: 22s - loss: 2.7672e-05 - accuracy: 1.0000 - auc:  - ETA: 21s - loss: 2.6724e-05 - accuracy: - ETA: 16s - loss: 2.0464e-05 - accuracy: 1.0000 -  - ETA: 15s - loss: 1.9891e-05 - ac - ETA: 13s - loss: 1.0304e-0 - ETA: 11s - loss: 9.6621e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 11s - loss: 9.5765e-05 - accuracy: 1.0 - ETA: 10s - loss: 9.2780e-05 - accuracy: 1.0000 - auc:  - ETA: 9s -\n",
      "Epoch 223/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 7.4094e-05 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.9880 - val_accuracy: 0.4088 - val_auc: 0.625130s - loss: 8.4662e-06 -  - ETA: 28s - loss: 5.0165e-05 - accur - ETA:  - ETA: 2s - loss: 8.0043e-05 - accuracy\n",
      "Epoch 224/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 2.5165e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6913 - val_accuracy: 0.4042 - val_auc: 0.6299c - ETA: 20s - loss: 2.9504e-05  - ETA: 17s - loss: 2.7433e-05 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 2.7100e-05 - accuracy: 1.0000 - auc: - ETA: 17s - loss: 2.6367e-05 - accuracy: 1.0000 - au - ETA: 16s  - ETA: 7s - loss: 2.766 - ETA: 6s - loss: 2.6616e-05  - ETA: 5s - loss: 2.7508e - E\n",
      "Epoch 225/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 1.2706e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.6539 - val_accuracy: 0.4008 - val_auc: 0.6270 - ETA: 21s - loss: 3.7390e-04 - accuracy: 0.9998 - a - ETA: 21s - - ETA: 17s - loss: 2.6933e-04 - accuracy: 0.9999 - auc: - ETA: 17s - loss: 2.6176e-04 - accu - ETA: 15s - loss - ETA: 12s - loss: 2.0111e-04  - ETA: 10s - loss: 1.8172e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 10s - loss: 1.8102e-04 - accuracy: 0.9999  - ETA: 9s - loss: 1.7665e-04 - accuracy: 0.9999 - auc: 1. - ETA: 7s - loss: 1.5968e-04 - ac - ETA: 0s - loss: 1.2901e-04 - accura\n",
      "Epoch 226/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 3.6908e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7506 - val_accuracy: 0.4000 - val_auc: 0.6265TA: 26s - loss: 1.6 - ETA: 2s - ETA: 1s - loss: 3.3653e-05 - ac\n",
      "Epoch 227/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 7.5528e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7165 - val_accuracy: 0.3996 - val_auc: 0.6255 - accur - ETA: 22s - loss: 1.4858e-04 - acc - ETA: 20s - loss: 1.4474e-04 - accur - ETA: 18s - loss: 1.4310e-04 - accuracy: 1.0000 - auc: - ETA: 18s - loss: 1.3845e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 18s - loss: 1.3781e-04 - accuracy: 1.0000 - - ETA: 17s - loss: 1.3237e-04 - accuracy: 1.0000 - auc: 1 - ETA: 17s - loss: 1.2959e-04 - accuracy: 1 - ETA: 16s - loss: 1.2019e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 16s - loss: 1.1971e-04 - accuracy: 1.000 - ETA: 15s - loss: 1.1311e-04 - accuracy: 1.0000 - au - ETA: 14s - loss: 1.0956e-04 - accuracy: 1 - ETA: 13s - loss: 1.0275e-04 - accuracy: 1.0000 - auc: 1 - ETA: 13s - loss: 1.0232e-04 - accuracy: 1.0000 - auc: - ETA: 12s -  - ETA: 9s - loss: 8.9048e-05 - accuracy: 1.0000 - auc: 1. - ETA: 9s - loss: 8.8555e-05 - accura - ETA: 8s - loss: 8.5392e-05 - accuracy: 1.0000 - - ETA: 8s - loss: 8.3 - ETA: 5s - loss: 7.7744e-05 - ac - ETA: 2s - loss: 8.0686e-05 - accuracy: 1.0000 - auc - ETA: 1s - loss: 8.0092e-05 - accuracy: 1.0000 - a - ETA: 1s - loss: 7.9288e-05 - accuracy - ETA: 1s - loss: 7.7731e-05 - accuracy: 1.0000 - auc - ETA: 0s - loss: 7.7235e-05 - accuracy - ETA: 0s - loss: 7.5565e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 228/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 4.3843e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7155 - val_accuracy: 0.4019 - val_auc: 0.62705 - accuracy - ETA: 16s - loss: 2.2410e-05 - accuracy: 1.0000 - auc: 1 - ETA: 16s - loss: 2.1956e-05 - accuracy: 1.0000 - ETA: 15s - loss: 2.1166e-05 - accuracy: 1.0000 - a - ETA: 14s - loss: 2.1126e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 14s - loss: 2.0944e-05 - ETA: 12s - loss: 2.2373e-05 - accuracy: 1.0000 - ETA: 8s - loss: 5.1491e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 8s - loss: 5.1373e-05 - accuracy: 1.0000 - - ETA: 8s - loss: 5.0762e-05 - accuracy: 1.0000 - - ETA: 7s - ETA: 4s - loss: 4.9417e-05 -  - ETA: 2s - loss: 4.7574e-05 - accuracy: 1.0000 - ETA: 2s - loss: 4.6912e-05 - accuracy: 1.00\n",
      "Epoch 229/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 1.3300e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.6043 - val_accuracy: 0.3985 - val_auc: 0.6180 ETA: 1\n",
      "Epoch 230/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.7381e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5667 - val_accuracy: 0.3989 - val_auc: 0.6210 loss: 7.3087e-05 - accuracy: 1.0000 - - ETA: 21s - loss: 7.4440e-05 - accuracy: - ETA: 19s - loss: 6.7133e-05 - accuracy: 1.0000 -  - ETA: 19s - loss - ETA: 16s - loss: 5.8706e-05 - accuracy: 1.0 - ETA: 15s - loss: 5.5394e-05 -  - ETA: 13s - loss: 5.8453e-05 - accuracy: 1.0000 - au - ETA: 12s - loss: 5.6650e - ETA: 10s - loss: 5.1078e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 10s - loss: 5.0720e-05  - ETA - ETA: 3s - loss: 4.0456e-05 - accuracy: 1.0000 - - ETA: 2s - loss: 4.0000e-05 - accuracy: 1.0000 - - E\n",
      "Epoch 231/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 3.9749e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5818 - val_accuracy: 0.3962 - val_auc: 0.6217: 21s - loss: 1.8010e-05 - accuracy: 1.0000 - au - ETA: 21s - loss: 2.5144e-05 - accuracy: 1.0000 - auc: 1 - ETA: 20s - loss: 2.4253e-05 -  - ETA: 18s - loss: 2.4739e-05 - accu - ETA: 17s - loss: 2.4373e-05 - accuracy: 1.0000 - a - ETA: 16s - loss: 2.4059e-05 - accu - ETA: 14s - loss: 3.1330e-05 - accuracy: 1.0000 - a - ETA: 14s - loss: 5.7476e-05 - accuracy: 1.0000 - a - ETA: 13s - loss: 5.6033e-05 - accuracy: 1.0000 - auc:  - ETA: 13s - loss: 5.4918e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 13s - loss: 5.4284e-05 - accuracy: 1.0000 - auc - ETA: 12s - loss: 5.3208e-05 - accuracy: 1.0000 - - ETA: 11s - loss: 5.1841e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 11s - loss: 5.1424e-05 - acc - ETA: 7s - loss: 4.6475e-05 - ac - ETA: 7s - loss: 4.5292e-05 - accuracy: 1.0000 - auc: 1. - ETA: 6s - loss: 4.5095e-05 - accuracy: 1.0000 - - ETA: 4s - loss: 4.2276e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 4s - loss: 4.2277e-05 - accuracy:  - ETA: 3s - loss: 4.1429e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 4.1343e-05 - accuracy: 1.0000 - a - ETA: 3s - loss: 4.0975e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 4.0887e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - l - ETA: 1s - los - ETA: 0s - loss: 3.9999e-05 - accuracy: 1.0000 -\n",
      "Epoch 232/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 3.8740e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5734 - val_accuracy: 0.3992 - val_auc: 0.6232 accuracy: 1.000 - ETA: 25s - loss: 1.2541e-05 - accuracy: 1.0000 - au - ETA: 25s - loss: 1.4630e-04 - accuracy: 1.0000 - au - ETA: 24s - loss: 1.3307e-04 - accuracy: 1.00 - ETA: 23s - loss: 1.1748e-04 - accuracy: 1.0000 - auc - ETA: 22s - loss:  - ETA: 20s - loss: 9.2030e-05 - a - ETA: 18s - loss: 8.0604e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 18s - loss: 8.0225e-05 - accurac - ETA: 17s - loss: 7.4670e-0 - ETA: 14s - loss: 6.6614e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 14s - loss: 6.5922e-05 - accuracy: 1.000 - ETA: 13s - loss: 6.3196e-05 - accuracy: 1.0000 - a - ETA: 13s - loss: 6.1177e-05 - accuracy - ETA: 11s - loss: 5.7480e-05 - accuracy: 1.0000 - auc: - ETA: 11s - loss: 5.6346e-05  - ETA: 9s - loss: 5.2543e-05 - accu - ETA: 8s - loss: 5.0672e-05 - accuracy: 1.0000 - - ETA: 8s - loss: 5.0132e - ETA: 7s - loss: 4.8360e-05 - accuracy: 1.0000 - - ETA: 6s - loss: 4.7552e-05 - accuracy: 1.0000 - ETA: 6s - loss: 4.6771e-05 - accuracy: 1.0000 - auc: 1. - ETA: 6s - loss: 4.6585e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 6s - loss: 4.6474e-05 - accuracy - ETA:  - ETA: 3s - loss: 4.3276e-05 - accuracy: 1.0000 - ETA: 3s - loss: 4.2739e-05 - accuracy: 1.0000 - auc:  - ETA: 3s - loss: 4.2474e-05 - accuracy: 1.0000 - a - ETA - ETA: 1s - loss: 4.0129e-05 - accuracy:  - ETA: 0s - loss: 3.9426e-05 - accuracy: 1.0000 - auc: 1. - ETA: 0s - loss: 3.9275e-05 - accuracy: 1.0000 - ETA: 0s - loss: 3.8764e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 233/250\n",
      "518/518 [==============================] - 32s 63ms/step - loss: 2.8797e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6035 - val_accuracy: 0.3977 - val_auc: 0.624000 - auc: 1.000 - ETA: 22s - loss: 2.0082e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 21s - loss: 1.9819e - ETA: 15s - loss: 1.7791e-05 - accuracy: 1.000 - ETA: 14s - loss: 1.6861e-05 - accurac - ETA: 13s - loss: 1.6914e-05 - accur - ETA: 11s - loss: 1.5874e-05 - accuracy: 1.0000 - auc: - ETA: 10s - loss: 1.5526e- - ETA: 3s - loss: 2.9110e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 3s - loss: 2.9196e-05 - accuracy: 1.0000 - auc - ETA: 2s - loss: 2.8985e-05 - accura - ETA: 2s - loss: 2.9 - ETA: 0s - loss: 2.9361e-05 \n",
      "Epoch 234/250\n",
      "518/518 [==============================] - 32s 62ms/step - loss: 2.8841e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8227 - val_accuracy: 0.4011 - val_auc: 0.62085s - loss: 1.9239e-05 - accuracy: 1.0000 - auc: 1 - ETA: 24s - loss: 1.9061e-05 - accuracy: 1.0000 - ETA: 23s - loss: 1.7170e-05 - accuracy: 1.0000  - ETA: 22s - loss: 1.8971e-05 - accuracy - ETA: 21s - loss: 2.0456e-05 - accuracy: 1.0000 - - ETA: 20s - loss: 1.9051e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 20s - loss: 1.8900e-05 - accuracy: 1. - ETA: 19s - loss: 1.8143e-05 - accuracy: 1.0 - ETA: 18s - loss: 1.6952e-05 - accuracy: 1.0000 - a - ETA: 17 - ETA: 14s - loss: 1.3998e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 1.3976e-05 - accuracy: - ETA: 12s - loss: 1.5240e-05 - accuracy: 1.0000 - auc - ETA: 12s - loss: 1.5080e-05 - accuracy: 1.00 - ETA: 11s - loss: 1.6212e-05 - accuracy: 1.00 - ETA: 10s - loss: 1.5697e-05 - acc - ETA: 9s - loss: 1.5690e-05 - accuracy: 1.00 - ETA: 8s - loss: 1.5482e-05 - accura - ETA: 7s - loss: - ETA: 6s - loss: 1.7010e-05 - accuracy: 1.0000 - auc - ETA: 6s - los - ETA: 0s - loss: 2.9153e-05 - accuracy: 1.0000 - - ETA: 0s - loss: 2.8856e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 235/250\n",
      "518/518 [==============================] - 32s 62ms/step - loss: 7.4536e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.5916 - val_accuracy: 0.4008 - val_auc: 0.6245- loss: 1.0769e-04 - accuracy: 1.0000  - ETA: 23s - loss: 9.5109e-05 - accuracy: 1.0000 - auc: - ETA: 23s - loss: 9.0731e-05 - accuracy: 1.0000 - auc - ETA: 22s - loss: 8.5853e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss: 8.5248e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 22s - loss: 8.4061e-05 - accuracy: 1.0000 - - ETA: 21s - loss: 7.7196e-05 - accuracy: - ETA: 20s - loss: 6.6352e-05 - accuracy: 1.0000 -  - ETA: 19s - loss: 6.52 - ETA: 17s - loss: 5.4894e-05 - accuracy: 1.0000 - au - ETA: 16s - loss: 5.3080e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 16s - loss: 5.2940e-05 - accuracy: 1.0000  - ETA: 15s - loss: 5.0369e-05 - accuracy: 1.0000 - ETA: 14s - loss: 4.9046e-05 - accuracy: 1.0000 -  - ETA: 13s - loss: 4.7148e-05 - accuracy: 1.0000 - a - ETA: 13s - loss: 4.6508e-05 - accu - ETA: 8s - loss: 5.6949e-05 - accura - ETA: 7s - l - ETA: 4s - loss: 8.3869e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 4s - loss: - ETA: 2s - loss: 8.1074e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 2s - loss: 8.0920e-05 - accuracy: 1.0000 - auc - ETA: 2s - loss: 8.0275e-05 - ac - ETA: 1s - loss: 7.8104e-05 -  - ETA: 0s - loss: 7.5849e-05 - accuracy: 1.\n",
      "Epoch 236/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 3.4002e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6314 - val_accuracy: 0.4000 - val_auc: 0.6247A: 29s - loss: 1.7119e-05 - accuracy: 1.0000 - au - ETA: 29s - loss: 3.2649e-05 - accuracy: - ETA: 28s - loss: 2.3141e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 28s - loss: 2.2606e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 28s - los - ETA: 25s - loss: 4.1320e-05 - accuracy: 1 - ETA: 23s - loss: 3.5642e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 23s - loss: 3.5343e- - ETA: 17s - loss: 3.6305e-05 - accuracy: 1.0000 - auc: 1. - ETA: 17s - loss: 3.5748e-05 - accuracy: 1.0000 - auc: 1. - ETA: 17s - loss: 3.5241e-05 - accuracy: 1.0000  - ETA: 16s - loss: 3.4775e-05 - accuracy: 1.0000 - - ETA: 15s - loss: 3.3808 - ETA: 13s - loss: 3.1450e-05 - accuracy:  - ETA: 12s - loss: 3.0749e-05 - accuracy: 1.0000 - auc: - ETA: 11s - loss: 3.0125e-05 - accuracy: 1.0000 - auc - ETA: - ETA: 8s - loss: 2.7725e-05 - accuracy: 1.0000 - ETA: 8s - loss: 2.7331e-05 - accuracy: 1.0000 - a - ETA: 6s - loss: 2.5272e-05 - accu - ETA: 1s - loss: 3.3037e-05 - accuracy: 1.0000 - ETA: 1s - loss: 3.2583e\n",
      "Epoch 237/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 5.4037e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6430 - val_accuracy: 0.4004 - val_auc: 0.6241 - loss: 1.5371e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 31s - loss: 1.4687e-05 - accuracy: 1.0000 - au - ETA: 30s - loss: 1.1292e-05 - accuracy: 1.0000 - ETA: 29s - loss: 8.711 - ETA: 22s - loss: 1.2473e-04 - accuracy: 1.0000 - auc: 1.000 - ETA: 22s - loss:  - ETA: 19s - loss: 1.0699e-04 - accuracy: 1.0000 - - ETA: 18s - loss: 1.0370e-04 - accuracy: 1.0000 - - ETA: 17s - loss: 9.7689e-05 - accuracy: 1.0000 - a - ETA: 17s - loss: 9.9692e-05 - ETA: 14s - loss: 9.0399e-05 - accuracy: 1.0000 - auc: 1 - - ETA: 0s - loss: 5.3599e-05 - accuracy: 1.\n",
      "Epoch 238/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 6.0766e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6071 - val_accuracy: 0.4019 - val_auc: 0.6242curacy: 1.0000 - - ETA: 28s - loss: 1.9290e-05 - accuracy: 1.0000 - auc: 1 - ETA: 28s - loss: 2.0513e-05 - accuracy: 1.0000 - auc - ETA: 28s - loss: 1.8038e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 27s - loss: 1.7589e-05 - accuracy: 1.0000 - a - ETA: 27s - loss: 2.2 - ETA: 20s - loss: 5.4696e-05 - accuracy: 1.0000 - ETA: 19s - loss: 7.0603e-05 - accu - ETA: 13s - loss: 9.0473e-05 - accuracy: 1.0000 - auc: 1 - ETA: 12s - loss: 8.9019e-05 - accuracy: 1.0000 - auc - ETA: 12s - loss: 8.6987e-05 - accuracy: 1.0000  - ETA: 11s - loss: 8.3492e-05 - accuracy: 1.0000 - auc: - ETA: 10s - loss: 8.1860e-05 - accuracy: 1.0000 - auc -  - ETA: 8s - loss: 7.3150e-05 - accuracy: 1.00 - ETA: 7s - l - ETA: 6s - loss: 6.8060e-05 - accuracy: 1.0000 - ETA: 3s - loss: 6.2931e-05 - accuracy - ETA: 1s - loss: 6.226\n",
      "Epoch 239/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 5.6937e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6952 - val_accuracy: 0.3996 - val_auc: 0.6242loss: 4.5956e-05 - accuracy: 1.0000 - - ETA: 24s - loss: 4.1085e-05 - accuracy: 1.0000 - - ETA: 23s - loss: 3.7344e-05 - accur - ETA: 21s - loss: 4.2018e-05 - accuracy: 1.0000 - auc: 1 - ETA: 21s - loss: 4.0733e-05 - accuracy: 1 - ETA: 20s - loss: 3.7712e-05 - accuracy: 1.0000 - auc: - ETA: 19s - loss: 3.6395e-05 - accuracy: 1.0000 -  - ETA: 19s - loss: 3.7694 - ETA: 16s - loss: 3.3316e-05 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 3.2933e-05 - accuracy: 1.0000 - auc: 1. - ETA: 16s - loss: 3.2289e-05 - accuracy - ETA - ETA: 11s - - ETA: 5s - loss: 6.4637e-05 - accuracy: 1.0000 - auc:  - ETA: 4s - loss: 6.5183e-05 - accuracy: 1.0000 - auc - ETA: 4s - loss: 6.4612e-05 - accuracy: 1.0000 - ETA: 4s - loss: 6.3 - ETA: 2s - - ETA: 1s - loss: 5.8646e-05 - accuracy: 1.0000 - a - ETA: 0s - loss: 5.8081e-05 - accuracy: 1.0000 - auc - ETA: 0s - loss: 5.7631e-05 - accuracy: 1.00\n",
      "Epoch 240/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 4.8844e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.6870 - val_accuracy: 0.4015 - val_auc: 0.62584.1294e-05 - accuracy: 1.0000  - ETA: 26s - loss: 3.6042e-05 - accuracy: 1.0000 - a - ETA: 25s - loss: 3.8761 - ETA: 23s - loss: 2.9852e-05 - accuracy: 1.0000 - auc:  - ETA: 23s - loss: 2.8762 - ETA: 21s - loss: 3.3868e-05 - accuracy: 1.0000 - ETA: 20s - loss: 3.4292e-05 - accuracy: 1.0000 - auc: - ETA: 19s - loss: 3.3525e-05 - accuracy: 1. - ETA: 18s - loss - ETA: 12s - loss: 7.3257e-05 - accuracy: 1.0000  - ETA: 11s - loss: 7.1005e-05 - accuracy: 1.0000 - auc: 1. - ETA: 11 - ETA: 8s - loss: 6.3912e-05 -  - ETA: 7s - loss: 6.1507e-05 - accuracy - ETA: 6s - loss: 6.0398e-05  - ETA: 6s - loss: 5.8499e-05 - accuracy: 1.0000 - ETA: 1s - loss:\n",
      "Epoch 241/250\n",
      "518/518 [==============================] - 34s 65ms/step - loss: 4.0471e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7566 - val_accuracy: 0.3969 - val_auc: 0.6258TA: 30s - loss: 1.4208e-05 - accuracy: 1. - ETA: 28s - loss: 9.6435e-06 - accuracy: 1.0000 - auc: 1.0 - ETA: 28s - loss: 9.7014e-06 - accuracy: 1. - ETA: 27s - loss: 1.1495e-05 - accuracy: 1.0000 - auc: 1. - ETA: 27s - loss: 1.0894e-05 - accuracy: 1.0000 - auc: 1 - ETA: 26s - loss: 1 - ETA: 24s - loss: 9.9282e-06 - accuracy: 1.0000 - auc: 1. - ETA: 23s - loss - ETA: 21s - loss: 1.0957e-05 - ETA: 2s - loss: 4.3306e-05 - accuracy: \n",
      "Epoch 242/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 3.4903e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7179 - val_accuracy: 0.3989 - val_auc: 0.6235e-05 - accuracy:  - ETA: 15s - loss: 4.9255e-05 - accuracy: 1.0000 - auc: 1. - ETA: 15s - loss: 4.8570e-05 - accuracy: 1.0000 - au - ETA: 14s - loss: 4.6962e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 4.6795e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 14s - loss: 4.6481e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 4.6325e-05 - accuracy: 1.0000 - au - ETA: 13s - loss: 4.5138e-05 - accuracy - ETA: 12s - loss: 4.2184e-05 - accuracy:  - ETA: 11s - loss - ETA: 0s - loss: 3.5719e-05 \n",
      "Epoch 243/250\n",
      "518/518 [==============================] - 34s 65ms/step - loss: 1.5605e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7801 - val_accuracy: 0.3958 - val_auc: 0.6238A: 29s - loss: 1.0425e-05 - accur - ETA: - ETA: 7s - loss: 1.4571e-05 - accuracy: 1.0000 - auc: 1. - ETA: 7s - loss: 1.4\n",
      "Epoch 244/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 2.1094e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.9108 - val_accuracy: 0.3996 - val_auc: 0.6220\n",
      "Epoch 245/250\n",
      "518/518 [==============================] - 33s 63ms/step - loss: 4.4045e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 6.0195 - val_accuracy: 0.4000 - val_auc: 0.6218: 12s - loss: 5.8575e-05 - accuracy: 1.0000 - auc:  - ETA: 12s - loss: 5.7524e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 12s - loss: 5.7351e-05 - accuracy: 1.0000  - ETA: 11s - loss: 5.5238e-05 - accuracy: 1.0000 - auc: 1.0 - ETA: 11s - loss: 5.4748e-05 - accurac - ETA: 9s - loss: 5.1293e-05 - accuracy: 1.0000 - auc:  - ETA: 9s - ETA: 8s - loss: 5.4358e-05 - accuracy: 1.0000 - - ETA: 7s - los - ETA: 3s - loss: 4.8340e-0 - ETA: 0s - loss: 4.4466e-05 - accuracy: 1.0000 - a - ETA: 0s - loss: 4.4120e-05 - accuracy: 1.0000\n",
      "Epoch 246/250\n",
      "518/518 [==============================] - 32s 62ms/step - loss: 5.5061e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7976 - val_accuracy: 0.3996 - val_auc: 0.62239s - loss: 4.8077e-06 - accuracy: 1.0000 - auc: 1 - ETA: 29s - loss: 4.2368e-06 - accuracy: 1.0000 - ETA: 28s - loss: 4.3119e-06 - accuracy: 1.0000 - auc:  - ETA: 28s - loss: 4.0371e-06 - accuracy: 1.0000 - auc - ETA: 27s - loss: 9.5439e-06 - accuracy: 1.0000 - au - ETA: 26s - loss: 9.6821e-06 - accuracy: - ETA: 25s - loss: 1.0491e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 25s - loss: 1.0382e-05 - accuracy - ETA: 24s - loss: 4.0012e-05 - accura - ETA: 22s - loss: 3.4198e-05 - accuracy: 1.0000 - auc: - ETA: 22s - loss - ETA: 19s - loss: 3.3 - ETA: 16s - loss: 3.3489e-05 - accuracy: 1.0000 - a - ETA: 16s - loss: 3.2578e-05 - accuracy: 1.0000  - ETA: 15s - loss: 3.1004e-05 - accuracy: 1.0000 - a - ETA: 14s - \n",
      "Epoch 247/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 1.8689e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8114 - val_accuracy: 0.3973 - val_auc: 0.6232- lo - ETA: 16s - loss: 1.5938e-05 - accuracy: 1.0000 - auc: 1 - ETA: 16s - loss: 1.5706e-05 - accuracy: 1.0000 - auc: 1.00 - ETA: 16s - loss: 1.5676e-05 - accurac - ETA: 15s - loss: 1.4612e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 14s - loss: 1.5096e-05 - accu - - - ETA: 5s - loss: 2.0303e-05 - accuracy: 1.0000 - a - ETA: 5s - loss: - ETA: 2s - loss: 1.9598e-05 - accuracy:  - ETA: 1s - loss:\n",
      "Epoch 248/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/518 [==============================] - 33s 63ms/step - loss: 1.9441e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.7933 - val_accuracy: 0.4008 - val_auc: 0.6225: 26s - loss: 5.8238e-05 - accuracy: 1. - ETA: 25s - loss: 4.8423e-05 - accuracy: 1.0000  - ETA: 24s - loss: 4.2985e-0 - ETA: 22s - loss: 3.3866e-05 - accuracy: - ETA: 21s - loss: 3.7292e-05 - accuracy: 1.0000 - - ETA: 20s - loss: 3.5203e-05 - a - ETA: 18s - loss: 3.1870e-05 - accuracy - ETA: 16s - loss: 3.0847e-05 - accuracy: 1.0000 - auc: 1.000 - ETA: 16s - loss: 3.0716e-05 - acc - E - ETA: 11s - loss: 2.4845e-05 - accuracy: 1.0000 - a - ETA: 10s - los - ETA: 8s - loss: 2 - ETA: 1s - loss: 1.959 - ETA: 0s - loss: 1.9697e-05 - accuracy: 1.0000\n",
      "Epoch 249/250\n",
      "518/518 [==============================] - 34s 65ms/step - loss: 6.2092e-05 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 5.8903 - val_accuracy: 0.3973 - val_auc: 0.62195 - accuracy: 1.0 - ETA: 27s - loss: 7.0252e-05 - accuracy: 1.0000  - ETA: 26s - loss: 5.8918e-05 - accuracy: 1.0000 - auc:  - ETA: 26s - loss: 5.53 - ETA: 23s - loss: 4.5810e-05 - accurac - - ETA: 18s - loss: 1.0790e-04 - accuracy: 1 - ETA: 17s - loss: 1.1952e-04 - accuracy: 1.00 - ET - ETA: 12s - ETA: 7s - loss: 7.7509e-05 - accuracy: 1.0000 - ETA: 7s - l - ETA: 1s - loss: 6.4 - ETA: 0s - loss: 6.3177e-05 - accuracy: \n",
      "Epoch 250/250\n",
      "518/518 [==============================] - 33s 64ms/step - loss: 4.1296e-04 - accuracy: 0.9999 - auc: 1.0000 - val_loss: 5.8290 - val_accuracy: 0.3973 - val_auc: 0.6242TA: 27s - loss: 2 -  - ETA: 16s - loss: 7.1797e-04 - accuracy: 0.9997 - auc: 1.000 - ETA: 16s - loss: 7.1507e-04 - accuracy - ETA: 15s - loss: 6.5523e-04 - accuracy: 0.9998 - au - ETA: 14s - loss: 6.3424e-04 - accuracy: 0.99 - ETA: 13s - loss: 6.0883e-04 - accuracy: 0.9998 - auc: 1.0 - ETA: 13s - loss: 6.0271e-04 - accuracy: 0.9998 - auc:  - ETA: 13s - loss: 6.5485e-04 - accuracy: 0.99 - ETA: 12s - loss: 6.2741e-04 - accuracy: 0. - ETA: 11s - loss: 5.9220e-04 - accuracy: 0.9998 - auc - ETA: 10s - loss: 5.7995e-04 - accur - ETA: 9s - loss: 5.5143e-04 - accuracy: 0.9998 - auc: 1.00 - ETA: 9s - loss: 5.4992e-04 -  - ETA: 8s - loss: 5.3741e-04 - ac - ETA: 7s - loss: 5.1 - ETA: 6s - loss: 5.0022e-04 - ac - ETA: 5s - loss: 4.8433e-04 - accuracy: 0.9999 - auc: 1.00 - ETA: 5s - loss: - ETA: 4s - loss: 4.5890e-0 - ETA: 3s - loss: 4.4356e-04 -  - ETA: 0s - loss: 4.1481e-04 - accuracy: 0.9999 - auc: \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images_array,train_label_enc,validation_data=(test_image_array,test_label_enc), batch_size=32, epochs=250, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "670663c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = scalar.fit_transform(test_images_array.reshape(len(test_images_array),112*112*3))\n",
    "test_image_array = test_image.reshape(len(test_images_array),112,112,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcb3f4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 2s 20ms/step - loss: 5.8290 - accuracy: 0.3973 - auc: 0.6242 0s - loss: 6.1700 - accuracy: 0.3691 - auc:  - ETA: 0s - loss: 5.5569 - accuracy: 0.40 - ETA: 0s - loss: 5.5531 - accuracy: 0.3964 - a\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_image_array,test_label_enc, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1375c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd7c24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(test_image_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1eccbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_bool = np.argmax(y_predict,axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9635b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c0226de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[316,  70, 219, 205],\n",
       "       [ 61,  50,  32, 157],\n",
       "       [ 79,  60, 479, 132],\n",
       "       [154,  83, 321, 192]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_image_label,y_predict_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8eecc0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39401173608950996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(test_image_label,y_predict_bool,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "444d2443",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.39      0.45       810\n",
      "           1       0.19      0.17      0.18       300\n",
      "           2       0.46      0.64      0.53       750\n",
      "           3       0.28      0.26      0.27       750\n",
      "\n",
      "    accuracy                           0.40      2610\n",
      "   macro avg       0.36      0.36      0.36      2610\n",
      "weighted avg       0.39      0.40      0.39      2610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_image_label,y_predict_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e747ca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7872539682539683\n"
     ]
    }
   ],
   "source": [
    "fpr,tpr,thresholds = roc_curve(test_image_label,y_predict_bool,pos_label=1)\n",
    "print(auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c9ceb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ab14393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dde5258a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['auc'])\n",
    "plt.plot(history.history['val_auc'])\n",
    "plt.title('model auc')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230219a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

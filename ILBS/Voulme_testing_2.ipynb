{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, MaxPool2D\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Work_to_be_Completed_ILBS'\n",
    "pid = []\n",
    "image_file = []\n",
    "for fname in os.listdir(path):\n",
    "    if fname.isdigit():\n",
    "        pid.append(fname)\n",
    "        for fname_ins in os.listdir(path+'\\\\'+fname):\n",
    "            image_file.append(path+'\\\\'+fname+'\\\\'+fname_ins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = pd.DataFrame(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35011, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile(path+'\\\\'+'HVPG Training Value_1.xlsx',engine='openpyxl')\n",
    "df_label_train = pd.read_excel(xls,'Train')\n",
    "df_label_test = pd.read_excel(xls,'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = []\n",
    "for row in df_f.values.tolist():\n",
    "    id_ = int(row[0].split('\\\\')[-2])\n",
    "    if id_ == 910:\n",
    "        id_ = 9109\n",
    "    for rows in df_label_train.values.tolist():\n",
    "        if id_==rows[0]:\n",
    "            labels_train.append([row[0],rows[-1]])\n",
    "           # print(label)\n",
    "        #break\n",
    "    #print(row,id_)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test = []\n",
    "for row in df_f.values.tolist():\n",
    "    id_ = int(row[0].split('\\\\')[-2])\n",
    "    if id_ == 910:\n",
    "        id_ = 9109\n",
    "    for rows in df_label_test.values.tolist():\n",
    "        if id_==rows[0]:\n",
    "            labels_test.append([row[0],rows[-1]])\n",
    "           # print(label)\n",
    "        #break\n",
    "    #print(row,id_)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(labels_train,columns=['path','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(labels_test,columns=['path','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "#X = df['imarray'].values\n",
    "y_train = np.array(df_train['label'])\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "y_test = np.array(df_test['label'])\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_train = []\n",
    "IMG_HEIGHT = IMG_WIDTH =150\n",
    "for row in df_train['path']:\n",
    "    image= cv2.imread( row, cv2.IMREAD_GRAYSCALE)\n",
    "    image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    all_images_train.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_test = []\n",
    "IMG_HEIGHT = IMG_WIDTH =150\n",
    "for row in df_test['path']:\n",
    "    image= cv2.imread( row, cv2.IMREAD_GRAYSCALE)\n",
    "    image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    image /= 255\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    all_images_test.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = np.array(all_images_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = np.array(all_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(train_,axis=3)\n",
    "X_test = np.expand_dims(test_, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_124 (Conv2D)          (None, 150, 150, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_127 (Conv2D)          (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_128 (Conv2D)          (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_131 (Conv2D)          (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_132 (Conv2D)          (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_133 (Conv2D)          (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_134 (Conv2D)          (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_135 (Conv2D)          (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_136 (Conv2D)          (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "vgg16 (MaxPooling2D)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 28)                3612      \n",
      "=================================================================\n",
      "Total params: 16,847,452\n",
      "Trainable params: 16,847,452\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(150,150,),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "model.add(Flatten(name='flatten'))\n",
    "model.add(Dense(256, activation='relu', name='fc1'))\n",
    "model.add(Dense(128, activation='relu', name='fc2'))\n",
    "model.add(Dense(28, activation='sigmoid', name='output'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22955 samples, validate on 7652 samples\n",
      "Epoch 1/40\n",
      "22955/22955 [==============================] - 93s 4ms/sample - loss: 3.3313 - accuracy: 0.0964 - val_loss: 3.3307 - val_accuracy: 0.0797\n",
      "Epoch 2/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.3294 - accuracy: 0.1053 - val_loss: 3.3292 - val_accuracy: 0.0797\n",
      "Epoch 3/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.3272 - accuracy: 0.1053 - val_loss: 3.3274 - val_accuracy: 0.0797\n",
      "Epoch 4/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.3246 - accuracy: 0.1053 - val_loss: 3.3253 - val_accuracy: 0.0797\n",
      "Epoch 5/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.3215 - accuracy: 0.1053 - val_loss: 3.3228 - val_accuracy: 0.0797\n",
      "Epoch 6/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.3176 - accuracy: 0.1053 - val_loss: 3.3194 - val_accuracy: 0.0797\n",
      "Epoch 7/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.3119 - accuracy: 0.1053 - val_loss: 3.3141 - val_accuracy: 0.0797\n",
      "Epoch 8/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.3013 - accuracy: 0.1053 - val_loss: 3.3024 - val_accuracy: 0.0797\n",
      "Epoch 9/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.2626 - accuracy: 0.1053 - val_loss: 3.2327 - val_accuracy: 0.0797\n",
      "Epoch 10/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 3.0057 - accuracy: 0.1053 - val_loss: 3.0906 - val_accuracy: 0.0797\n",
      "Epoch 11/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.8444 - accuracy: 0.1053 - val_loss: 3.0465 - val_accuracy: 0.0797\n",
      "Epoch 12/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.8069 - accuracy: 0.1153 - val_loss: 3.0728 - val_accuracy: 0.0519\n",
      "Epoch 13/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.7902 - accuracy: 0.1163 - val_loss: 3.1185 - val_accuracy: 0.0473\n",
      "Epoch 14/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.7773 - accuracy: 0.1188 - val_loss: 3.1418 - val_accuracy: 0.0362\n",
      "Epoch 15/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.7663 - accuracy: 0.1204 - val_loss: 3.2066 - val_accuracy: 0.0375\n",
      "Epoch 16/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.7547 - accuracy: 0.1208 - val_loss: 3.2287 - val_accuracy: 0.0257\n",
      "Epoch 17/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.7393 - accuracy: 0.1224 - val_loss: 3.2537 - val_accuracy: 0.0255\n",
      "Epoch 18/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.7190 - accuracy: 0.1237 - val_loss: 3.3663 - val_accuracy: 0.0353\n",
      "Epoch 19/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.6902 - accuracy: 0.1240 - val_loss: 3.4471 - val_accuracy: 0.0519\n",
      "Epoch 20/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.6493 - accuracy: 0.1241 - val_loss: 3.4552 - val_accuracy: 0.0397\n",
      "Epoch 21/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.5974 - accuracy: 0.1253 - val_loss: 3.5122 - val_accuracy: 0.0518\n",
      "Epoch 22/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.5412 - accuracy: 0.1153 - val_loss: 3.5695 - val_accuracy: 0.0852\n",
      "Epoch 23/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.4862 - accuracy: 0.1059 - val_loss: 3.6286 - val_accuracy: 0.0797\n",
      "Epoch 24/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.4367 - accuracy: 0.1053 - val_loss: 3.8377 - val_accuracy: 0.0797\n",
      "Epoch 25/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.3878 - accuracy: 0.1053 - val_loss: 3.9349 - val_accuracy: 0.0797\n",
      "Epoch 26/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.3378 - accuracy: 0.1053 - val_loss: 4.2297 - val_accuracy: 0.0797\n",
      "Epoch 27/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.2962 - accuracy: 0.1053 - val_loss: 4.5073 - val_accuracy: 0.0797\n",
      "Epoch 28/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.2547 - accuracy: 0.1053 - val_loss: 4.4662 - val_accuracy: 0.0797\n",
      "Epoch 29/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.2204 - accuracy: 0.1053 - val_loss: 4.9402 - val_accuracy: 0.0797\n",
      "Epoch 30/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.1879 - accuracy: 0.1053 - val_loss: 4.6408 - val_accuracy: 0.0797\n",
      "Epoch 31/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.1537 - accuracy: 0.1053 - val_loss: 5.6459 - val_accuracy: 0.0797\n",
      "Epoch 32/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.1293 - accuracy: 0.1053 - val_loss: 5.5698 - val_accuracy: 0.0797\n",
      "Epoch 33/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.0987 - accuracy: 0.1053 - val_loss: 5.6270 - val_accuracy: 0.0797\n",
      "Epoch 34/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.0769 - accuracy: 0.1053 - val_loss: 5.9434 - val_accuracy: 0.0797\n",
      "Epoch 35/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.0506 - accuracy: 0.1053 - val_loss: 6.6214 - val_accuracy: 0.0797\n",
      "Epoch 36/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.0278 - accuracy: 0.1055 - val_loss: 6.0940 - val_accuracy: 0.0797\n",
      "Epoch 37/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 2.0108 - accuracy: 0.1055 - val_loss: 6.7984 - val_accuracy: 0.0797\n",
      "Epoch 38/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 1.9882 - accuracy: 0.1057 - val_loss: 7.4455 - val_accuracy: 0.0797\n",
      "Epoch 39/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 1.9744 - accuracy: 0.1060 - val_loss: 7.4580 - val_accuracy: 0.0797\n",
      "Epoch 40/40\n",
      "22955/22955 [==============================] - 87s 4ms/sample - loss: 1.9550 - accuracy: 0.1063 - val_loss: 7.7780 - val_accuracy: 0.0797\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,validation_split=0.25, batch_size=64, epochs=40, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_68 (Conv2D)           (None, 150, 150, 16)      160       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 150, 150, 16)      64        \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 150, 150, 32)      4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 150, 150, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_60 (MaxPooling (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 75, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 75, 75, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_61 (MaxPooling (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 37, 37, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_62 (MaxPooling (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 82944)             0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               21233920  \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 28)                3612      \n",
      "=================================================================\n",
      "Total params: 21,665,756\n",
      "Trainable params: 21,664,252\n",
      "Non-trainable params: 1,504\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', padding='same',\n",
    "                 input_shape=(150, 150,1)))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_1.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_1.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_1.add(Flatten())\n",
    "# Densely connected layers\n",
    "model_1.add(Dense(256, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001), bias_regularizer=l2(0.001)))\n",
    "model_1.add(BatchNormalization())\n",
    "model_1.add(Dropout(.5))\n",
    "model_1.add(Dense(128, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001), bias_regularizer=l2(0.001)))\n",
    "model_1.add(Dropout(.25))\n",
    "\n",
    "# output layer\n",
    "model_1.add(Dense(28, activation='softmax'))\n",
    "\n",
    "model_1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(0.001),\n",
    "              metrics=['accuracy'])\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=3, min_lr=0.0001)\n",
    "print(model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22955 samples, validate on 7652 samples\n",
      "Epoch 1/40\n",
      "22955/22955 [==============================] - 38s 2ms/sample - loss: 4.3236 - accuracy: 0.1010 - val_loss: 3.9213 - val_accuracy: 0.1541\n",
      "Epoch 2/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 3.1777 - accuracy: 0.2803 - val_loss: 4.4668 - val_accuracy: 0.0495\n",
      "Epoch 3/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 2.5529 - accuracy: 0.4544 - val_loss: 4.6604 - val_accuracy: 0.0404\n",
      "Epoch 4/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 2.1198 - accuracy: 0.6005 - val_loss: 4.7046 - val_accuracy: 0.0427\n",
      "Epoch 5/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.9088 - accuracy: 0.6717 - val_loss: 4.7337 - val_accuracy: 0.0405\n",
      "Epoch 6/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.8482 - accuracy: 0.6938 - val_loss: 4.7311 - val_accuracy: 0.0404\n",
      "Epoch 7/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.7888 - accuracy: 0.7142 - val_loss: 4.7408 - val_accuracy: 0.0393\n",
      "Epoch 8/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.7437 - accuracy: 0.7313 - val_loss: 4.7419 - val_accuracy: 0.0387\n",
      "Epoch 9/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.7282 - accuracy: 0.7359 - val_loss: 4.7515 - val_accuracy: 0.0370\n",
      "Epoch 10/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.7109 - accuracy: 0.7391 - val_loss: 4.7503 - val_accuracy: 0.0369\n",
      "Epoch 11/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.6813 - accuracy: 0.7532 - val_loss: 4.7522 - val_accuracy: 0.0376\n",
      "Epoch 12/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.6496 - accuracy: 0.7636 - val_loss: 4.7593 - val_accuracy: 0.0372\n",
      "Epoch 13/40\n",
      "22955/22955 [==============================] - 34s 1ms/sample - loss: 1.6323 - accuracy: 0.7672 - val_loss: 4.7716 - val_accuracy: 0.0365\n",
      "Epoch 14/40\n",
      "17856/22955 [======================>.......] - ETA: 6s - loss: 1.6249 - accuracy: 0.7706WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \"\"\"\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aiims-iitd\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tensorflow as tf\n",
    "history = model_1.fit(X_train, y_train,callbacks=[reduce_lr],validation_split=0.25, batch_size=64, epochs=40, verbose=1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6189/6189 [==============================] - 2s 393us/sample - loss: 5.7445 - accuracy: 0.2973\n",
      "Test loss: 5.744454553505199\n",
      "Test accuracy: 0.29730165\n",
      "30607/30607 [==============================] - 12s 379us/sample - loss: 1.3129 - accuracy: 0.8874\n",
      "Train loss: 1.3129004359490675\n",
      "Train accuracy: 0.88741136\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(X_test, y_test, verbose = 1) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "score = model_1.evaluate(X_train, y_train, verbose = 1) \n",
    "\n",
    "print('Train loss:', score[0]) \n",
    "print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 148, 148, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 146, 146, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_67 (MaxPooling (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 341056)            0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 128)               43655296  \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 28)                3612      \n",
      "=================================================================\n",
      "Total params: 43,677,724\n",
      "Trainable params: 43,677,724\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', \n",
    "                 input_shape=(150, 150,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model_1.add(Dropout(.25))\n",
    "model.add(Dense(28, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27546 samples, validate on 3061 samples\n",
      "Epoch 1/55\n",
      "27546/27546 [==============================] - 23s 818us/sample - loss: 3.0460 - accuracy: 0.1298 - val_loss: 3.0379 - val_accuracy: 0.0069\n",
      "Epoch 2/55\n",
      "27546/27546 [==============================] - 22s 808us/sample - loss: 2.7706 - accuracy: 0.2190 - val_loss: 3.0052 - val_accuracy: 0.0196\n",
      "Epoch 3/55\n",
      "27546/27546 [==============================] - 22s 811us/sample - loss: 2.6251 - accuracy: 0.2674 - val_loss: 3.0697 - val_accuracy: 0.0082\n",
      "Epoch 4/55\n",
      "27546/27546 [==============================] - 22s 795us/sample - loss: 2.4644 - accuracy: 0.3259 - val_loss: 3.1052 - val_accuracy: 0.0180\n",
      "Epoch 5/55\n",
      "27546/27546 [==============================] - 22s 795us/sample - loss: 2.2714 - accuracy: 0.3940 - val_loss: 3.1529 - val_accuracy: 0.0216\n",
      "Epoch 6/55\n",
      "27546/27546 [==============================] - 22s 800us/sample - loss: 2.0369 - accuracy: 0.4816 - val_loss: 3.1479 - val_accuracy: 0.0454\n",
      "Epoch 7/55\n",
      "27546/27546 [==============================] - 22s 814us/sample - loss: 1.7640 - accuracy: 0.5704 - val_loss: 3.3215 - val_accuracy: 0.0245\n",
      "Epoch 8/55\n",
      "27546/27546 [==============================] - 22s 815us/sample - loss: 1.4783 - accuracy: 0.6621 - val_loss: 3.4923 - val_accuracy: 0.0180\n",
      "Epoch 9/55\n",
      "27546/27546 [==============================] - 22s 796us/sample - loss: 1.2096 - accuracy: 0.7405 - val_loss: 3.6949 - val_accuracy: 0.0124\n",
      "Epoch 10/55\n",
      "27546/27546 [==============================] - 22s 796us/sample - loss: 0.9780 - accuracy: 0.7984 - val_loss: 4.0338 - val_accuracy: 0.0150\n",
      "Epoch 11/55\n",
      "27546/27546 [==============================] - 22s 797us/sample - loss: 0.7894 - accuracy: 0.8437 - val_loss: 4.3779 - val_accuracy: 0.0147\n",
      "Epoch 12/55\n",
      "27546/27546 [==============================] - 22s 797us/sample - loss: 0.6398 - accuracy: 0.8817 - val_loss: 4.6843 - val_accuracy: 0.0140\n",
      "Epoch 13/55\n",
      "27546/27546 [==============================] - 22s 797us/sample - loss: 0.5223 - accuracy: 0.9091 - val_loss: 4.7979 - val_accuracy: 0.0095\n",
      "Epoch 14/55\n",
      "27546/27546 [==============================] - 22s 807us/sample - loss: 0.4300 - accuracy: 0.9286 - val_loss: 5.3228 - val_accuracy: 0.0023\n",
      "Epoch 15/55\n",
      "27546/27546 [==============================] - 22s 803us/sample - loss: 0.3572 - accuracy: 0.9467 - val_loss: 5.5721 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/55\n",
      "27546/27546 [==============================] - 22s 808us/sample - loss: 0.2995 - accuracy: 0.9566 - val_loss: 5.7571 - val_accuracy: 6.5338e-04\n",
      "Epoch 17/55\n",
      "27546/27546 [==============================] - 23s 819us/sample - loss: 0.2536 - accuracy: 0.9644 - val_loss: 6.1359 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/55\n",
      "27546/27546 [==============================] - 23s 826us/sample - loss: 0.2165 - accuracy: 0.9718 - val_loss: 6.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/55\n",
      "27546/27546 [==============================] - 22s 806us/sample - loss: 0.1867 - accuracy: 0.9748 - val_loss: 6.3928 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/55\n",
      "27546/27546 [==============================] - 23s 819us/sample - loss: 0.1620 - accuracy: 0.9786 - val_loss: 6.7110 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/55\n",
      "27546/27546 [==============================] - 22s 807us/sample - loss: 0.1418 - accuracy: 0.9800 - val_loss: 6.8392 - val_accuracy: 9.8007e-04\n",
      "Epoch 22/55\n",
      "27546/27546 [==============================] - 23s 821us/sample - loss: 0.1253 - accuracy: 0.9814 - val_loss: 7.1582 - val_accuracy: 0.0023\n",
      "Epoch 23/55\n",
      "27546/27546 [==============================] - 23s 834us/sample - loss: 0.1116 - accuracy: 0.9834 - val_loss: 7.3741 - val_accuracy: 0.0016\n",
      "Epoch 24/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0999 - accuracy: 0.9842 - val_loss: 7.3255 - val_accuracy: 0.0026\n",
      "Epoch 25/55\n",
      "27546/27546 [==============================] - 23s 832us/sample - loss: 0.0905 - accuracy: 0.9843 - val_loss: 7.7255 - val_accuracy: 0.0020\n",
      "Epoch 26/55\n",
      "27546/27546 [==============================] - 22s 808us/sample - loss: 0.0822 - accuracy: 0.9847 - val_loss: 7.8857 - val_accuracy: 0.0029\n",
      "Epoch 27/55\n",
      "27546/27546 [==============================] - 22s 800us/sample - loss: 0.0754 - accuracy: 0.9848 - val_loss: 7.7582 - val_accuracy: 0.0033\n",
      "Epoch 28/55\n",
      "27546/27546 [==============================] - 22s 800us/sample - loss: 0.0700 - accuracy: 0.9845 - val_loss: 8.1437 - val_accuracy: 0.0026\n",
      "Epoch 29/55\n",
      "27546/27546 [==============================] - 22s 799us/sample - loss: 0.0646 - accuracy: 0.9857 - val_loss: 8.0535 - val_accuracy: 0.0033\n",
      "Epoch 30/55\n",
      "27546/27546 [==============================] - 22s 800us/sample - loss: 0.0604 - accuracy: 0.9849 - val_loss: 8.4736 - val_accuracy: 0.0023\n",
      "Epoch 31/55\n",
      "27546/27546 [==============================] - 22s 806us/sample - loss: 0.0569 - accuracy: 0.9849 - val_loss: 8.2614 - val_accuracy: 0.0036\n",
      "Epoch 32/55\n",
      "27546/27546 [==============================] - 22s 815us/sample - loss: 0.0533 - accuracy: 0.9860 - val_loss: 8.3292 - val_accuracy: 0.0039\n",
      "Epoch 33/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0509 - accuracy: 0.9855 - val_loss: 8.4942 - val_accuracy: 0.0049\n",
      "Epoch 34/55\n",
      "27546/27546 [==============================] - 22s 812us/sample - loss: 0.0486 - accuracy: 0.9852 - val_loss: 8.6640 - val_accuracy: 0.0033\n",
      "Epoch 35/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0459 - accuracy: 0.9856 - val_loss: 9.1272 - val_accuracy: 0.0033\n",
      "Epoch 36/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0447 - accuracy: 0.9854 - val_loss: 9.3601 - val_accuracy: 0.0036\n",
      "Epoch 37/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0423 - accuracy: 0.9851 - val_loss: 9.1324 - val_accuracy: 0.0033\n",
      "Epoch 38/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0407 - accuracy: 0.9857 - val_loss: 9.1312 - val_accuracy: 0.0039\n",
      "Epoch 39/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0403 - accuracy: 0.9847 - val_loss: 9.1648 - val_accuracy: 0.0052\n",
      "Epoch 40/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0386 - accuracy: 0.9854 - val_loss: 9.6616 - val_accuracy: 0.0036\n",
      "Epoch 41/55\n",
      "27546/27546 [==============================] - 22s 814us/sample - loss: 0.0378 - accuracy: 0.9854 - val_loss: 9.2693 - val_accuracy: 0.0052\n",
      "Epoch 42/55\n",
      "27546/27546 [==============================] - 22s 812us/sample - loss: 0.0369 - accuracy: 0.9854 - val_loss: 9.5188 - val_accuracy: 0.0042\n",
      "Epoch 43/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0358 - accuracy: 0.9852 - val_loss: 9.4232 - val_accuracy: 0.0078\n",
      "Epoch 44/55\n",
      "27546/27546 [==============================] - 22s 812us/sample - loss: 0.0353 - accuracy: 0.9848 - val_loss: 9.7310 - val_accuracy: 0.0039\n",
      "Epoch 45/55\n",
      "27546/27546 [==============================] - 22s 814us/sample - loss: 0.0344 - accuracy: 0.9852 - val_loss: 9.8698 - val_accuracy: 0.0039\n",
      "Epoch 46/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0337 - accuracy: 0.9855 - val_loss: 9.8650 - val_accuracy: 0.0046\n",
      "Epoch 47/55\n",
      "27546/27546 [==============================] - 22s 812us/sample - loss: 0.0339 - accuracy: 0.9845 - val_loss: 9.9125 - val_accuracy: 0.0049\n",
      "Epoch 48/55\n",
      "27546/27546 [==============================] - 22s 814us/sample - loss: 0.0329 - accuracy: 0.9853 - val_loss: 10.3400 - val_accuracy: 0.0039\n",
      "Epoch 49/55\n",
      "27546/27546 [==============================] - 22s 813us/sample - loss: 0.0324 - accuracy: 0.9852 - val_loss: 10.1440 - val_accuracy: 0.0036\n",
      "Epoch 50/55\n",
      "27546/27546 [==============================] - 22s 816us/sample - loss: 0.0320 - accuracy: 0.9856 - val_loss: 10.3297 - val_accuracy: 0.0036\n",
      "Epoch 51/55\n",
      "27546/27546 [==============================] - 22s 814us/sample - loss: 0.0312 - accuracy: 0.9860 - val_loss: 10.3427 - val_accuracy: 0.0049\n",
      "Epoch 52/55\n",
      "27546/27546 [==============================] - 23s 818us/sample - loss: 0.0309 - accuracy: 0.9856 - val_loss: 10.2319 - val_accuracy: 0.0052\n",
      "Epoch 53/55\n",
      "27546/27546 [==============================] - 23s 826us/sample - loss: 0.0307 - accuracy: 0.9862 - val_loss: 10.2262 - val_accuracy: 0.0052\n",
      "Epoch 54/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27546/27546 [==============================] - 23s 818us/sample - loss: 0.0302 - accuracy: 0.9859 - val_loss: 10.5547 - val_accuracy: 0.0039\n",
      "Epoch 55/55\n",
      "27546/27546 [==============================] - 23s 846us/sample - loss: 0.0301 - accuracy: 0.9847 - val_loss: 10.8270 - val_accuracy: 0.0042\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "history = model.fit(X_train, y_train,validation_split=0.1, batch_size=100, epochs=55, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6189/6189 [==============================] - 3s 413us/sample - loss: 12.9507 - TP: 2097.0000 - FP: 4067.0000 - TN: 163036.0000 - FN: 4092.0000 - accuracy: 0.3393 - precision: 0.3402 - recall: 0.3388 - auc: 0.6623\n",
      "Test loss: 12.95073006419986\n",
      "Test accuracy: 0.3393117\n",
      "30607/30607 [==============================] - 12s 379us/sample - loss: 1.3282 - TP: 27207.0000 - FP: 3299.0000 - TN: 823090.0000 - FN: 3400.0000 - accuracy: 0.8889 - precision: 0.8919 - recall: 0.8889 - auc: 0.9543\n",
      "Train loss: 1.3281505224375183\n",
      "Train accuracy: 0.8889143\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose = 1) \n",
    "\n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[5])\n",
    "score = model.evaluate(X_train, y_train, verbose = 1) \n",
    "\n",
    "print('Train loss:', score[0]) \n",
    "print('Train accuracy:', score[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'D:\\ILBS_14_8_21_Sanjeev\\Work_to_be_Completed_ILBS\\186877'\n",
    "image_file = []\n",
    "IMG_HEIGHT = IMG_WIDTH=150\n",
    "for fname in os.listdir(path):\n",
    "    #print(fname)\n",
    "    image= cv2.imread( path+'\\\\'+fname, cv2.IMREAD_GRAYSCALE)\n",
    "    #print(image[0])\n",
    "    #image=cv2.resize(image, (IMG_HEIGHT, IMG_WIDTH),interpolation = cv2.INTER_AREA)\n",
    "    image=np.array(image)\n",
    "    image = image.astype('float32')\n",
    "    #image = np.expand_dims(image, axis=0)\n",
    "    image_file.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = []\n",
    "for item in image_file:\n",
    "    p.append(np.mean(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fe2a5933c8>]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00910\n",
      "110991\n",
      "115428\n",
      "119394\n",
      "121800\n",
      "123453\n",
      "129155\n",
      "134645\n",
      "141396\n",
      "142836\n",
      "145692\n",
      "148415\n",
      "152674\n",
      "154032\n",
      "154974\n",
      "157025\n",
      "158066\n",
      "159071\n",
      "161885\n",
      "162051\n",
      "163422\n",
      "163557\n",
      "166060\n",
      "171969\n",
      "172738\n",
      "173378\n",
      "174323\n",
      "174922\n",
      "175633\n",
      "175634\n",
      "176381\n",
      "176633\n",
      "177080\n",
      "177541\n",
      "178788\n",
      "181077\n",
      "181571\n",
      "181585\n",
      "183370\n",
      "183481\n",
      "183556\n",
      "183684\n",
      "184158\n",
      "184206\n",
      "184530\n",
      "185684\n",
      "185691\n",
      "185700\n",
      "185703\n",
      "186097\n",
      "186247\n",
      "186436\n",
      "186449\n",
      "186632\n",
      "186655\n",
      "186667\n",
      "186712\n",
      "186877\n",
      "186970\n",
      "187054\n",
      "187072\n",
      "187084\n",
      "187095\n",
      "187107\n",
      "187108\n",
      "187162\n",
      "187184\n",
      "187195\n",
      "187199\n",
      "187407\n",
      "187442\n",
      "187479\n",
      "187599\n",
      "187603\n",
      "187615\n",
      "187698\n",
      "187868\n",
      "187876\n",
      "187897\n",
      "187921\n",
      "188081\n",
      "188084\n",
      "188094\n",
      "188141\n",
      "188224\n",
      "188267\n",
      "188674\n",
      "188726\n",
      "188974\n",
      "189082\n",
      "189138\n",
      "189143\n",
      "189216\n",
      "189243\n",
      "189689\n",
      "189715\n",
      "19699\n",
      "31322\n",
      "45341\n",
      "49565\n",
      "95470\n",
      "99036\n"
     ]
    }
   ],
   "source": [
    "path = 'Work_to_be_Completed_ILBS'\n",
    "pid = []\n",
    "image_file = []\n",
    "for fname in os.listdir(path):\n",
    "    if fname.isdigit():\n",
    "        pid.append(fname)\n",
    "        print(fname)\n",
    "        os.makedirs(os.path.join(\"D:\\ILBS_14_8_21_Sanjeev\\ILBS2_Cropped_Volumes\",fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join('D:\\ILBS_14_8_21_Sanjeev\\ILBS2_Cropped_Volumes','00910'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189715\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00022.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00023.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00024.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00025.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00026.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00027.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00028.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00029.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00030.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00031.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00032.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00033.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00034.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00035.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00036.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00037.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00038.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00039.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00040.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00041.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00042.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00043.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00044.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00045.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00046.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00047.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00048.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00049.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00050.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00051.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00052.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00053.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00054.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00055.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00056.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00057.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00058.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00059.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00060.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00061.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00062.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00063.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00064.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00065.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00066.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00067.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00068.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00069.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00070.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00071.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00072.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00073.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00074.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00075.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00076.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00077.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00078.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00079.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00080.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00081.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00082.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00083.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00084.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00085.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00086.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00087.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00088.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00089.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00090.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00091.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00092.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00093.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00094.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00095.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00096.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00097.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00098.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00099.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00100.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00101.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00102.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00103.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00104.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00105.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00106.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00107.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00108.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00109.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00110.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00111.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00112.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00113.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00114.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00115.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00116.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00117.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00118.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00119.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00120.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00121.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00122.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00123.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00124.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00125.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00126.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00127.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00128.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00129.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00130.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00131.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00132.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00133.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00134.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00135.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00136.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00137.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00138.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00139.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00140.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00141.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00142.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00143.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00144.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00145.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00146.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00147.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00148.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00149.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00150.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00151.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00152.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00153.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00154.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00155.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00156.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00157.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00158.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00159.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00160.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00161.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00162.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00163.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00164.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00165.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00166.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00167.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00168.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00169.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00170.jpg\n",
      "D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes\\189715\\IMG-0073-00171.jpg\n"
     ]
    }
   ],
   "source": [
    "path = 'Work_to_be_Completed_ILBS'\n",
    "pid = []\n",
    "image_file = []\n",
    "for fname in os.listdir(path):\n",
    "    if fname.isdigit():\n",
    "        pid.append(fname)\n",
    "#print(len(pid))\n",
    "import shutil\n",
    "folder = pid[95]\n",
    "print(folder)\n",
    "files = os.listdir(os.path.join(path,folder))\n",
    "a = 21\n",
    "for i in range(a,a+150):\n",
    "    p = shutil.copyfile(os.path.join(path, folder, files[i]), os.path.join('D:\\ILBS_14_8_21_Sanjeev\\ILBS_Cropped_Volumes',folder,files[i]))\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'95470'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
